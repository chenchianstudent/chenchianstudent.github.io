<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Anyapoi WebSite</title>
  
  
  
  <!--link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css"-->
  
<link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css">

  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
<div class="Shell">
    <aside class='SideBar'>
    <section class='avatar' style="background-image: url()">
        <div class='av-pic' style="background-image: url()">
        </div>
    </section>
    <section class='menu'>
        <div>Anyapoi WebSite</div>
        
            <div>poi</div>
        
        <ul>
          
            <a href="/" class="Btn">
              <li>Home</li>
            </a>  
          
            <a href="/archives/" class="Btn">
              <li>Archive</li>
            </a>  
          
            <a href="/tags/" class="Btn">
              <li>Tags</li>
            </a>  
          
            <a href="/categories/" class="Btn">
              <li>Categories</li>
            </a>  
          
            <a href="/about/" class="Btn">
              <li>About</li>
            </a>  
          
            <a href="https://i.imgur.com/cjGoQtg.jpg" target="_blank" rel="noopener" class="Btn">
              <li>avatar</li>
            </a>  
          
        </ul>
    </section>
    <section class="media">
        
            
                <a href="https://github.com/chenchianstudent" target="_blank" rel="noopener">
                    <img src="/assets/github.svg" />
                </a>
            
        
            
                <a href="https://www.facebook.com/profile.php?id=100004713881642" target="_blank" rel="noopener">
                    <img src="/assets/facebook.svg" />
                </a>
            
        
    </section>
</aside>

    <div class="container">
        <div data-pager-shell>
            <ul class="Index">
  
    <header class='PageTitle'>
        <h1>{ Deep Learning }</h1>
    </header>
  
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E7%9A%84Hello_World-%E6%89%8B%E5%AF%AB%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98/">World-手寫數字辨識</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-08T07:17:20.000Z" itemprop="datePublished">
    2020-09-08
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">實作心得</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/jupyter-notebook/">jupyter notebook</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h3 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h3><p>記錄我在研究所學習深度學習的知識與心得。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明如何利用tensorflow來寫一個最基礎的深度學習範例，相當於學習程式語言的hello world。我會盡量將每個程式碼進行解釋，也保持著盡量說人話的方式來說明，太多專有名詞換作是我去看這類的文章，也一定很想關掉頁面。所以請抱持放鬆的心情來看文章！</p>
<h3 id="前置步驟-amp-注意事項"><a href="#前置步驟-amp-注意事項" class="headerlink" title="前置步驟&amp;注意事項"></a>前置步驟&amp;注意事項</h3><ol>
<li>本心得教學是使用tensorflow來進行撰寫。怎麼裝tensorflow？我有另外寫了<a href="https://chenchianstudent.github.io/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/" target="_blank" rel="noopener">文章</a>。</li>
<li>我必須強調一下，本人在寫這篇文章時還是學習中的學生，算是初心者。內容若是有錯，誤導大家還請多多包涵！之後發現自己有說錯話，也會去重新修文章，你發現我有說錯話，也請告訴我哪裡錯了。</li>
<li>深度學習的一些專有名詞和要表達的概念實在太多了，如果漏掉了還請多多包涵。</li>
<li>模型訓練的過程中，有些參數若是照我的內容抄，結果執行時噴錯，原因很有可能是設備性能造成的。我的指導老師說了一句我覺得蠻中肯的話:深度學習也是一種軍備競賽，裝備差的人能表現的實在有限。</li>
<li>若是範例跑不動，可以採用colab。colab是google發明類似jupyter notebook的程式編譯器，是線上的，有網路就可以在瀏覽器上使用，有興趣可以試試，目前是免費的，但不保證未來也是免費喔！colab的教學我再考慮看看要不要另外寫一篇來說。</li>
<li>什麼是深度學習？請參考這篇<a href="https://chenchianstudent.github.io/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/" target="_blank" rel="noopener">文章</a></li>
</ol>
<h3 id="了解資料內容-什麼是手寫數字辨識資料集"><a href="#了解資料內容-什麼是手寫數字辨識資料集" class="headerlink" title="了解資料內容-什麼是手寫數字辨識資料集?"></a>了解資料內容-什麼是手寫數字辨識資料集?</h3><p>簡單來說，它是一個很多張圖片的資料夾。<br>內容是一般人從數字0寫到9的圖片，不同人寫下並拍照，最後匯集在一起變成手寫數字資料集。手寫數字資料集從很久以前就有人在使用了，它不是最近才出現的，當時創造這份資料的主要目標，是想辦法透過手寫資料集讓電腦能正確判斷人寫的數字，也就是這篇文章要做的事情。<br>在以前這是一份很艱難的任務，但自從深度學習興起後，電腦辨識手寫數字這份任務就變得很簡單！而且辨識率可以達到99%以上，比人類辨識還要精準！</p>
<h3 id="程式內容"><a href="#程式內容" class="headerlink" title="程式內容"></a>程式內容</h3><p>以下為等等要講解的程式內容，也就是一個手寫數字辨識的實際範例<br>完整程式在我的Github <a href="https://github.com/chenchianstudent/DeepLearing-Test" target="_blank" rel="noopener">Deep Learing-test</a>專案中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<p>一共15行，解決以前的大難題，很厲害吧！<br>接下來要做的就是講解這15行在幹嘛，但因為一次說明會很複雜，因此我會將程式分成5個部分，就像jupyter notebook一樣。<br>第一部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>第二部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br></pre></td></tr></table></figure>
<p>第三部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>第四部份</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p>第五部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>

<h3 id="程式講解-第一部分"><a href="#程式講解-第一部分" class="headerlink" title="程式講解-第一部分"></a>程式講解-第一部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>這是我們最一開始必須import的函式庫，也就是我們的主角tensorflow，接下來會用tensorflow來進行深度學習。<br>而<code>import tensorflow as tf</code>的<code>as tf</code>則是將tensorflow做簡稱，等等在寫程式時如果要用到tensorflow時，只需要打tf電腦就會呼叫tensorflow了。<br>基本上你查文章時很多人都是將tensorflow簡稱tf的，希望各位初學者也養成這個習慣。<br>一來大家看你程式碼時比較不會多想，因為大家都知道tf是什麼，二來是你養成習慣後，查文章看到tf也可以知道作者是在表達什麼，對大家都好，tf這習慣不強制性，但養成會更好。<br>再來我們說說下行的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>如果有寫過程式的人，應該會很明白的這是要做print出一個值的動作。<br>問題是這個值是什麼？<br>很簡單，version的中文是”版本”，整句的意思：print出tensorflow的版本。</p>
<p>關於第一部分程式碼的注意事項:</p>
<ol>
<li>version旁邊的__是特殊寫法，為什麼這樣寫——–&gt;沒為什麼，就是tensorflow的規定。</li>
<li><code>__version__</code> 的<em>_ 一邊是兩個_，左右兩邊共4個</em> &lt;——-反正寫錯會跳error，你就會記得了。</li>
<li>tf就是我們上面講的，tensorflow的代稱。</li>
</ol>
<h3 id="程式講解-第二部分"><a href="#程式講解-第二部分" class="headerlink" title="程式講解-第二部分"></a>程式講解-第二部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br></pre></td></tr></table></figure>
<p><code>mnist = tf.keras.datasets.mnist</code>的整句意思為以mnist這個變數來存取數字辨識資料集。<br>mnist的意思是手寫數字辨識，你在google打上mnist就會跑出很多手寫數字辨識的文章或資料集。<br>奇怪？我都沒有下載手寫數字資料集，為什麼就能存取數字辨識了？<br>原因就是這個<code>tf.keras.datasets</code>，tensorflow裡面就有內建手寫數字辨識了，我們去呼叫tensorflow資料庫裡的mnist手寫數字辨識就好了，tensorflow將很多大家常用的資料集都放到自己的資料庫了，有興趣的可以上網查一下這個資料庫裡有什麼，今次只講解mnist，因此就不花時間說明。<br>這是我們剛抓進來的<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">mnist資料集詳細資料</a>，可以看一下！<br>資料集內容大概是長這樣</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train-images-idx3-ubyte.gz:  training set images (9912422 bytes)</span><br><span class="line">train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)</span><br><span class="line">t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)</span><br><span class="line">t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)</span><br></pre></td></tr></table></figure>
<p>四個檔案—&gt;training的圖片和標籤(2個)+test的圖片和標籤(2個)<br>為什麼我要突然講資料內容，因為接下來的程式講解會用到這些來說明，老師當初上課不講害我查很久才知道這是在幹嘛的==<br><code>(x_train, y_train), (x_test, y_test) = mnist.load_data()</code>這行跟下行程式碼是比較困難的地方，我想辦法講的簡單一點。<br>想來說說這些x跟y是甚麼東西好了：<br>x_train = 等等要拿去讓機器訓練的數字圖片集<br>y_train = 等等要拿去讓機器訓練的數字標籤集<br>x_test = 機器訓練好後拿來做驗證的數字圖片集<br>y_test = 機器訓練好後拿來做驗證的數字標籤集<br>再將這個代稱拆解<br>x代表圖片集<br>y代表標籤集<br>train代表訓練用<br>test代表測試用<br>合起來就是<code>(x_train, y_train), (x_test, y_test)</code>然後進行讀取資料<code>mnist.load_data()</code>，目的就是讓這些資料轉變成等等要建立的模型能讀取的型態，就是這樣。<br>讀取型態大概就是長這樣<br>訓練用的(‘圖片’,’標籤’)<br>測試用的(‘圖片’,’標籤’)<br>另外圖片是一大串數字，這些數字就是圖片數字化的樣子，你可以print一下x裡的東西看一下長怎樣！</p>
<p><code>x_train, x_test = x_train / 255.0, x_test / 255.0</code>這行是資料處理，目的是讓等等建立的模型做訓練時可以比較好訓練找出規則。<br>主要的意思是對訓練和測試的圖片(已數字化)都除255.0當作資料再存取。<br>這個行為是所謂的<strong>歸一化</strong>，因為圖片為彩色RGB，值是0-255的數字，我們將這些色彩圖進行/255.0後會將這些數值縮小到0-1之間，好處是模型做計算時會比較好算，百位數跟個位數哪個比較好算，當然是個位數！另外就是防止overfitting，不會因為這張圖色彩在某個區間而認為這就是規則而當作辨識條件。</p>
<p>關於第二部分程式碼的注意事項:</p>
<ol>
<li>為什麼要除255.0而不是255？因為我們要它的小數點，因為歸一化是在0-1數字之間，就是小數點阿！</li>
<li>你可以發現我們做歸一化都是在圖片集上，標籤集不用做喔！</li>
<li>不用做歸一化其實也可以，這是一種資料處理的手法，不是絕對必要的動作。</li>
</ol>
<h3 id="程式講解-第三部分"><a href="#程式講解-第三部分" class="headerlink" title="程式講解-第三部分"></a>程式講解-第三部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>這部分就是在做建立模型(model)。<br>建立模型是深度學習最精華的地方，我們前面都是在做資料處理，目的就是讓現在我們建立的模型能夠讀取，也就是說，這裡是主菜。<br><code>model = tf.keras.models.Sequential([ ])</code>這裡是tensorflow建立模型的寫法。<br>這裡我覺得要用比喻的方式來說明，假如我們現在正在創造一個機器人，<code>model = tf.keras.models.Sequential([ ])</code>就是在做機器人的外殼，讓機器人有個形狀，告訴各位我要做一個機器人，model這個變數則是告訴大家機器人叫model。<br>機器人有了外殼後，接下來就是將空殼加入零件讓他能夠動起來。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br></pre></td></tr></table></figure>
<p>這些就是我們的零件，這段程式就是在建構我們的神經層。<br>其中你們有看到Flatten、Dense、Dropout這幾個英文單字，這些是利用keras在做建構網路層時會使用到的東西。</p>
<p><strong>Flatten層</strong><br>功能是將我們讀入的資料攤平攤開，把多維的輸入一维化，通常我們是把Flatten層當卷積層到全連結層的過渡層。而<code>input_shape=(28, 28)</code>則是設定Flatten層資料讀取進來的大小28*28。</p>
<p><strong>Dense層</strong><br>就是我們大家常說的全連接層，建立神經層。Dense層會用到很多參數，但是不一定每次建Dense層時，會對每個參數做設定。像這次我們只動用到2個參數，分別是unit與activation。以<code>tf.keras.layers.Dense(128, activation=&#39;relu&#39;)</code>來做解釋好了，裡面的參數寫的詳細點就是(unit = 128, activation = ‘relu’)。</p>
<ul>
<li>unit：就是我們神經元，要在神經層裡設定多少個神經元，就是在這裡設定，一般我們在做設定神經元時，只會寫數字，不會寫”unit = “。</li>
<li>activation：中文名叫激活函數，激活函數的設定有很多，這段程式中我用了兩次Dense層，而這兩層都有用到激活函數，分別是relu與softmax。這些設定我無法用人話說，因為真的是數學抽象東西….若真的想了解，請參考<a href="https://keras.io/zh/activations/" target="_blank" rel="noopener">Keras-激活函数 Activations</a>，他會告訴你在幹嘛……</li>
</ul>
<p><strong>Dropout層</strong><br>其功用在將訓練過程中每次更新參數時按一定比率斷開輸入神經元，人話的意思是在丟到一些參數結果進下一神經元，其目的防止overfitting。</p>
<p>程式內一些注意事項</p>
<ol>
<li>最後一行的Dense層為什麼是10，原因是我們輸出結果是0-9共10個數字，因此我們會需要10個神經元。</li>
<li>Dense層是建構模型裡不可或缺的零件，請一定要加Dense層。</li>
<li>Dropout層可加可不加，其實你玩久了就會發現有些建立模型的小規則和習慣，各位在建神經層時可以試試有加跟沒加的訓練結果長怎樣。</li>
<li>input_shape為什麼是28 X 28，原因是這些手寫數字圖片是28 X 28，讓模型讀取訓練資料前，還請讓這些訓練資料修正至統一大小，不然會無法讀取！今天的範例為什麼沒做修正，原因是這些圖片都已經變成28 X 28，不用再做修正，範例比較簡單些，之後如果要自己找資料練習，就會遇到圖片處理這個環節。</li>
</ol>
<h3 id="程式講解-第四部份"><a href="#程式講解-第四部份" class="headerlink" title="程式講解-第四部份"></a>程式講解-第四部份</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p><code>model.compile()</code>是用來選擇這個模型的目標以及求解方法。<br>如果要用上面機器人的例子來說的話，就是對這些在機器人裡的零件建立好規則、教導怎麼運作來防止不會出錯。今天機器人目標是要走路，那就要制訂好規則是用四肢爬還是二肢走，手腳要怎麼運作才能正常走路等類似的概念。<br>在模型中，我們尋求解決方法會用compile(編譯)函數定義損失函數(loss)、優化函數(optimizer)及成效衡量指標(mertrics)。</p>
<p><strong>優化函數(optimizer)</strong><br>我們建立起來的模型在學習訓練的時候會一個名叫學習率的東西，它是負責控制梯度的收斂程度，如果單次更新學習率的值過高，收斂方向的速度就會變快，但這裡又說一句話，越快並不一定是最好的方法，梯度下降的收斂過程就像走小山丘，太大會暴衝會不穩，太小收斂會太慢，或是卡在局部解(local minimum)而跨不出來了。為了讓學習率更能找到我們要的最底點，就會採取像Adam的優化函數來控制α。</p>
<p><strong>損失函數(loss)</strong><br>損失函數是神經網路定義要收斂的對象函數。因為我們有龐大的參數節點(神經元)，可以擬合任意函數，我們可以不用知道權重跟bias的值明確要設多少，但可以靠反向傳播做梯度下降，讓函數逐步收斂，直到逼近最低點(global minimum)。<br>好像不是太人話，但這裡我有點想不到能用什麼例子來比喻，大概就是我們會需要定義一個損失函數來尋找最底點這樣子。</p>
<p><strong>效衡量指標(mertrics)</strong><br>用來評估訓練和測試之間的模型標準，通常我們會用’accuracy’。<br>目前我看了很多模型，幾乎都是用’accuracy’。</p>
<h3 id="程式講解-第五部份"><a href="#程式講解-第五部份" class="headerlink" title="程式講解-第五部份"></a>程式講解-第五部份</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<p>這裡就是最後一步了，恭喜你堅持到這裡！<br>機器人零件裝好了，怎麼動的規則也建立好了，最後就是要進行測試是不是我們要的結果。<br>沒錯！最後的程式碼就是在進行測試以及評估的動作，確認是我們要的答案。<br><code>model.fit()</code>用來進行模型的訓練。其中你會看到(  )內使用了測試圖片集與標籤集x_train &amp;  y_train，意思就是我要拿這兩份資料來讓模型進行訓練，從這些訓練資料找出規則，進而讓電腦自行找到辨識最佳解。<br>而<code>epochs</code>是訓練次數，我們訓練一次模型時，會更改神經元上的變數權重以利形成良好的辨識規則，但通常模型訓練時不會一次訓練就是最佳解，學腳踏車不太可能一騎上去就會吧？要多騎幾次去累積經驗才能正常騎腳踏車。模型也是如此，我們會讓模型訓練完一次後，讓訓練完後的模型再進行訓練，直到規定的訓練次數都完成為止。當然要訓練幾次就是一個經驗，答案不是你所希望的，就是再訓練或是重新再來一次。<br>另外，因為這裡只是一個很簡單的範例程式，用到的設定其實還蠻少的，實際找例子做會有很多設定會去設，之後我會找機會說，如果你等不下去想早點知道，就參考<a href="https://keras.io/zh/models/model/" target="_blank" rel="noopener">這份文章</a>吧：！</p>
<p><code>model.evaluate(x_test, y_test)</code>則是評估你的模型正確率。當你得到了一個你滿意的模型就可以拿測試資料進行評估正確率，確認拿新的資料來辨識時，是不是也能如期的辨識出正確的答案。</p>
<p><strong>output</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 112us&#x2F;sample - loss: 0.2889 - acc: 0.9142</span><br><span class="line">Epoch 2&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 97us&#x2F;sample - loss: 0.1397 - acc: 0.9582</span><br><span class="line">Epoch 3&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 95us&#x2F;sample - loss: 0.1049 - acc: 0.9682</span><br><span class="line">Epoch 4&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 97us&#x2F;sample - loss: 0.0847 - acc: 0.9739</span><br><span class="line">Epoch 5&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 99us&#x2F;sample - loss: 0.0728 - acc: 0.9769</span><br><span class="line">10000&#x2F;10000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 69us&#x2F;sample - loss: 0.0758 - acc: 0.9779</span><br><span class="line"></span><br><span class="line">[0.07581472408375703, 0.9779]</span><br></pre></td></tr></table></figure>

<p>從output裡，我們有很多東西需要知道，這些在模型訓練時給予了我們很多重要的資訊來評估是不是更改我們的模型或是這就是我們要的模型。<br>我們從<code>60000/60000 [==============================] - 7s 112us/sample - loss: 0.2889 - acc: 0.9142</code>這裡來做講解好了，這段代表模型訓練完成一次了！</p>
<p><code>60000/60000 [==============================] - 7s 112us/sample</code>是電腦在模型訓練時所花費的時間，現在這個狀態是100%，所以旁邊的秒數是寫整個過程花費的時間。當訓練還在進行時，7s這個位置就會變成距離訓練完成所剩餘的時間。</p>
<p><code>loss: 0.2889 - acc: 0.9142</code>是我們主要看的地方，loss就是損失函數，而acc則是整體正確率，正確率為0.9142(91.42%)。每一次訓練完成都會顯示loss與acc，這些資訊就是訓練時主要看的。你可以發現output中每次訓練完成後，acc會提升，這也說明了模型越來越能找到規則，能夠辨識的正確率可以提升起來。</p>
<p><code>[0.07581472408375703, 0.9779]</code>是<code>model.evaluate()</code>的output。拿一份新的資料去進行辨識，loss和acc會是多少，就是output顯示的樣子。做這個目的在於確認模型沒有overfitting，也許在訓練時，模型把訓練資料裡全部的特徵都記住了，也就是連無關緊要的特徵也納入辨識規則中，導致正確率才會那麼高！因為訓練都是拿同一份資料。假如拿一份不是訓練資料裡的圖片去辨識，可能會因為這些無關緊要的特徵而判斷錯誤，我們要避免的就是這個！評估一下拿新的資料去辨識是不是與訓練時的正確率一樣，正是評估的主要意義。</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/">深度學習？！為什麼最近大學和資訊界都能聽到這個詞？</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-08T07:05:57.000Z" itemprop="datePublished">
    2020-09-08
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h3 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h3><p>因為碩士選擇了人工智慧，於是便開始接觸tensorflow。學習過程中發現深度學習，比我在大學四年所學到的東西還要來的難！到目前為止，我每天被深度學習困擾到開始有壓力，因此，我想說先把我手上學到的東西整理成文章，一來方便自己重新閱讀，二來寫文章時可以再重新複習一遍我學到的東西，甚至在寫文章時可以把一些模糊的觀念釐清一下，在這些想法的驅使下，決定來寫看看。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明什麼是深度學習，也算是我接下來寫文章的序言，一切的開頭。</p>
<h3 id="為什麼要學深度學習"><a href="#為什麼要學深度學習" class="headerlink" title="為什麼要學深度學習?"></a>為什麼要學深度學習?</h3><p>阿我就想學阿！沒人逼你學！阿不是…..目前在資訊界裡最常聽到的名詞之一應該就是AI(人工智慧)了！我們生活環境也開始慢慢出現跟AI應用有關的產品，好比說特斯拉的自動駕駛系統，駕駛只要輸入目的地，就可以睡覺了，因為特斯拉會自動幫你駕駛到目的地，完全不需要人為介入，這就是一個AI應用的例子。聽起來非常厲害，對！真的非常厲害，如果你心中產生了非常厲害的想法，那就是為什麼有人要去學深度學習的原因了。因為這種自駕車的技術，就是從深度學習延伸出來的應用，想必未來的各種產品也會朝著這種技術去發展，AI應用的例子真的很多，不止是自駕車技術，但因為礙於篇幅長度，所以只提一個例子來佐證，現階段深度學習還是一種新興的技術，各企業搶著要這類的人才，故薪水也不會差到哪裡去，這也是為什麼我想學的原因，當然也有被這種厲害的感覺所吸引。<br>回到標題為什麼要學深度學習，為何要下這種標題？其實算是再三提醒我學深度學習的初衷，盡管最近真的超想放棄，學到快吐血，但我也必須堅持住，因為這個厲害的感覺也許就換我給別人了。</p>
<h3 id="何謂深度學習"><a href="#何謂深度學習" class="headerlink" title="何謂深度學習?"></a>何謂深度學習?</h3><p>深度學習是人工智慧的其中一種技術，人工智慧算是眾多技術合在一起的統稱。若今天別人說AI，也並不代表是在說深度學習，可能再說其他相關技術。但目前為止，深度學習是AI的主流，最近開始流行AI也是要歸功於深度學習的興起，也有不少人把AI的這詞投影在深度學習裡。恩….有對有錯拉！聽得懂就好了，不過我還是要再強調一下，深度學習只是人工智慧的其中技術，就像下圖表示的，儘管深度學習是AI大主流，但依舊只是人工智慧裡的一環而已，在未來跟別人討論AI時，也請將這個知識視為常識，不然懂的人聽到其實滿尷尬的。</p>
<img src="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/pc01.JPG" class="" title="This is an image">
<p>(圖源<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fblogs.nvidia.com.tw%2F2016%2F07%2Fwhats-difference-artificial-intelligence-machine-learning-deep-learning-ai%2F&psig=AOvVaw3XqYIgghvTbnNs_sjlEl5N&ust=1591169227107000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCODggbjN4ukCFQAAAAAdAAAAABAD" target="_blank" rel="noopener">Nvidia官方部落格</a>)<br>雖然深度學習是目前AI的主流，但深度學習這一詞並不是一個新興詞，早在90年代就存在了，當時用神經網路的概念來發表，但礙於當時的設備性能，導致無法提倡這樣的概念，想法終究只能是想法。直到最近的硬體設備性能大幅提升後，才開始把這個概念又拉回來，也因此產生了風潮。</p>
<p>我重新審視一遍自己寫的，發現還是在說人話，接下來因為太多專有名詞和抽象概念了，可能會讓你產生混亂，所以特地提醒你一下！要準備集中精神看了。</p>
<p>「深度學習」表面上看起來很難，其實真的很難！你以為我會說簡單嗎？並沒有。很多文章說明深度學習會說簡單，其實也沒騙你拉！但是當你深入進去時，就會發現這個概念就像樹枝一樣，在樹上會隨著時間越長越多，樹枝開始不停出現分叉，要學的東西也就不停地出現，感覺永遠也沒有學完的一天。舊的東西還沒學完，新的東西又出現了，根本來不及去搞懂，這就是我目前體驗到的。</p>
<p>盡管我這樣說深度學習，他還是有一個很基礎很根本的概念和步驟在，所有的東西都是從這個概念延伸出去的。台大電機系教授李宏毅有說過：「深度學習也只要三個步驟：<strong>建構網路</strong>、<strong>設定目標</strong>、<strong>開始學習</strong>。」</p>
<p>我們用李宏毅教授所說的這三個步驟來解釋好了。</p>
<p><strong>深度學習 = 建構網路 + 設定目標 + 開始學習</strong></p>
<p>因此我們就必須去理解這三個步驟在說什麼。</p>
<p><strong>建構網路</strong><br>建構所謂的神經網路。<br>各位有聽過IPO嗎?也就是Input+Program+Output的簡稱。我們輸入資料，經過程式計算，最後輸出結果，這個就是IPO架構。有學過程式的人一定不陌生。而建構網路就是負責Program這塊。在深度學習的IPO裡，我們會建構一個模型，當輸入一份資料後，資料就會進入這個模型(model)去運算，最後得出結果。模型(model)就像人的神經，裡面有神經元，神經元跟神經元彼此會連線，當神經元有很多個並且連起來後，就會形成神經網路，呼應第一句說的，建構神經網路。</p>
<p><strong>設定目標</strong><br>簡單來說就是你希望這個模型是來做什麼的？<br>這邊我要說一個蠻重要的觀念，深度學習不是萬能的，模型建構出來沒辦法應用於所有的東西上，它只能解決特定的需求。這就來到了我說的第一句，你希望你的模型用來解決什麼問題的？可能是手寫數字的辨識，也有可能是讓機器學會畫畫，不同的問題需求，就會有不同的模型誕生，目前為止是沒有任何一個模型能套用到所有的問題上的。因此設定目標是一個極為關鍵的要素，有了一個目標，才會有想法去「建構網路」，最後才能讓電腦「開始學習」。</p>
<p><strong>開始學習</strong><br>讓機器開始學習。<br>如果什麼參數和細節都要透過人類去設定的話，那就不是「機器學習」。我們設定好目標，建構好網路，接下來就是要讓機器自己去學習。神經網路裡面有數千數百萬個數值細節，這些要靠機器自己去學習如何改變裡面的變數。人們要做的只有給機器大量的訓練資料和規則去學習，並且當機器給出結果時，要告訴它這個答案對不對，最終機器會得到一個最佳函數，也就是問題的最佳解。</p>
<p>這樣講有比較明白一點嗎?我蠻怕我解釋錯誤，自己再三檢查我寫的，覺得這應該就是深度學習最主要的問題與處理步驟，自己學過後了解深度學習的一些相關認知後再回來看這三個要素，蠻感同身受的！</p>
<h3 id="關於神經網路"><a href="#關於神經網路" class="headerlink" title="關於神經網路"></a>關於神經網路</h3><p>剛剛在上文我們有講到深度學習很早之前就被提過了，是以神經網路的概念提出，因此我們就應該好好的去了解一下神經網路到底是什麼了。</p>
<p>上文我有稍微帶到一點神經網路的東西，不知道各位有沒有看到？如果要用生活上的事物來比喻神經網路的話，大概就是人的神經了！正確來說就是模仿生物神經來創造神經網路的。</p>
<p>人的神經有兩個神經元，神經元之間會利用神經纖維來連成一條線進行信號傳輸，機器的神經網路亦是如此。我們在建構神經網路時，會先建立一層神經層，神經層裡有若干的神經元，數量多少就是靠我們自己去決定。接著還會再建立新的神經層，然後新神經層裡的神經元就會與上一層的神經元做連接，形成網路開始進行信號傳遞，什麼情況信號要傳遞到A或B神經元，正是深度學習在學習的。</p>
<p>當我們成功建立好一套神經網路後，就會是我們平常講的模型(Model)。<br>新建立模型一開始正確率一定很低，我們正是要透過大量的訓練資料來訓練這個模型，而模型會因這些訓練資料來學習判斷正確結果，訓練到一定程度後，就會是我們理想中的模型，就可以拿去解決我們需要的問題了，概念如下圖。</p>
<img src="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/pc02.jpg" class="" title="This is an image">

<p>另外可能會有人問說:模型訓練是在訓練什麼東西？為什麼訓練後正確率會開始提高？<br>神經網路可以說是一個數學公式，因為我一直希望是抱持著說人話的方式來寫文章，因此就不太說數學那邊的東西。不過這裡我必須要帶點數學觀念了！剛剛我們在上上段有說到神經元這個詞，其實這些神經元就代表著一個變數，一開始是隨機亂給的，所以辨識正確率才會那麼低。為了要讓模型提高正確率，我們會加入訓練資料來做訓練，目的就是為了改變這些神經元的參數，讓這些參數達到我們要的數值，進而提升模型預測的正確率。</p>
<p>如何提高模型正確率？改變神經網路裡神經元的參數權重。</p>
<p>怎麼改神經元的參數權重？替模型加入訓練資料來進行學習。</p>
<p>學習訓練資料裡的什麼？找出訓練資料裡的規則。</p>
<h3 id="神經網路的建置-amp-問題"><a href="#神經網路的建置-amp-問題" class="headerlink" title="神經網路的建置&amp;問題"></a>神經網路的建置&amp;問題</h3><p>這部分如果讀者是0基礎的話，我覺得看過就好，因為之後的程式範例文章看過理解後，才會開始對這一個標題有想法。不過這部分也是屬於深度學習的介紹，因此還是需要歸類在這一篇文章中。</p>
<p><strong>深度學習的精隨，在於怎麼建置神經網路。</strong><br>這句話是我說的，應該沒有任何毛病！當然深度學習也有資料處理這一塊，不過最精華最精華的，還是神經網路這一塊，調整神經網路的架構、參數、模型類別等…..，我們學習深度學習主要的地方。</p>
<p><strong>深度學習為什麼厲害，在於它可以疊很多神經層。</strong><br>神經網路你愛加幾層就幾層，沒人阻止你，建置怎樣的神經網路，正是我們在學習的。<br>不過這裡就來到一個問題: 神經網路越多層越好嗎？<br>答案:不一定！</p>
<p>雖然近幾年來，一些機器學習競賽結果來看，層數越深，錯誤率也跟著降低。VGG模型層數總共19層，錯誤率到7.3%，而googleNet比VGG層數多了3層，一共22層，錯誤率可以再降到6.7%。甚至157層的Residual Network，錯誤率更可降至3.5%！但是層數越多的網路，越是會有<strong>梯度消失問題（Vanishing gradient problem）</strong>，因為每一層運算讓數值不斷收斂，導致最後的 output 越來越小，跟正確答案相減之後也就看不到顯著的最小值，看起來到處都是最小值。而防止梯度爆炸和梯度消失也是我們在建構神經網路時也必須注意的東西。</p>
<p>那可能有人又會問:驗證時不是都有標準答案嗎?把所有的答案和標準答案做比對，怎麼會找不到最小值呢？<br>答案：其實我們要面對的可能不止單單這些標準答案，也許幾百萬幾千萬！驗證時我們沒辦法把一切的答案都納入進去，而是用隨機抽選的方式，在線上找一點，比對這點四周的數值，看看是否又更低的，再慢慢去貼近最低點，這個我們稱此為<strong>梯度下降(Gradient descent)</strong>。</p>
<p>當今天你被丟在一個環境的山上，你的目的是要走到這個環境的最低點，你會開始慢慢的往低點下去。過程可能繞一大圈才下山，也有可能直直的就往低點下去。但不管怎麼樣，最終目的便是前往環境的最低點。</p>
<p>但問題來了！當你下降到一個附近都平坦的地方，你可能就認為這裡就是環境的最低點，殊不知山的對面可能還存在更深的地方或是平原遠一點的地方還存在著谷底。</p>
<p>神經網路疊加的越多層，這個問題就會越明顯，因此需要設計不同的架構，跟特殊的運算過程，才能避免找不到最低點。有時候反而 layer 少一點，正確率還更高。</p>
<h3 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h3><p>我發現我後半段好像開始說東說西偏離主題了，因此總結一下我目前說的：<br>1.深度學習離不開三個要素： 建構網路 、 設定目標 、 開始學習<br>2.怎麼進行深度學習？建構神經網路模型→輸入大量訓練資料來進行模型訓練→再利用訓練好的模型進行實際預測<br>3.深度學習的精隨，在於怎麼建置神經網路。<br>4.神經層數越高，模型的正確率也會隨之增加，但也存在著梯度消失以及梯度爆炸的風險，因此如何避免這些風險並提高模型正確率，正是我們在深度學習所要探討的。</p>
<h3 id="個人心得"><a href="#個人心得" class="headerlink" title="個人心得"></a>個人心得</h3><p>抱歉！最近因為學業和家庭關係，變得不太常更新文章，導致github上的文章都是很久之前的，讓人覺得我是不是放棄這坑了。其實這篇文章我在6月初就寫好了，但是被教授抓去幫中國信託做點他們AI上的事情，然後每周又要有論文進度，因此不太能更新文章。<br>另外我也發現，幾個月前的文章，當初要表達什麼我也不知道了XD比如圖片該放哪張？這篇文章只有兩張圖，我卻想了很久…咦？我這裡有事先截圖留著嗎？我到底是要截哪張圖上來等等…已經有這不是我寫出來的錯覺了XD總而言之，希望這篇文對你在深度學習的認知上有一點基礎，雖然有人可能會覺得打那麼多誰看得完？十分抱歉，因為我不是超級專家，我也是學習中的學生，所以無法靠很厲害的圖解來讓讀者輕鬆閱讀，這點還請多多包涵！日後我會盡量改進的。</p>

      
    </div>
</article>

    </li>
  
</ul>



            <footer>
    <div>© 2020 - daniel chen </div>
    <div>
        <span>
            Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a>
        </span>
        ,
        <span>
            Theme - <a href="https://github.com/nameoverflow/hexo-theme-icalm" target="_blank" rel="noopener">Icalm</a>
        </span>
    </div>
</footer>

        </div>
    </div>
</div>

<script src="/js/pager/dist/singlepager.js"></script>

<script>
var sp = new Pager('data-pager-shell')

</script>
</body>
</html>