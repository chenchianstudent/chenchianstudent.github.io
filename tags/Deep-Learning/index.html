<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Anyapoi WebSite</title>
  
  
  
  <!--link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css"-->
  
<link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css">

  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
<div class="Shell">
    <aside class='SideBar'>
    <section class='avatar' style="background-image: url()">
        <div class='av-pic' style="background-image: url()">
        </div>
    </section>
    <section class='menu'>
        <div>Anyapoi WebSite</div>
        
            <div>poi</div>
        
        <ul>
          
            <a href="/" class="Btn">
              <li>Home</li>
            </a>  
          
            <a href="/archives/" class="Btn">
              <li>Archive</li>
            </a>  
          
            <a href="/tags/" class="Btn">
              <li>Tags</li>
            </a>  
          
            <a href="/categories/" class="Btn">
              <li>Categories</li>
            </a>  
          
            <a href="/about/" class="Btn">
              <li>About</li>
            </a>  
          
            <a href="https://i.imgur.com/cjGoQtg.jpg" target="_blank" rel="noopener" class="Btn">
              <li>avatar</li>
            </a>  
          
        </ul>
    </section>
    <section class="media">
        
            
                <a href="https://github.com/chenchianstudent" target="_blank" rel="noopener">
                    <img src="/assets/github.svg" />
                </a>
            
        
            
                <a href="https://www.facebook.com/profile.php?id=100004713881642" target="_blank" rel="noopener">
                    <img src="/assets/facebook.svg" />
                </a>
            
        
    </section>
</aside>

    <div class="container">
        <div data-pager-shell>
            <ul class="Index">
  
    <header class='PageTitle'>
        <h1>{ Deep Learning }</h1>
    </header>
  
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/24/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%9701-%E8%8A%B1%E5%93%81%E7%A8%AE%E8%BE%A8%E8%AD%98/">深度學習實作心得01-花品種辨識</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-24T07:54:00.000Z" itemprop="datePublished">
    2020-09-24
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">實作心得</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/jupyter-notebook/">jupyter notebook</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h2 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h2><p>記錄我在研究所學習深度學習的知識與心得。</p>
<h2 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h2><p>這篇文章為<a href="https://chenchianstudent.github.io/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E7%9A%84Hello_World-%E6%89%8B%E5%AF%AB%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98/" target="_blank" rel="noopener">深度學習的Hello World-手寫數字辨識</a>的延伸實作，目的是透過一系列的實作心得，來帶給閱讀者怎麼使用tensorflow進行深度學習。<br>上次的文章資料使用Mnist，是函式庫裡面就有且處理好的資料，因此在資料處理這塊沒辦法深入太多，而這次主要是希望集中在資料處理這方面的實作解說，起碼不會讓你只能做Mnist的辨識而已，更可以應用在其他東西上。</p>
<h2 id="前置步驟-amp-注意事項"><a href="#前置步驟-amp-注意事項" class="headerlink" title="前置步驟&amp;注意事項"></a>前置步驟&amp;注意事項</h2><ol>
<li>本心得教學是使用tensorflow來進行撰寫。怎麼裝tensorflow？我有另外寫了<a href="https://chenchianstudent.github.io/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/" target="_blank" rel="noopener">文章</a>。</li>
<li>我必須強調一下，本人在寫這篇文章時還是學習中的學生，算是初心者。內容若是有錯，誤導大家還請多多包涵！之後發現我自己有說錯的話，也會去重新修文章，你發現我有說錯的話，也請告訴我哪裡錯了。</li>
<li>本文章為深度學習實作心得的系列文章，此篇為第一集，如果沒有看過第0集的話，希望你先看完第0集再來觀看此文章。</li>
<li>模型訓練的過程中，有些參數若是照我的內容抄，結果執行時會噴錯，原因很有可能是設備的性能造成的。我的指導老師說了一句我覺得蠻中肯的話:深度學習也是一種軍備競賽，裝備差的人能表現的實在有限。</li>
<li>若是範例在jupyter notebook上跑不動，可以採用colab。<br>colab是google發明類似jupyter notebook的程式編譯器，是online的，有網路就可以在瀏覽器上使用，有興趣可以試試，目前是免費的，但不保證未來也是免費喔！</li>
</ol>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>當Mnist資料集的範例程式了解後，想必第一個念頭就是能不能應用在其他的辨識上？<br>答案是能的！一定可以！深度學習不單單用在手寫數字辨識上，生活上各種辨識很多都能透過深度學習去進行辨識，但是我要怎麼把範例程式改成其他資料呢？<br>其實透過上篇文章的範例程式進行添加與修飾，就可以進行其他資料的辨識，不會太艱深，真的就是範例程式碼的變化而已。</p>
<h2 id="了解資料內容-花的品種"><a href="#了解資料內容-花的品種" class="headerlink" title="了解資料內容-花的品種"></a>了解資料內容-花的品種</h2><p>這是kaggle一個蠻早期的辨識題目，目的是讓機器辨識各種花的品種，品種有’daisy’, ‘dandelion’, ‘rose’, ‘sunflower’, ‘tulip’。乍看下差異有點大，人去辨識就很直接的出結果，沒有什麼挑戰性。但這份資料蠻適合新手第一次的練習，原因是資料量滿夠的，每個品種至少有700張以上，幫你省去了資料收集的動作，而且這個資料量可以更接近確切數據的，不會因為資料量少而導致容易overfitting，真心推薦各位使用這份資料。</p>
<h2 id="了解資料形式"><a href="#了解資料形式" class="headerlink" title="了解資料形式"></a>了解資料形式</h2><p>在研究深度學習時，我經常把程序分成好幾個部分。<br>程序如下：<br><strong>資料處理 –&gt; 模型建置 –&gt; 模型訓練 –&gt; 模型評估 –&gt; 模型儲存</strong></p>
<p>這是我個人分出來的大項，每一項都能拿出來當一個主題細講，內容多到不行。<br>就如前面提到的，今天我要說明資料處理的一些重點，因為一切的開頭都是從資料開始進行的，不先說明就沒辦法做接下來的流程，偏偏很多網路文章都不喜歡講資料處理這塊，我不知道是太懶還是把閱讀者都當萬事通，明明這麼重要的東西，撰寫者就丟個程式碼說這是我的訓練資料製作就沒了，連個說明都沒有，這誰看的懂阿！</p>
<p>回到正題，在進行資料處理前，必須要知道資料是長什麼樣子的。<br>一般在網路上拿到的資料，都會處理成下面兩大形式：</p>
<ol>
<li>用各自類別命名的單獨資料夾中的所有圖像，A標籤的圖片全部集中在同一個資料夾中，以此類推。</li>
<li>所有圖像都存在於一個目錄中，並將圖片名稱與對應標籤寫入一個CSV或JSON文件中。</li>
</ol>
<p>我目前也只有遇到這兩大形式，這兩種形式在資料處理的時候，會有很大不同的寫法，甚至是資料增強使用的函數也會有所不同！<br>本次的資料形式是屬於第一類型，資料夾的名稱就是花的品種，資料夾內也會有對應的花圖片。</p>
<img src="/2020/09/24/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%9701-%E8%8A%B1%E5%93%81%E7%A8%AE%E8%BE%A8%E8%AD%98/pc02.jpg" class="" title="This is an image">
<p>這個環節很重要喔！判斷是哪種形式也是資料處理中很重要的一環，儘管這看起來非常簡單，特意寫出來怎麼判斷感覺很蠢，但這就是開頭。</p>
<h2 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h2><p>本文章對應的github專案，內容全是我自己寫的，歡迎大家參考，也請查看專案的 readme.md ，它會教你怎麼使用。<br>網址：<a href="https://github.com/chenchianstudent/DeepLearning_FlowerSpecies_Identification" target="_blank" rel="noopener">https://github.com/chenchianstudent/DeepLearning_FlowerSpecies_Identification</a></p>
<h2 id="實作心得"><a href="#實作心得" class="headerlink" title="實作心得"></a>實作心得</h2><h3 id="程式碼"><a href="#程式碼" class="headerlink" title="程式碼"></a>程式碼</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">print(tf.__version__)</span><br><span class="line">print(<span class="string">"本次測試標籤為:"</span>,os.listdir(<span class="string">'C:/Users/danie/flowers'</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2                  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm                </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X=[]</span><br><span class="line">Z=[]</span><br><span class="line">IMG_SIZE=<span class="number">224</span></span><br><span class="line">FLOWER_DAISY_DIR=<span class="string">'C:/Users/danie/flowers/daisy'</span></span><br><span class="line">FLOWER_SUNFLOWER_DIR=<span class="string">'C:/Users/danie/flowers/sunflower'</span></span><br><span class="line">FLOWER_TULIP_DIR=<span class="string">'C:/Users/danie/flowers/tulip'</span></span><br><span class="line">FLOWER_DANDI_DIR=<span class="string">'C:/Users/danie/flowers/dandelion'</span></span><br><span class="line">FLOWER_ROSE_DIR=<span class="string">'C:/Users/danie/flowers/rose'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">assign_label</span><span class="params">(img,flower_type)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> flower_type</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_train_data</span><span class="params">(flower_type,DIR)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> tqdm(os.listdir(DIR)):</span><br><span class="line">        label=assign_label(img,flower_type)</span><br><span class="line">        path = os.path.join(DIR,img)</span><br><span class="line">        img = cv2.imread(path,cv2.IMREAD_COLOR)</span><br><span class="line">        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))</span><br><span class="line">        </span><br><span class="line">        X.append(np.array(img))</span><br><span class="line">        Z.append(str(label))</span><br><span class="line">        </span><br><span class="line">make_train_data(<span class="string">'Daisy'</span>,FLOWER_DAISY_DIR)</span><br><span class="line">print(<span class="string">"Daisy:"</span>,len(X))</span><br><span class="line"></span><br><span class="line">make_train_data(<span class="string">'Sunflower'</span>,FLOWER_SUNFLOWER_DIR)</span><br><span class="line">print(<span class="string">"Sunflower:"</span>,len(X))</span><br><span class="line"></span><br><span class="line">make_train_data(<span class="string">'Tulip'</span>,FLOWER_TULIP_DIR)</span><br><span class="line">print(<span class="string">"Tulip:"</span>,len(X))</span><br><span class="line"></span><br><span class="line">make_train_data(<span class="string">'Rose'</span>,FLOWER_ROSE_DIR)</span><br><span class="line">print(<span class="string">"Rose:"</span>,len(X))</span><br><span class="line"></span><br><span class="line">make_train_data(<span class="string">'Dandelion'</span>,FLOWER_DANDI_DIR)</span><br><span class="line">print(<span class="string">"Dandelion:"</span>,len(X))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rn</span><br><span class="line">fig,ax=plt.subplots(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line">fig.set_size_inches(<span class="number">15</span>,<span class="number">15</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range (<span class="number">2</span>):</span><br><span class="line">        l=rn.randint(<span class="number">0</span>,len(Z))</span><br><span class="line">        ax[i,j].imshow(X[l])</span><br><span class="line">        ax[i,j].set_title(<span class="string">'Flower: '</span>+Z[l])</span><br><span class="line">        </span><br><span class="line">plt.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">le=LabelEncoder()</span><br><span class="line">Y=le.fit_transform(Z)</span><br><span class="line">Y=to_categorical(Y,<span class="number">5</span>)</span><br><span class="line">X=np.array(X)</span><br><span class="line">print(type(X))</span><br><span class="line">print(X.shape)</span><br><span class="line">print(len(X))</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">rn.seed(<span class="number">42</span>)</span><br><span class="line">tf.set_random_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">X=X/<span class="number">255</span></span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=<span class="number">0.25</span>,random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam,SGD,Adagrad,Adadelta,RMSprop</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(filters = <span class="number">32</span>, kernel_size = (<span class="number">5</span>,<span class="number">5</span>),padding = <span class="string">'Same'</span>,activation =<span class="string">'relu'</span>, input_shape = (<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters = <span class="number">64</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>),padding = <span class="string">'Same'</span>,activation =<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters =<span class="number">96</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>),padding = <span class="string">'Same'</span>,activation =<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters = <span class="number">96</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>),padding = <span class="string">'Same'</span>,activation =<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">512</span>))</span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">5</span>, activation = <span class="string">"softmax"</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,loss=<span class="string">'categorical_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ReduceLROnPlateau</span><br><span class="line">red_lr= ReduceLROnPlateau(monitor=<span class="string">'val_acc'</span>,patience=<span class="number">3</span>,verbose=<span class="number">1</span>,factor=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">        featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">        samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">        featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">        samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">        zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">        rotation_range=<span class="number">10</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">        zoom_range = <span class="number">0.1</span>, <span class="comment"># Randomly zoom image </span></span><br><span class="line">        width_shift_range=<span class="number">0.2</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">        height_shift_range=<span class="number">0.2</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">        horizontal_flip=<span class="literal">True</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">        vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">datagen.fit(x_train)</span><br><span class="line"></span><br><span class="line">History = model.fit(x_train,</span><br><span class="line">                    y_train, </span><br><span class="line">                    batch_size=<span class="number">20</span>,</span><br><span class="line">                    epochs = <span class="number">10</span>, </span><br><span class="line">                    validation_data = (x_test,y_test),</span><br><span class="line">                    verbose = <span class="number">1</span>,</span><br><span class="line">                    <span class="comment">#callbacks = red_lr</span></span><br><span class="line">                   )</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curves</span><span class="params">(History)</span>:</span></span><br><span class="line">    pd.DataFrame(History.history).plot(figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    plt.gca().set_ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">plot_learning_curves(History)</span><br></pre></td></tr></table></figure>
<p>大…大哥！你不是說只是範例程式碼的變化而已嗎？範例程式也才15行左右，怎麼瞬間迸出了這麼多行！？我是不是上賊船了？？<br>冷…冷靜！真的只是變化而已，只是我不小心寫多了！有些小技巧想告訴大家，因此多了些函數，另外資料處理這塊應該是多最多行的，原因是之前的Mnist資料集在import進來時就處理好了，你只要呼叫就好，這次則是要重新處理，所以才會比較多。</p>
<p>一樣我會分段進行解釋，但是上一篇我有說過的東西會草草帶過，因為重新解釋的話，會多很多不必要的廢話，導致文章過長。</p>
<h3 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">print(tf.__version__)</span><br><span class="line">print(<span class="string">"本次測試標籤為:"</span>,os.listdir(<span class="string">'C:/Users/danie/flowers'</span>))</span><br></pre></td></tr></table></figure>
<p>很簡單的確認版本程式碼。<br>這次我多import了os這個函式庫，目的是來抓取本地資料，因為這次主題就是用手上的資料。<br><code>print(os.listdir(&#39;欲輸入的位置&#39;))</code>用來查看這個位置有什麼資料夾的名稱，也算是另類的標籤類別確認。</p>
<p>output：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.14.0</span><br><span class="line">本次測試標籤為: [&#39;daisy&#39;, &#39;dandelion&#39;, &#39;rose&#39;, &#39;sunflower&#39;, &#39;tulip&#39;]</span><br></pre></td></tr></table></figure>
<h3 id="第二部分"><a href="#第二部分" class="headerlink" title="第二部分"></a>第二部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2                  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm               </span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> shuffle  </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">X=[]</span><br><span class="line">Z=[]</span><br><span class="line">IMG_SIZE=<span class="number">224</span></span><br><span class="line">FLOWER_DAISY_DIR=<span class="string">'C:/Users/danie/flowers/daisy'</span></span><br><span class="line">FLOWER_SUNFLOWER_DIR=<span class="string">'C:/Users/danie/flowers/sunflower'</span></span><br><span class="line">FLOWER_TULIP_DIR=<span class="string">'C:/Users/danie/flowers/tulip'</span></span><br><span class="line">FLOWER_DANDI_DIR=<span class="string">'C:/Users/danie/flowers/dandelion'</span></span><br><span class="line">FLOWER_ROSE_DIR=<span class="string">'C:/Users/danie/flowers/rose'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">assign_label</span><span class="params">(img,flower_type)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> flower_type</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_train_data</span><span class="params">(flower_type,DIR)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> tqdm(os.listdir(DIR)):</span><br><span class="line">        label=assign_label(img,flower_type)</span><br><span class="line">        path = os.path.join(DIR,img)</span><br><span class="line">        img = cv2.imread(path,cv2.IMREAD_COLOR)</span><br><span class="line">        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))</span><br><span class="line">        </span><br><span class="line">        X.append(np.array(img))</span><br><span class="line">        Z.append(str(label))</span><br></pre></td></tr></table></figure>
<p>import的部分我稍稍提一下就好，基本上在做深度學習的時候，有幾個函式庫很常import進來，比如cv2和numpy。</p>
<ul>
<li>tqdm：可以在 Python 長迴圈中新增進度提示資訊，讓你有個進度條確認。</li>
<li>numpy：一個開源的python科學計算函式庫，許多常見有名的科學計算函式庫都會用上Numpy的一些功能，例如Pandas、Scikit-learn等。簡言之：很常用！  但因為要細講可以寫一篇文章，因此我這邊簡略說明。</li>
<li>cv2：全名叫openCV，程式撰寫時簡稱cv2。cv2專門處理圖像的函式庫，在深度學習中，與Numpy很常在組合進行撰寫。</li>
<li>PIL：python中比較有名的影像處理套件，可以用來轉檔、調色、濾鏡、浮水印甚至創造圖等功能，而且可以批次處理大量的檔案。</li>
</ul>
<p><code>X=[]
Z=[]</code>宣告這兩個陣列是用來儲存圖片資料和標籤類別的。<br><code>IMG_SIZE</code>則是圖片大小的設定<br>剩下的<code>FLOWER_XXXXX_DIR</code>是紀錄花的各品種圖片資料夾位置，注意不用在最後面加上”/“。</p>
<p>這裡我宣告了兩個函式”assign_label”和”make_train_data”。<br>assign_label是用來返回花品種的，等等用在make_train_data這個函式裡，因為花不是只有一種，然後make_train_data函式會用在所有的品種處裡上，故無法寫死品種這一塊，這時就需要靠assign_label函式來判斷這個圖片屬於哪種品種。</p>
<p>make_train_data用來製作訓練資料的函式，首先我們要輸入花品種和該品種的圖片資料夾位置，接著就會將資料夾裡的圖片依序抓出來做處裡(調整大小、資料型態轉numpy等…)，最後圖片資料加入X陣列，而標籤類別則加進Y陣列。</p>
<h3 id="第三部分"><a href="#第三部分" class="headerlink" title="第三部分"></a>第三部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">make_train_data(<span class="string">'Daisy'</span>,FLOWER_DAISY_DIR)</span><br><span class="line">print(<span class="string">"Daisy:"</span>,len(X))</span><br><span class="line"></span><br><span class="line">make_train_data(<span class="string">'Sunflower'</span>,FLOWER_SUNFLOWER_DIR)</span><br><span class="line">print(<span class="string">"Sunflower:"</span>,len(X))</span><br><span class="line"></span><br><span class="line">make_train_data(<span class="string">'Tulip'</span>,FLOWER_TULIP_DIR)</span><br><span class="line">print(<span class="string">"Tulip:"</span>,len(X))</span><br><span class="line"></span><br><span class="line">make_train_data(<span class="string">'Rose'</span>,FLOWER_ROSE_DIR)</span><br><span class="line">print(<span class="string">"Rose:"</span>,len(X))</span><br><span class="line"></span><br><span class="line">make_train_data(<span class="string">'Dandelion'</span>,FLOWER_DANDI_DIR)</span><br><span class="line">print(<span class="string">"Dandelion:"</span>,len(X))</span><br></pre></td></tr></table></figure>
<p>這一段就是直接對每種品種進行訓練資料的處理，用的是第二部分<code>make_train_data</code>函式。<br>output：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">100%|███████████████████████████████████████████████████████████████████████████████| 984&#x2F;984 [00:06&lt;00:00, 142.48it&#x2F;s]</span><br><span class="line">Tulip: 2487</span><br></pre></td></tr></table></figure>
<p>我拿其中一段做展示，出現進度條原因是我在make_train_data函式裡有用上tqdm，讓你的output帥一點。</p>
<h3 id="第四部份"><a href="#第四部份" class="headerlink" title="第四部份"></a>第四部份</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rn</span><br><span class="line">fig,ax=plt.subplots(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line">fig.set_size_inches(<span class="number">15</span>,<span class="number">15</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range (<span class="number">2</span>):</span><br><span class="line">        l=rn.randint(<span class="number">0</span>,len(Z))</span><br><span class="line">        ax[i,j].imshow(X[l])</span><br><span class="line">        ax[i,j].set_title(<span class="string">'Flower: '</span>+Z[l])</span><br><span class="line">        </span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>
<p>這段程式碼是用來確認和一些圖片呈現的小技術，對深度學習訓練本身沒有甚麼大影響。<br>先給各位看output比較明白：</p>
<img src="/2020/09/24/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%9701-%E8%8A%B1%E5%93%81%E7%A8%AE%E8%BE%A8%E8%AD%98/pc01.JPG" class="" title="This is an image">

<p><code>fig,ax=plt.subplots(5,2)</code>顯告output要以怎樣的形式呈現(列，行)，像上面的output呈現不是一行2張嗎？就是在這裡設定的。而5列因為截圖關係，我只截到3列，正確的output會是5列，這點請多多包涵，總之概念有傳達到。<br><code>fig.set_size_inches(15,15)</code>則是output時，每張圖片呈現的大小，跟之前我們對圖片做的resize不同喔！之前做的是模型讀入時的調整大小，而這裡純粹是在jupyter notebook上output時的大小調整，實質上對圖片沒有任何修改。</p>
<p>接下來的for迴圈我應該不用說明吧？很簡單的邏輯，因為我們的列行設定5跟2，所以for迴圈的i和j設定就是5和2。<br>剩下就是圖片呈現出來的設定，圖片抓取是靠亂數抓去，因此每次抓取都會是不同的圖片，這段多RUN幾次大概就知道了。</p>
<p>最後就是靠<code>plt.tight_layout()</code>output出來。</p>
<h3 id="第五部分"><a href="#第五部分" class="headerlink" title="第五部分"></a>第五部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">le=LabelEncoder()</span><br><span class="line">Y=le.fit_transform(Z)</span><br><span class="line">Y=to_categorical(Y,<span class="number">5</span>)</span><br><span class="line">X=np.array(X)</span><br><span class="line">print(type(X))</span><br><span class="line">print(X.shape)</span><br><span class="line">print(len(X))</span><br></pre></td></tr></table></figure>
<p>這部分偏這次資料處理的重點了。<br>有一個概念是上次沒有遇到的，叫Encoding。<br>這個概念很簡單，假如今天有類別是A、B、C這三種。<br>那Encoding則是將這三種類別轉成陣列0跟1的形式，變成：<br>A —&gt; [ 1 , 0 , 0 ]<br>B —&gt; [ 0 , 1 , 0 ]<br>C —&gt; [ 0 , 0 , 1 ]<br>為什麼要這樣做？因為機器看不懂英文單字或詞。<br>上次Mnist沒這樣做是因為數字辨識的結果就是0-9，是數字，因此不太需要做Encoding。而這次因為辨識結果是英文單詞，所以才需要做這件事情。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">le=LabelEncoder()</span><br><span class="line">Y=le.fit_transform(Z)</span><br><span class="line">Y=to_categorical(Y,<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>這裡就是在做Encoding，宣告一個Y將Z陣列放進去，最後再將Y進行Encoding。<br><code>X=np.array(X)</code>是將X陣列的屬性轉乘ndarray形式。<br>到這裡型態處理就告一段了。</p>
<p>如果對這些型態的轉變還是有不少疑慮，不知道到底有沒有轉成功，可以嘗試使用下面程式碼去確認，對比轉換前後的樣子有什麼不同，可能在理解上會有更好的幫助。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(type(X)) <span class="comment"># 查看X的型態</span></span><br><span class="line">print(X.shape) <span class="comment"># 查看X的數組大小</span></span><br><span class="line">print(len(X))  <span class="comment"># 查看X的長度</span></span><br><span class="line">print(Y[<span class="number">1</span>]) <span class="comment"># 查看Y陣列第2個位置的內容</span></span><br><span class="line">print(Z[<span class="number">1</span>]) <span class="comment"># 查看Z陣列第2個位置的內容</span></span><br></pre></td></tr></table></figure>
<p>output：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &#39;numpy.ndarray&#39;&gt;</span><br><span class="line">(4323, 224, 224, 3)</span><br><span class="line">(224, 224, 3)</span><br><span class="line">[1. 0. 0. 0. 0.]</span><br><span class="line">Daisy</span><br></pre></td></tr></table></figure>
<p>我只列幾個比較重要的查看方式，不是所有的喔！還請自行變化做判斷。</p>
<h3 id="第六部分"><a href="#第六部分" class="headerlink" title="第六部分"></a>第六部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">rn.seed(<span class="number">42</span>)</span><br><span class="line">tf.set_random_seed(<span class="number">42</span>)</span><br><span class="line">X=X/<span class="number">255</span></span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=<span class="number">0.25</span>,random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<p><code>X=X/255</code>做歸一化，上次有說明了。<br><code>x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)</code>是用來劃分我們剛剛處理好的資料，哪些要當訓練資料、哪些要當驗證資料。<br>上次的文章也有用到類似的程式碼，透過<code>train_test_split()</code>先載入X陣列的圖片和Y陣列的標籤，再用<code>test_size</code>進行劃分。0.25意即X陣列總數的25%當驗證資料。<br>後面有個<code>random_state=42</code>是來隨機抓取圖片的應用，剛剛我們不是設定數量的25%當驗證資料嗎？照理來說，如果沒有加亂數處理，劃分時會按照順序去取比例，加上亂數後，劃分就會變為依比例隨機抓圖片，不會永遠是編號1-75是訓練資料，編號76-100是驗證資料。<br>這樣做有什麼原因嗎？有的喔！如果是直接按照順序劃分的話，會怕機器訓練時讀取圖片，一次都讀到相同類別的圖片，這種狀況機器做辨識時會有 “阿這一塊都是類別A，表示編號<strong>~編號</strong>這段就都會是A類別” 的想法而納入特徵關鍵點，為了避免機器去產生這種想法，所以保險點會加個亂數讓機器去抓圖片。</p>
<h3 id="第七部分"><a href="#第七部分" class="headerlink" title="第七部分"></a>第七部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam,SGD,Adagrad,Adadelta,RMSprop</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(filters = <span class="number">32</span>, kernel_size = (<span class="number">5</span>,<span class="number">5</span>),padding = <span class="string">'Same'</span>,activation =<span class="string">'relu'</span>, input_shape = (<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters = <span class="number">64</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>),padding = <span class="string">'Same'</span>,activation =<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters =<span class="number">96</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>),padding = <span class="string">'Same'</span>,activation =<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters = <span class="number">96</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>),padding = <span class="string">'Same'</span>,activation =<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">512</span>))</span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">5</span>, activation = <span class="string">"softmax"</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,loss=<span class="string">'categorical_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>相信大家都知道這裡在做什麼了，就是模型的建置和函數調整。<br>裡面有幾層是上次文章沒講過的東西。這次我呢……沒有打算講w<br>原因是我打算當下一篇文章的主題，這種模型叫”CNN模型”，是非常有名的深度學習模型。<br>因為太有名，如果CNN草草帶過的話，那就不用學深度學習了。因此這裡就先讓各位知道這是建立模型就好，你可以改成上篇文章的模型也沒關係，一樣都能RUN起來。</p>
<h3 id="第八部分"><a href="#第八部分" class="headerlink" title="第八部分"></a>第八部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">        featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">        samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">        featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">        samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">        zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">        rotation_range=<span class="number">10</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">        zoom_range = <span class="number">0.1</span>, <span class="comment"># Randomly zoom image </span></span><br><span class="line">        width_shift_range=<span class="number">0.2</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">        height_shift_range=<span class="number">0.2</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">        horizontal_flip=<span class="literal">True</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">        vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">datagen.fit(x_train)</span><br></pre></td></tr></table></figure>
<p>這個部分可以pass掉，這裡的內容偏中期才需要讀的東西，叫”<a href="https://chenchianstudent.github.io/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/" target="_blank" rel="noopener">資料增強</a>“。文章我有先寫完了，感興趣的話可以看看！</p>
<h3 id="第九部分"><a href="#第九部分" class="headerlink" title="第九部分"></a>第九部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">History = model.fit(x_train,</span><br><span class="line">                    y_train, </span><br><span class="line">                    batch_size=<span class="number">20</span>,</span><br><span class="line">                    epochs = <span class="number">10</span>, </span><br><span class="line">                    validation_data = (x_test,y_test),</span><br><span class="line">                    verbose = <span class="number">1</span>,</span><br><span class="line">                    <span class="comment">#callbacks = red_lr</span></span><br><span class="line">                   )</span><br></pre></td></tr></table></figure>
<p>模型訓練。<br><code>validation_data = (x_test,y_test)</code>是驗證資料的應用。它會在每一次訓練結束時，用驗證資料去評估這次訓練完成的模型正確率能達到多少。<br>output：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Train on 3242 samples, validate on 1081 samples</span><br><span class="line">Epoch 1&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 20s 6ms&#x2F;sample - loss: 1.3169 - acc: 0.4377 - val_loss: 1.0855 - val_acc: 0.5615</span><br><span class="line">Epoch 2&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 19s 6ms&#x2F;sample - loss: 1.0262 - acc: 0.5910 - val_loss: 0.9683 - val_acc: 0.6161</span><br><span class="line">Epoch 3&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 18s 6ms&#x2F;sample - loss: 0.8734 - acc: 0.6678 - val_loss: 0.9812 - val_acc: 0.6383</span><br><span class="line">Epoch 4&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 18s 6ms&#x2F;sample - loss: 0.7239 - acc: 0.7304 - val_loss: 0.9805 - val_acc: 0.6494</span><br><span class="line">Epoch 5&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 18s 6ms&#x2F;sample - loss: 0.5176 - acc: 0.8091 - val_loss: 1.0303 - val_acc: 0.6485</span><br><span class="line">Epoch 6&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 18s 6ms&#x2F;sample - loss: 0.3354 - acc: 0.8831 - val_loss: 1.3695 - val_acc: 0.6475</span><br><span class="line">Epoch 7&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 18s 6ms&#x2F;sample - loss: 0.2050 - acc: 0.9300 - val_loss: 1.7195 - val_acc: 0.6263</span><br><span class="line">Epoch 8&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 18s 6ms&#x2F;sample - loss: 0.1331 - acc: 0.9562 - val_loss: 2.0495 - val_acc: 0.6263</span><br><span class="line">Epoch 9&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 18s 6ms&#x2F;sample - loss: 0.0754 - acc: 0.9790 - val_loss: 2.1570 - val_acc: 0.6401</span><br><span class="line">Epoch 10&#x2F;10</span><br><span class="line">3242&#x2F;3242 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 18s 6ms&#x2F;sample - loss: 0.0620 - acc: 0.9809 - val_loss: 2.2967 - val_acc: 0.6244</span><br></pre></td></tr></table></figure>
<p>是不是有看到叫<code>val_acc</code>的地方？在訓練時<code>val_acc</code>不會出現，訓練完一輪後才會出現，它提供這個模型訓練完成後實際上的正確效果，平常我們只看<code>acc</code>是不太準的，因為它只評估這些訓練資料我讀熟了沒，是不是能完全分類正確這些訓練資料。以人的生活行為來比喻的話，有點像應付考試而去背完所有的重點，也許那場考試你拿到很高分，但是下次同樣主題但不同題型考試時，就不一定會拿到這麼高分了。而這時候驗證資料就會是一個很好的參考點，可以評估這個模型是否overfitting，或是還有繼續訓練的空間，亦或是建立的模型是不是不適合等…..</p>
<h3 id="延伸部分"><a href="#延伸部分" class="headerlink" title="延伸部分"></a>延伸部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curves</span><span class="params">(History)</span>:</span></span><br><span class="line">    pd.DataFrame(History.history).plot(figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    plt.gca().set_ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">plot_learning_curves(History)</span><br></pre></td></tr></table></figure>
<p>覺得看數字去評估訓練結果不舒服嗎？可不可以用圖片呈現模型的訓練狀況？<br>恭喜你！這個部分就是教你做圖片呈現的應用。<br>在網路上查，應該很多都會叫你用上tensorboard，這個解答算對拉！畢竟tensorboard比較詳細。<br>但這次要教的，不用tensorboard就可以達到模型評估的情形。同樣都能達到評估效果，何必再多花心思去搞tensorboard呢？<br>這次會用到pandas這個函式庫。<br>然後函式照我<code>plot_learning_curves</code>寫上去就好了，這樣就會幫你畫出來了。<br>output：</p>
<img src="/2020/09/24/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%9701-%E8%8A%B1%E5%93%81%E7%A8%AE%E8%BE%A8%E8%AD%98/pc03.JPG" class="" title="This is an image">

<p>提醒一下！History是訓練時我有事先宣告的變數，是紀錄每次訓練的情形用的，目的也是為了做畫圖而去宣告的。</p>
<h2 id="結尾"><a href="#結尾" class="headerlink" title="結尾"></a>結尾</h2><p>這次的實作心得就告一段落了。不難吧？真的就是範例程式的變化而已，個人認為難在資料處理，因為這是一個全新的東西，沒有基礎概念會很難下手，而且不是每個人都有這個概念，像我就是，第一次學的時候我完全不知道從何下手，即使我知道簡單的模型要怎麼建，但不會讓資料處理就完全沒有發揮的地方，所以第二集會非常focus在資料要怎麼處理，也希望這樣有幫助到大家。下一集沒意外就是補充這篇文章沒有說明的CNN，這是一個很重要的一章，希望我的文筆能夠清楚表達CNN是什麼lol</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/">資料增強imageGenerator使用心得</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-21T06:11:58.000Z" itemprop="datePublished">
    2020-09-21
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">實作心得</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/jupyter-notebook/">jupyter notebook</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h2 id="資料增強-Image-Generator-使用心得"><a href="#資料增強-Image-Generator-使用心得" class="headerlink" title="資料增強(Image Generator)使用心得"></a>資料增強(Image Generator)使用心得</h2><h2 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h2><p>記錄我在研究所學習深度學習的知識與心得。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明如何利用Keras的Image Generator來進行資料擴增。<br>文中會說明資料增強是什麼？<br>flow、flow_from_directory、fit以及flow_from_dataframe的使用。</p>
<h2 id="前置步驟-amp-注意事項"><a href="#前置步驟-amp-注意事項" class="headerlink" title="前置步驟&amp;注意事項"></a>前置步驟&amp;注意事項</h2><ol>
<li>本次心得比較特殊一點，重心在keras而已，tensorflow比較偏延伸應用向，但因為教學心得寫文章關係，因此我會帶點tensorflow。</li>
<li>我必須強調一下，本人在寫這篇文章時還是學習中的學生，算是初心者。內容若是有錯，誤導大家還請多多包涵！之後發現自己有說錯話，也會去重新修文章，你發現我有說錯的話，也請告訴我哪裡錯了，email和FB應該都在我首頁裡，不好意思麻煩老手了。</li>
<li>資料增強其實算是學習中期才需要看的文章，初學者可以先跳過這篇文章，會提早寫主要是因為我剛好又深入一次資料增強，趁記憶猶新馬上來寫一下，以免日後想到要寫這篇文章時，已經忘得一乾二淨。</li>
<li>什麼是深度學習？請參考這篇<a href="https://chenchianstudent.github.io/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/" target="_blank" rel="noopener">文章</a></li>
</ol>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>要訓練一個高正確率且泛用的模型，除了需要琢磨模型本身的架構之外，龐大的資料來讓我們去訓練也是一個重大關鍵。<br>今天我們不來討論模型結構這種比較偏數學且核心的問題，我們來討論「資料」這一塊。<br>在進行深度學習處理資料這一塊，我們最終極的目標就是將訓練資料轉變成模型可以讀取的形式。但是在模型讀取資料前，其實有很多小細節可以做，做了會怎樣？不外乎就是讓模型正確率再提高一點，或是將模型的訓練時間縮短。今天要講的「資料增強」就是這個小細節的一環，現在深度學習的比賽或是實例上，不少人都會用上資料增強，這是一個提高正確率不可或缺的手段。</p>
<h2 id="什麼是資料增強-Data-Augmentation-？"><a href="#什麼是資料增強-Data-Augmentation-？" class="headerlink" title="什麼是資料增強(Data Augmentation)？"></a>什麼是資料增強(Data Augmentation)？</h2><h3 id="一言以蔽之：製造假資料來騙機器說這是份新數據，請拿去訓練。"><a href="#一言以蔽之：製造假資料來騙機器說這是份新數據，請拿去訓練。" class="headerlink" title="一言以蔽之：製造假資料來騙機器說這是份新數據，請拿去訓練。"></a><strong>一言以蔽之：製造假資料來騙機器說這是份新數據，請拿去訓練。</strong></h3><p>前言我們有提到，除了對模型架構下功夫來提高正確率外，龐大的資料也是提高正確率最不可或缺的關鍵。我們訓練的資料越多、越完整，模型就能表現得越好！但一般來說，資料的收集往往是最大的痛點，收集資料比起改變模型結構，要來的困難許多。假如今天在資料有限的狀況下，又該如何創造新的資料呢？沒錯！最直接的方式就是進行資料增強！資料增強最主要的目的，就是透過一些”手法”來將一張圖擴增至2張以上，今天我手上有1000張圖片，那我就可以將數量增加到2000張甚至更多，比起1000張來進行訓練，2000張訓練出來的結果一定比較好！</p>
<img src="/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/pc03.png" class="" title="This is an image">
<p>(<a href="https://chtseng.wordpress.com/2017/11/11/data-augmentation-%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7/" target="_blank" rel="noopener">圖源</a>—&gt;因為我覺得這張圖呈現的很貼切，因此就引用了該網站的圖片來當圖片參考，這個人寫的也很不錯，歡迎參考他的文章內容)<br>這裡可能會有個疑問，同一張圖無論分裂幾百次，不都是同一張圖片嗎？這樣有意義？<br>答案是有意義的。在人類眼裡，這種行為是無意義的沒錯，因為不管怎麼看都是一樣的東西，是能變化出什麼花樣？但在機器眼裡，他就是一份新數據，機器去判斷不是靠肉眼，是靠一連串的計算和數字。因此這種「假」資料可以算一份訓練資料。</p>
<p>假歸假，這種假數據還是要靠特別的”手法”來騙過機器，而不是隨便從原圖複製幾張就行。<br>增強手法有很多種，常見的增強手法主要是靠旋轉、裁切、增加噪點、白化、拉長、放大縮小等…..，另外也有人特意去研究增強手法來當論文主題，因此每一天都有可能出現新的手法來騙機器。</p>
<h2 id="如何做資料增強？"><a href="#如何做資料增強？" class="headerlink" title="如何做資料增強？"></a>如何做資料增強？</h2><h3 id="一、了解增強手法"><a href="#一、了解增強手法" class="headerlink" title="一、了解增強手法"></a>一、了解增強手法</h3><p>首先回到一個根本的問題，為什麼要做資料增強？主要原因是資料取得不易，收集下來可能只有幾十張幾百張，無法訓練出好的模型，所以才會誕生出資料資強這種手段！<br>因此資料的收集還請做明確且不要馬虎，不要只拍個幾張圖片，然後用資料增強增加到1000張，這樣做的結果不會讓你正確率拉高，還可能會overfitting。資料增強不是資料處理的萬能解藥，這點還請多多注意！</p>
<p>本篇文章是用python語言裡的Keras Image Generator來進行。<br>現在網上查的文章，如果沒指定特定程式語言，大多都是用python來進行深度學習，我在學習也是用python，因此文章幾乎是用python語言寫的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">img_gen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>這段程式碼主要做的事情是來設定資料增強的手法。<br><code>from keras.preprocessing.image import ImageDataGenerator</code>是用來import我們需要的函式庫<br><code>img_gen = ImageDataGenerator(  )</code>的img_gen是變數，可以隨意取名字。<code>ImageDataGenerator(  )</code>則是我們設定資料增強的地方，(  )內填寫你需要的手法。</p>
<p>增強的手法怎麼設定?Keras官方文檔給出了不少手法供你設定，我一一列舉出來(親手整理的，沒有複製貼上喔~)：</p>
<ol>
<li>featurewise_center:<br>將輸入的資料均值設為0，並依特徵進行。使用布林值(True or False)</li>
<li>samplewise_center:<br>將每個樣本的均值設置為0。使用布林值(True or False)</li>
<li>featurewise_std_normalization:<br>將輸入的數據除以標準差，並依特徵進行。使用布林值(True or False)</li>
<li>samplewise_std_normalization:<br>將每個輸入的數據除以標準差。使用布林值(True or False)</li>
<li>zca_epsilon:<br>圖片白化。值默認為：1e-6。</li>
<li>zca_whitening:<br>是否要應用 ZCA 白化。使用布林值(True or False)</li>
<li>rotation_range:<br>隨機旋轉圖片的度數範圍。只接受整數數值</li>
<li>width_shift_range:<br>圖片寬度的某個比例，數據提升時圖片水平偏移的幅度。使用浮點數、一維數列或整数。<ul>
<li>float: 如果 &lt;1，則是除以總寬度的值，或者 &gt;=1，則為像素值。</li>
<li>1-D 數列: 數列中的隨機元素。</li>
<li>int: 來自間隔 (-width_shift_range, +width_shift_range) 之間的整數各像素。width_shift_range=2 時，可能值是整數 [-1, 0, +1]，與 width_shift_range= [-1, 0, +1] 相同；而 width_shift_range=1.0 時，可能值是 [-1.0, +1.0) 之間的浮點數。</li>
</ul>
</li>
<li>height_shift_range:<br>圖片長度的某個比例，數據提升時圖片水平偏移的幅度。使用浮點數、一維數列或整数。<ul>
<li>float: 如果 &lt;1，則是除以總寬度的值，或者 &gt;=1，則為像素質。</li>
<li>1-D 數列: 數列中的隨機元素。</li>
<li>int: 來自間隔 (-width_shift_range, +width_shift_range) 之間的整數各像素。width_shift_range=2 時，可能值是整數 [-1, 0, +1]，與 width_shift_range= [-1, 0, +1] 相同；而 width_shift_range=1.0 時，可能值是 [-1.0, +1.0) 之間的浮點數。</li>
</ul>
</li>
<li>shear_range:<br>剪切強度（逆時針方向的剪切變換角度）。使用浮點數。</li>
<li>zoom_range:<br>浮點數 或 [lower, upper]。隨機縮放範圍。<br>如果是浮點數，[lower, upper] = [1-zoom_range, 1+zoom_range]。</li>
<li>channel_shift_range:<br>隨機通道轉換的範圍。使用浮點數。</li>
<li>fill_mode:<br>當進行變換時超出邊界的點將根據本參數給定的方法進行處理：<br>{“constant”, “nearest”, “reflect” or “wrap”} 之一。默認為nearest。<ul>
<li>constant: kkkkkkkk|abcd|kkkkkkkk (cval=k)</li>
<li>nearest: aaaaaaaa|abcd|dddddddd</li>
<li>reflect: abcddcba|abcd|dcbaabcd</li>
<li>wrap: abcdabcd|abcd|abcdabcd</li>
</ul>
</li>
<li>cval:<br>用於邊界之外點的值。使用浮點數或整數。</li>
<li>horizontal_flip:<br>隨機水平翻轉。使用布林值(True or False)。</li>
<li>vertical_flip:<br>随機垂直翻轉。使用布林值(True or False)</li>
<li>rescale:<br>重新縮放因子。默認為 None。<br>如果是 None 或 0，則不進行縮放，否則將數據乘上所提供的值（在任何應用其他轉化之前）。</li>
<li>preprocessing_function:<br>應用於每個輸入的函數。這個函數會在任何其他改變之前運行。<br>這個函數需要一個參數：一張圖片（亦為 3 的 Numpy 張量），並且應該輸出一個同尺存的Numpy張量。</li>
<li>data_format:<br>圖像數據格式，{“channels_first”, “channels_last”} 之一。<br>“channels_last” 模式表示圖像輸入尺寸應該為 (samples, height, width, channels)，”channels_first” 模式表示輸入尺寸應該為 (samples, channels, height, width)。<br>默認為在 Keras 配置文件 ~/.keras/keras.json 中的 image_data_format 值。如果你未設置，那它就是 “channels_last”。</li>
<li>validation_split:<br>保留用於驗證的圖像比例（基本上是0-1之間）。使用浮點數</li>
<li>dtype:<br>生成數組用的數據類型。</li>
</ol>
<p>我知道一定有人沒看完，打那麼多字誰要看阿！對！是我也會放棄觀看。<br>能設定的東西是真的很多，而且有些設定十分的抽象，沒有實際的範例我想也很難懂，但相信我，在實作上用到的就那幾個，不用馬上去搞懂所有的設定，至於常用是哪幾個，應該就旋轉、裁切、增加噪點、白化、拉長、放大縮小等…..就這幾個手法在做，第一次接觸增強也可以只先做這幾種就好，等真的熟了再去嘗試其他的也不遲。<br><strong>題外話</strong><br>“資料增強時要用什麼手段”比較偏習慣和今天要學習的主題去做變化居多，如果第一次接觸沒有方向的話，建議去kaggle找別人的notebook看看，看多了就會發現大家常用的是哪幾個。我自己常用的就是上面那段程式碼裡面的設定，就給你們參考看看。</p>
<h3 id="二、flow、flow-from-directory、fit以及flow-from-dataframe的使用"><a href="#二、flow、flow-from-directory、fit以及flow-from-dataframe的使用" class="headerlink" title="二、flow、flow_from_directory、fit以及flow_from_dataframe的使用"></a>二、flow、flow_from_directory、fit以及flow_from_dataframe的使用</h3><p>做完上面的設定後，接著就是把這些手法套用至圖片上。<br>在套用前，我們必須要判斷一件事：你的訓練資料在處理前，是以什麼樣的形式呈現的？<br>我們在網路上找到的資料集大多有兩種形式：</p>
<ol>
<li>用各自類名命名的單獨資料夾中的所有圖像，A標籤的圖片全部集中在同一個資料夾中，以此類推。</li>
<li>所有圖像都存在於一個目錄中，並將圖片名稱與對應標籤寫入一個CSV或JSON文件中。</li>
</ol>
<p>這兩大類對資料處裡的方法會有所不同，這就是需要判斷的原因。<br>另外也關係到你接下來要用什麼樣的函數去進行資料增強，也就是文章的第二主題《flow、flow_from_directory、fit以及flow_from_dataframe的使用》，每個函數都有不太相同的使用時機，我自己也不是100%全熟，但我會把我目前用到的，介紹給各位。</p>
<p>※ 以下我會用數據生成器來代替”將資料增強手法套用至圖片”這個行為<br><strong>fit</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fit(x, </span><br><span class="line">    augment=<span class="literal">False</span>, </span><br><span class="line">    rounds=<span class="number">1</span>, </span><br><span class="line">    seed=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>將數據生成器套用至特定的數據上。<br>通常會用fit主要是圖片資料已經轉換成模型可以讀取的形式了(Numpy)，接著對這些數據套用fit就會幫你將這些資料進行增強。</p>
<ul>
<li>x：樣本數據，也就是這裡填寫你要增強的數據。</li>
<li>augment：是否隨機對數據進行增強。使用布林值(True or False)</li>
<li>rounds: 當 augment 為True，對該圖片要增強幾次。</li>
<li>seed: 使用種子碼隨機。</li>
</ul>
<p>下面是我寫程式時有用到fit的片段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>])</span><br><span class="line">datagen.fit(x_train)   &lt;---------這個地方</span><br><span class="line">x_train = x_train/<span class="number">255</span></span><br><span class="line">x_test = x_test/<span class="number">255</span></span><br><span class="line">x_val = x_val/<span class="number">255</span></span><br><span class="line">print(<span class="string">'rescale！done!'</span>)</span><br></pre></td></tr></table></figure>
<p>x_train是我的圖片訓練資料集，而下面的/255是在做歸一化，之前的文章有講到，這次就不多說了。</p>
<h3 id="flow"><a href="#flow" class="headerlink" title="flow"></a>flow</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">flow(x, </span><br><span class="line">     y=<span class="literal">None</span>, </span><br><span class="line">     batch_size=<span class="number">32</span>, </span><br><span class="line">     shuffle=<span class="literal">True</span>, </span><br><span class="line">     sample_weight=<span class="literal">None</span>, </span><br><span class="line">     seed=<span class="literal">None</span>, </span><br><span class="line">     save_to_dir=<span class="literal">None</span>, </span><br><span class="line">     save_prefix=<span class="string">''</span>, </span><br><span class="line">     save_format=<span class="string">'png'</span>, </span><br><span class="line">     subset=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>透過數據生成器可以將numpy的數組和標籤，進行批量的資料增強。<br>用法比較像fit的加強版。fit是對特定的數組進行增強，而flow除了做到fit的工作外，還能批量進行，並且還加上儲存的功能。</p>
<ul>
<li>x：樣本數據，也就是這裡填寫你要增強的數據。</li>
<li>y：標籤</li>
<li>batch_size: 批量數據的尺寸，默認為32。</li>
<li>shuffle: 是否混洗數據，講白點就是亂數打亂，默認為True。</li>
<li>save_to_dir: 是否要保存增強後的圖片，是的話填入要保存的路徑，默認為None。</li>
<li>save_prefix: 保存圖片的名稱前綴。</li>
<li>save_format: 二選一 “png” &amp; “jpeg” ，默認為”png”。</li>
<li>yields: 形如(x,y)的tuple，x是代表圖像數據的numpy數組，y是代表標籤的numpy數組。</li>
<li>seed: 是否用種子碼打亂數據。</li>
</ul>
<p>flow的使用是我這4個要介紹的數據生成器中，唯一沒使用過的生成器。<br>不過我在網上有找到不少範例，我用範例有稍微改了一下，應該可以Run起來的，自己測試還可以。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">img_gen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 將圖片轉成array並儲存至l陣列，再將l陣列轉成numpy</span></span><br><span class="line">l=[]</span><br><span class="line">img01 = load_img(<span class="string">r"圖片路徑/00001.jpg"</span>)  </span><br><span class="line">img02 = load_img(<span class="string">r"圖片路徑/00002.jpg"</span>)  </span><br><span class="line">x = img_to_array(img01)</span><br><span class="line">y = img_to_array(img02) </span><br><span class="line">l.append(x)</span><br><span class="line">l.append(y)</span><br><span class="line">l=np.array(l)</span><br></pre></td></tr></table></figure>



<p><strong>flow_from_dataframe</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">flow_from_dataframe(dataframe, </span><br><span class="line">                    directory, </span><br><span class="line">                    x_col=<span class="string">'filename'</span>, </span><br><span class="line">                    y_col=<span class="string">'class'</span>, </span><br><span class="line">                    has_ext=<span class="literal">True</span>, </span><br><span class="line">                    target_size=(<span class="number">256</span>, <span class="number">256</span>), </span><br><span class="line">                    color_mode=<span class="string">'rgb'</span>, </span><br><span class="line">                    classes=<span class="literal">None</span>, </span><br><span class="line">                    class_mode=<span class="string">'categorical'</span>, </span><br><span class="line">                    batch_size=<span class="number">32</span>, </span><br><span class="line">                    shuffle=<span class="literal">True</span>, </span><br><span class="line">                    seed=<span class="literal">None</span>, </span><br><span class="line">                    save_to_dir=<span class="literal">None</span>, </span><br><span class="line">                    save_prefix=<span class="string">''</span>, </span><br><span class="line">                    save_format=<span class="string">'png'</span>, </span><br><span class="line">                    subset=<span class="literal">None</span>, </span><br><span class="line">                    interpolation=<span class="string">'nearest'</span>)</span><br></pre></td></tr></table></figure>
<p>在此數據生成器輸入 dataframe 和圖片目錄的路徑，使其生成批量的增強數據。<br>這個函數常適用在資料形式為”所有圖像都存在於一個目錄中，並將圖片名稱與對應標籤寫入一個CSV或JSON文件中”的這一類。<br>flow_from_dataframe有超級多東西可以設定，可能對新手來說會花上不少時間。</p>
<ul>
<li>dataframe: Pandas dataframe，一列為圖像名稱，另一列為該圖像類別標籤，或是做為原始目標數據多個列。</li>
<li>directory: 字符串，目標目錄的路徑，也就是dataframe裡的所有圖像的路徑。</li>
<li>x_col: 字符串，dataframe 圖像名稱的列名稱，也就是圖像名稱該列的最上面名字，沒有的話就自行加個。</li>
<li>y_col: 字符串或字符串列表，圖像對應的標籤類別的列，與”x_col”雷同，一樣是沒有就自行加入。</li>
<li>has_ext: 如果 dataframe[x_col] 中的文件名具有擴展名則為 True，否則為 False。使用布林值(True or False)</li>
<li>target_size: 將圖片調整為(height, width)的尺寸，默認為 (256, 256)。只接受整數。</li>
<li>color_mode: 二選一 “grayscale” &amp; “rgb” 。默認為”rgb”。 圖像是否轉換為 1 個或 3 個顏色通道。</li>
<li>classes: 可選的類別列表 (例如， [‘dogs’, ‘cats’])。默認為None。 若沒有提供，則類比列表會自動從 y_col 中推理出來，y_col 將會被映射為類別索引）。包含從類名到類索引的映射的字典可以通過屬性 class_indices 獲得。</li>
<li>class_mode: 六選一 “categorical”, “binary”, “sparse”, “input”, “other” or None 之一。 默認為”categorical”。<br>決定返回標籤數組的類型：<br>categorical：  2D one-hot 編碼標籤。<br>binary： 1D 二進制標籤。<br>sparse： 1D 整數標籤。<br>input： 與輸入圖像相同的圖像（主要用於與自動編碼器一起使用）。<br>other： 將是 y_col 數據的 numpy 數組，<br>None： 不返回任何標籤（生成器只會產生批量的圖像數據，這對使用model.predict_generator(), model.evaluate_generator() 等很有用）。</li>
<li>batch_size: 批量數據的尺寸，默認為32。</li>
<li>shuffle: 是否混洗數據，講白點就是亂數打亂，默認為True。</li>
<li>seed: 是否用種子碼打亂數據。</li>
<li>save_to_dir: 是否要保存增強後的圖片，是的話填入要保存的路徑，默認為None。</li>
<li>save_prefix: 保存圖片的名稱前綴。</li>
<li>save_format: 二選一 “png” &amp; “jpeg” ，默認為”png”。</li>
<li>follow_links: 是否跟隨類子目錄的符號連結，默認為False。</li>
<li>subset: 決定資料的數據子集 (“training” 或 “validation”)，前提是 ImageDataGenerator 中有設定 validation_split。</li>
<li>interpolation: 在目標大小與加載圖像的大小不同時，用於重新採樣圖像的插值方法。 支持的方法有 “nearest”, “bilinear”, and “bicubic”。 如果安裝了 1.1.3 以上版本的 PIL 的話，同樣支持 “lanczos”。 如果安裝了 3.4.0 以上版本的 PIL 的話，同樣支持 “box” 和 “hamming”。 默認情況下，使用 “nearest”。</li>
</ul>
<p>下面是我寫程式時有用到flow_from_dataframe的片段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">df_train = pd.read_csv(<span class="string">"C:/**********/C1-P2_Train Dev/train2.csv"</span>,encoding=<span class="string">"utf8"</span>)</span><br><span class="line">img_gen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>],</span><br><span class="line">    validation_split=<span class="number">0.25</span>   <span class="comment">#設定驗證集</span></span><br><span class="line">)</span><br><span class="line">train_generator = img_gen.flow_from_dataframe(</span><br><span class="line">                                              dataframe=df_train,</span><br><span class="line">                                              directory=<span class="string">"C:/Users/**************/Crop_Train"</span>,</span><br><span class="line">                                              x_col=<span class="string">"image_id"</span>,</span><br><span class="line">                                              y_col=<span class="string">"grade"</span>,</span><br><span class="line">                                              batch_size=<span class="number">10</span>,</span><br><span class="line">                                              <span class="comment">#has_ext=False, </span></span><br><span class="line">                                              subset=<span class="string">"training"</span>, </span><br><span class="line">                                              class_mode=<span class="string">"categorical"</span>,</span><br><span class="line">                                              color_mode=<span class="string">"rgb"</span>,</span><br><span class="line">                                              target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line"></span><br><span class="line">val_generator = img_gen.flow_from_dataframe( </span><br><span class="line">                                          dataframe=df_train, </span><br><span class="line">                                          directory=<span class="string">"C:/**************/Crop_Train"</span>,</span><br><span class="line">                                          x_col=<span class="string">"image_id"</span>,</span><br><span class="line">                                          y_col=<span class="string">"grade"</span>, </span><br><span class="line">                                          batch_size=<span class="number">10</span>,</span><br><span class="line">                                          <span class="comment">#has_ext=False, </span></span><br><span class="line">                                          subset=<span class="string">"validation"</span>, </span><br><span class="line">                                          class_mode=<span class="string">"categorical"</span>, </span><br><span class="line">                                          color_mode=<span class="string">"rgb"</span>,</span><br><span class="line">                                          target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br></pre></td></tr></table></figure>
<p><code>flow_from_dataframe</code>函數裡有個<code>dataframe=df_train</code>，這個<code>df_train</code>是CSV檔，變數的宣告我寫在最上方。</p>
<p>另外這個範例有一個很重要的東西要講，各位應該有看到一個<code>validation_split=0.25</code>這個設定吧？<br>這個設定是用來設置驗證資料集，0.25代表拿訓練資料裡的25%來當驗證。</p>
<p>當<code>validation_split</code>有被設定後，接下來進行<code>flow_from_dataframe</code>這個函數就需要在設定裡加上<code>subset=&quot;validation&quot;或 &quot;training&quot;</code>。training代表訓練集，validation代表驗證集。<br>這也就是為什麼我宣告了兩次變數去進行<code>flow_from_dataframe</code>這個函數，因為我需要訓練集跟驗證集，兩個是要個別做宣告的。</p>
<p>那要進行訓練時要怎麼去應用上面的東西呢？<br>假設你已經建構好一個模型了，接下來要進行訓練。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model 代表你建置的模型名稱</span></span><br><span class="line">model.fit_generator(</span><br><span class="line">                    <span class="comment">#使用訓練集</span></span><br><span class="line">                    generator = train_generator,                                                 steps_per_epoch = step_size_train,</span><br><span class="line">                    <span class="comment">#使用驗證集</span></span><br><span class="line">                    validation_data = val_generator,    </span><br><span class="line">                    validation_steps = step_size_valid, </span><br><span class="line">                    epochs = <span class="number">10</span>,</span><br><span class="line">                    verbose = <span class="number">1</span>,</span><br><span class="line">                    callbacks = [RLR, ckptforall],</span><br><span class="line">                    use_multiprocessing = <span class="literal">False</span>,</span><br><span class="line">                    shuffle = <span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>訓練時就不是用<code>fit</code>了，而是用<code>fit_generator</code>。<br>裡面的設定也有小變化喔！各位應該有看到<code>batch_size</code>這個設定不見了吧？<br>在<code>fit_generator</code>這個函數裡，不會用到<code>batch_size</code>，就算用了也只會噴錯給你看。<br><code>batch_size</code>的不見，換來的是<code>steps_per_epoch = step_size_train</code>變成必填設定，怎麼設定？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">step_size_train = train_generator.n//train_generator.batch_size</span><br></pre></td></tr></table></figure>
<p>再加個<code>epochs</code>決定你要訓練幾次，這樣就是基本的訓練形式，可以直接進行訓練了。<br>如果還還要再加個驗證資料，那就是以下兩個設定要填：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">validation_data = val_generator,</span><br><span class="line">validation_steps = step_size_valid,</span><br></pre></td></tr></table></figure>
<p><code>validation_steps</code>中的<code>step_size_valid</code>設定怎麼用？就跟<code>steps_per_epoch</code>一樣：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">step_size_valid = val_generator.n//val_generator.batch_size</span><br></pre></td></tr></table></figure>
<p>範例中<code>fit_generator</code>剩下的設定就不是太必要的東西，算額外的設定，因此我就不多加說明。</p>
<p>總結上述的程式範例，整個流程為下圖：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#讀取csv檔</span></span><br><span class="line">df_train = pd.read_csv(<span class="string">"C:/********/C1-P2_Train Dev/train2.csv"</span>,encoding=<span class="string">"utf8"</span>)  </span><br><span class="line"><span class="comment"># 設定增強手法</span></span><br><span class="line">img_gen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>],</span><br><span class="line">    validation_split=<span class="number">0.25</span>   <span class="comment">#設定驗證集</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 進行資料增強於訓練資料中</span></span><br><span class="line">train_generator = img_gen.flow_from_dataframe(</span><br><span class="line">                                              dataframe=df_train,</span><br><span class="line">                                              directory=<span class="string">"C:/********/Crop_Train"</span>,</span><br><span class="line">                                              x_col=<span class="string">"image_id"</span>,</span><br><span class="line">                                              y_col=<span class="string">"grade"</span>,</span><br><span class="line">                                              batch_size=<span class="number">10</span>,</span><br><span class="line">                                              <span class="comment">#has_ext=False, </span></span><br><span class="line">                                              subset=<span class="string">"training"</span>, </span><br><span class="line">                                              class_mode=<span class="string">"categorical"</span>,</span><br><span class="line">                                              color_mode=<span class="string">"rgb"</span>,</span><br><span class="line">                                              target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line"><span class="comment"># 進行資料增強於驗證資料中</span></span><br><span class="line">val_generator = img_gen.flow_from_dataframe( </span><br><span class="line">                                          dataframe=df_train, </span><br><span class="line">                                          directory=<span class="string">"C:/**********/test/Crop_Train"</span>,</span><br><span class="line">                                          x_col=<span class="string">"image_id"</span>,</span><br><span class="line">                                          y_col=<span class="string">"grade"</span>, </span><br><span class="line">                                          batch_size=<span class="number">10</span>,</span><br><span class="line">                                          <span class="comment">#has_ext=False, </span></span><br><span class="line">                                          subset=<span class="string">"validation"</span>, </span><br><span class="line">                                          class_mode=<span class="string">"categorical"</span>, </span><br><span class="line">                                          color_mode=<span class="string">"rgb"</span>,</span><br><span class="line">                                          target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">                                          </span><br><span class="line">*********************過程中你建置了一個模型*********************                                           </span><br><span class="line"><span class="comment"># model 代表你建置的模型名稱</span></span><br><span class="line"><span class="comment"># 進行訓練</span></span><br><span class="line">model.fit_generator(</span><br><span class="line">    generator = train_generator,        <span class="comment"># 訓練資料集                          </span></span><br><span class="line">    steps_per_epoch = step_size_train,</span><br><span class="line">    validation_data = val_generator,    <span class="comment"># 驗證資料集</span></span><br><span class="line">    validation_steps = step_size_valid, </span><br><span class="line">    epochs = <span class="number">10</span>,</span><br><span class="line">    verbose = <span class="number">1</span>,</span><br><span class="line">    callbacks = [RLR, ckptforall],</span><br><span class="line">    use_multiprocessing = <span class="literal">False</span>,</span><br><span class="line">    shuffle = <span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>不要直接複製起來用喔！應該會噴錯，因為這只是一個概念流程圖。</p>
<p><strong>flow_from_directory</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">flow_from_directory(directory, </span><br><span class="line">                    target_size=(<span class="number">256</span>, <span class="number">256</span>), </span><br><span class="line">                    color_mode=<span class="string">'rgb'</span>, </span><br><span class="line">                    classes=<span class="literal">None</span>, </span><br><span class="line">                    class_mode=<span class="string">'categorical'</span>, </span><br><span class="line">                    batch_size=<span class="number">32</span>, </span><br><span class="line">                    shuffle=<span class="literal">True</span>, </span><br><span class="line">                    seed=<span class="literal">None</span>, </span><br><span class="line">                    save_to_dir=<span class="literal">None</span>, </span><br><span class="line">                    save_prefix=<span class="string">''</span>, </span><br><span class="line">                    save_format=<span class="string">'png'</span>, </span><br><span class="line">                    follow_links=<span class="literal">False</span>, </span><br><span class="line">                    subset=<span class="literal">None</span>, </span><br><span class="line">                    interpolation=<span class="string">'nearest'</span>)</span><br></pre></td></tr></table></figure>
<p>這個數據生成器最主要目的是從圖片資料夾裡抓出圖片，接著對該圖片進行增強後再儲存至指定路徑中，不會去管標籤類別。<br>因此<code>flow_from_directory</code>適用於”用各自類名命名的單獨資料夾中的所有圖像，A標籤的圖片全部集中在同一個資料夾中，以此類推”的形式。</p>
<ul>
<li>directory: 欲增強的圖片資料夾路徑，資料夾內接受 PNG, JPG, BMP, PPM 或 TIF 格式的圖像。。</li>
<li>target_size: 將圖片調整為(height, width)的尺寸，默認為 (256, 256)。只接受整數。</li>
<li>color_mode: 二選一 “grayscale” &amp; “rgb” 。默認為”rgb”。 圖像是否轉換為 1 個或 3 個顏色通道。</li>
<li>classes: 可選的類別列表 (例如， [‘dogs’, ‘cats’])。默認為None。 若沒有提供，則類比列表會自動從 y_col 中推理出來，y_col 將會被映射為類別索引）。包含從類名到類索引的映射的字典可以通過屬性 class_indices 獲得。</li>
<li>class_mode: 六選一 “categorical”, “binary”, “sparse”, “input”, “other” or None 之一。 默認為”categorical”。<br>決定返回標籤數組的類型：<br>categorical：  2D one-hot 編碼標籤。<br>binary： 1D 二進制標籤。<br>sparse： 1D 整數標籤。<br>input： 與輸入圖像相同的圖像（主要用於與自動編碼器一起使用）。<br>other： 將是 y_col 數據的 numpy 數組，<br>None： 不返回任何標籤（生成器只會產生批量的圖像數據，這對使用model.predict_generator(), model.evaluate_generator() 等很有用）。這裡要特別留意，如果 class_mode 為 None，數據仍然需要留在 directory 的子目錄才能正常運作。</li>
<li>batch_size: 批量數據的尺寸，默認為32。</li>
<li>shuffle: 是否混洗數據，講白點就是亂數打亂，默認為True。</li>
<li>seed: 是否用種子碼打亂數據。</li>
<li>save_to_dir: 是否要保存增強後的圖片，是的話填入要保存的路徑，默認為None。</li>
<li>save_prefix: 保存圖片的名稱前綴。</li>
<li>save_format: 二選一 “png” &amp; “jpeg” ，默認為”png”。</li>
<li>follow_links: 是否跟隨類子目錄的符號連結，默認為False。</li>
<li>subset: 決定資料的數據子集 (“training” 或 “validation”)，前提是 ImageDataGenerator 中有設定 validation_split。</li>
<li>interpolation: 在目標大小與加載圖像的大小不同時，用於重新採樣圖像的插值方法。 支持的方法有 “nearest”, “bilinear”, and “bicubic”。 如果安裝了 1.1.3 以上版本的 PIL 的話，同樣支持 “lanczos”。 如果安裝了 3.4.0 以上版本的 PIL 的話，同樣支持 “box” 和 “hamming”。 默認情況下，使用 “nearest”。</li>
</ul>
<p>這是我使用<code>flow_from_directory</code>時的程式片段，下面我會稍微做個解釋：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>])</span><br><span class="line">train_dir = <span class="string">r'C:/********************/test/'</span></span><br><span class="line">train_generator = datagen.flow_from_directory(</span><br><span class="line">          train_dir,</span><br><span class="line">          target_size=(<span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line">          batch_size=<span class="number">1</span>,</span><br><span class="line">          shuffle=<span class="literal">False</span>,</span><br><span class="line">          save_to_dir=<span class="string">'C:/Users/*********/C1-P2_Train Dev/Train_dataFrame/'</span>,</span><br><span class="line">          save_prefix=<span class="string">'train'</span>,</span><br><span class="line">          save_format=<span class="string">'jpg'</span>,</span><br><span class="line">          class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">45000</span>):</span><br><span class="line">    train_generator.next()</span><br><span class="line">    <span class="keyword">if</span> (i%<span class="number">100</span> == <span class="number">0</span>):</span><br><span class="line">        print(<span class="string">"."</span>, end=<span class="string">''</span>)</span><br><span class="line">print(<span class="string">"down"</span>)</span><br></pre></td></tr></table></figure>
<p>前面的應該大家都熟了，就是增強手法的設定，主要是下面的程式碼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">train_dir = <span class="string">r'C:/********************/test/'</span></span><br><span class="line">train_generator = datagen.flow_from_directory(</span><br><span class="line">          train_dir,</span><br><span class="line">          target_size=(<span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line">          batch_size=<span class="number">1</span>,</span><br><span class="line">          shuffle=<span class="literal">False</span>,</span><br><span class="line">          save_to_dir=<span class="string">'C:/***************/C1-P2_Train Dev/Train_dataFrame/'</span>,</span><br><span class="line">          save_prefix=<span class="string">'train'</span>,</span><br><span class="line">          save_format=<span class="string">'jpg'</span>,</span><br><span class="line">          class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">45000</span>):</span><br><span class="line">    train_generator.next()</span><br><span class="line">    <span class="keyword">if</span> (i%<span class="number">100</span> == <span class="number">0</span>):</span><br><span class="line">        print(<span class="string">"."</span>, end=<span class="string">''</span>)</span><br><span class="line">print(<span class="string">"down"</span>)</span><br></pre></td></tr></table></figure>
<p><code>train_dir</code>是變數，記錄訓練資料的資料夾路徑。<br>這裡有兩個很重要的地方：</p>
<ol>
<li>資料夾路徑不是寫到目標資料夾的所在位置，而是所在位置的上一層，假如目標資料夾的路徑為”A/B/C/目標資料夾”，那寫法就是”A/B/C”，這樣子就可以停了。</li>
<li>目標資料夾所在的位置，最好是只放單獨的資料夾，也就是只放目標資料夾，不然很容易噴路徑錯誤。我至今也沒搞懂為何會這樣，就當有個限制在，怕衍伸出不必要的麻煩。<br>我用圖片來說明會比較好：<img src="/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/pc01.jpg" class="" title="This is an image">
Crop_Train資料夾是我的訓練資料集，而它路徑上一層test就是Crop_Train的所在位置。這個位置只能放一個資料夾。</li>
</ol>
<p><code>train_generator = datagen.flow_from_directory( )</code>就是本次數據生成器主要的核心，裡面的設定我不細講，上面我有做說明了。</p>
<p>在這邊你可以先嘗試Run一下，有個小細節要讓各位知道。<br>我們不是做完資料增強了嗎？現在Run下去，<code>save_to_dir</code>這個路徑裡是不是就會有增強後的圖片了？<br>答案是：沒半張。<br>我當時也是傻眼，沒道理阿！之前的<code>flow_from_directory</code>或是<code>fit</code>使用下去就有結果了，為什麼<code>flow_from_directory</code>照著<code>flow_from_directory</code>的邏輯走，結果會沒反應呢？</p>
<p>我也另外爬文查這個問題了，好笑的是，天下一大抄，全部抄官方文檔或是別人的example，半字不提這個情況…..，所以等我查到這個問題的核心前，就當是一個未解之謎。</p>
<p>不過不是不能用，就只是要多加個for迴圈</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">45000</span>):</span><br><span class="line">    train_generator.next()</span><br></pre></td></tr></table></figure>

<p>45000是因為我的訓練集有45000張圖片，我要所有的圖片都進行增強。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (i%<span class="number">100</span> == <span class="number">0</span>):</span><br><span class="line">        print(<span class="string">"."</span>, end=<span class="string">''</span>)</span><br></pre></td></tr></table></figure>
<p>後面我有多加這個，主要是想知道圖偏增強進行到哪了。<br>output的結果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Found 45000 images belonging to 1 classes.</span><br><span class="line">..................................................................................................................................................................................................................................................................................................................................................................................................................................................................down</span><br></pre></td></tr></table></figure>
<p>實際的結果：</p>
<img src="/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/pc02.jpg" class="" title="This is an image">
<p>左邊第一張對應右邊第一張，以此類推。<br>跟原圖片不太相同，但仔細去看的話，其實跟原圖片有很多相似處，這個就是資料增強。<br>要先說明一下，我只對原圖片增強一次，<code>batch_size</code>我設定1而已喔！如果一張要變成好幾張，還請把<code>batch_size</code>調高。</p>
<h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p>[<a href="https://keras.io/zh/preprocessing/image/]" target="_blank" rel="noopener">https://keras.io/zh/preprocessing/image/]</a><br>[<a href="https://kknews.cc/zh-tw/code/yeg6oba.html]" target="_blank" rel="noopener">https://kknews.cc/zh-tw/code/yeg6oba.html]</a><br>[<a href="https://www.itread01.com/content/1546542668.html]" target="_blank" rel="noopener">https://www.itread01.com/content/1546542668.html]</a></p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E7%9A%84Hello_World-%E6%89%8B%E5%AF%AB%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98/">深度學習的helloWorld-手寫數字辨識</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-08T07:17:20.000Z" itemprop="datePublished">
    2020-09-08
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">實作心得</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/jupyter-notebook/">jupyter notebook</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h3 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h3><p>記錄我在研究所學習深度學習的知識與心得。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明如何利用tensorflow來寫一個最基礎的深度學習範例，相當於學習程式語言的hello world。我會盡量將每個程式碼進行解釋，也保持著盡量說人話的方式來說明，太多專有名詞換作是我去看這類的文章，也一定很想關掉頁面。所以請抱持放鬆的心情來看文章！</p>
<h3 id="前置步驟-amp-注意事項"><a href="#前置步驟-amp-注意事項" class="headerlink" title="前置步驟&amp;注意事項"></a>前置步驟&amp;注意事項</h3><ol>
<li>本心得教學是使用tensorflow來進行撰寫。怎麼裝tensorflow？我有另外寫了<a href="https://chenchianstudent.github.io/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/" target="_blank" rel="noopener">文章</a>。</li>
<li>我必須強調一下，本人在寫這篇文章時還是學習中的學生，算是初心者。內容若是有錯，誤導大家還請多多包涵！之後發現自己有說錯話，也會去重新修文章，你發現我有說錯話，也請告訴我哪裡錯了。</li>
<li>深度學習的一些專有名詞和要表達的概念實在太多了，如果漏掉了還請多多包涵。</li>
<li>模型訓練的過程中，有些參數若是照我的內容抄，結果執行時噴錯，原因很有可能是設備性能造成的。我的指導老師說了一句我覺得蠻中肯的話:深度學習也是一種軍備競賽，裝備差的人能表現的實在有限。</li>
<li>若是範例跑不動，可以採用colab。colab是google發明類似jupyter notebook的程式編譯器，是線上的，有網路就可以在瀏覽器上使用，有興趣可以試試，目前是免費的，但不保證未來也是免費喔！colab的教學我再考慮看看要不要另外寫一篇來說。</li>
<li>什麼是深度學習？請參考這篇<a href="https://chenchianstudent.github.io/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/" target="_blank" rel="noopener">文章</a></li>
</ol>
<h2 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h2><p>本文章對應的github專案，內容全是我自己寫的，歡迎大家參考，也請查看專案的 readme.md ，它會教你怎麼使用。<br>網址：<a href="https://github.com/chenchianstudent/DeepLearing-Test" target="_blank" rel="noopener">https://github.com/chenchianstudent/DeepLearing-Test</a></p>
<h3 id="了解資料內容-什麼是手寫數字辨識資料集"><a href="#了解資料內容-什麼是手寫數字辨識資料集" class="headerlink" title="了解資料內容-什麼是手寫數字辨識資料集?"></a>了解資料內容-什麼是手寫數字辨識資料集?</h3><p>簡單來說，它是一個很多張圖片的資料夾。<br>內容是一般人從數字0寫到9的圖片，不同人寫下並拍照，最後匯集在一起變成手寫數字資料集。手寫數字資料集從很久以前就有人在使用了，它不是最近才出現的，當時創造這份資料的主要目標，是想辦法透過手寫資料集讓電腦能正確判斷人寫的數字，也就是這篇文章要做的事情。<br>在以前這是一份很艱難的任務，但自從深度學習興起後，電腦辨識手寫數字這份任務就變得很簡單！而且辨識率可以達到99%以上，比人類辨識還要精準！</p>
<h3 id="程式內容"><a href="#程式內容" class="headerlink" title="程式內容"></a>程式內容</h3><p>以下為等等要講解的程式內容，也就是一個手寫數字辨識的實際範例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<p>一共15行，解決以前的大難題，很厲害吧！<br>接下來要做的就是講解這15行在幹嘛，但因為一次說明會很複雜，因此我會將程式分成5個部分，就像jupyter notebook一樣。<br>第一部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>第二部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br></pre></td></tr></table></figure>
<p>第三部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>第四部份</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p>第五部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>

<h3 id="程式講解-第一部分"><a href="#程式講解-第一部分" class="headerlink" title="程式講解-第一部分"></a>程式講解-第一部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>這是我們最一開始必須import的函式庫，也就是我們的主角tensorflow，接下來會用tensorflow來進行深度學習。<br>而<code>import tensorflow as tf</code>的<code>as tf</code>則是將tensorflow做簡稱，等等在寫程式時如果要用到tensorflow時，只需要打tf電腦就會呼叫tensorflow了。<br>基本上你查文章時很多人都是將tensorflow簡稱tf的，希望各位初學者也養成這個習慣。<br>一來大家看你程式碼時比較不會多想，因為大家都知道tf是什麼，二來是你養成習慣後，查文章看到tf也可以知道作者是在表達什麼，對大家都好，tf這習慣不強制性，但養成會更好。<br>再來我們說說下行的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>如果有寫過程式的人，應該會很明白的這是要做print出一個值的動作。<br>問題是這個值是什麼？<br>很簡單，version的中文是”版本”，整句的意思：print出tensorflow的版本。</p>
<p>關於第一部分程式碼的注意事項:</p>
<ol>
<li>version旁邊的__是特殊寫法，為什麼這樣寫——–&gt;沒為什麼，就是tensorflow的規定。</li>
<li><code>__version__</code> 的<em>_ 一邊是兩個_，左右兩邊共4個</em> &lt;——-反正寫錯會跳error，你就會記得了。</li>
<li>tf就是我們上面講的，tensorflow的代稱。</li>
</ol>
<h3 id="程式講解-第二部分"><a href="#程式講解-第二部分" class="headerlink" title="程式講解-第二部分"></a>程式講解-第二部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br></pre></td></tr></table></figure>
<p><code>mnist = tf.keras.datasets.mnist</code>的整句意思為以mnist這個變數來存取數字辨識資料集。<br>mnist的意思是手寫數字辨識，你在google打上mnist就會跑出很多手寫數字辨識的文章或資料集。<br>奇怪？我都沒有下載手寫數字資料集，為什麼就能存取數字辨識了？<br>原因就是這個<code>tf.keras.datasets</code>，tensorflow裡面就有內建手寫數字辨識了，我們去呼叫tensorflow資料庫裡的mnist手寫數字辨識就好了，tensorflow將很多大家常用的資料集都放到自己的資料庫了，有興趣的可以上網查一下這個資料庫裡有什麼，今次只講解mnist，因此就不花時間說明。<br>這是我們剛抓進來的<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">mnist資料集詳細資料</a>，可以看一下！<br>資料集內容大概是長這樣</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train-images-idx3-ubyte.gz:  training set images (9912422 bytes)</span><br><span class="line">train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)</span><br><span class="line">t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)</span><br><span class="line">t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)</span><br></pre></td></tr></table></figure>
<p>四個檔案—&gt;training的圖片和標籤(2個)+test的圖片和標籤(2個)<br>為什麼我要突然講資料內容，因為接下來的程式講解會用到這些來說明，老師當初上課不講害我查很久才知道這是在幹嘛的==<br><code>(x_train, y_train), (x_test, y_test) = mnist.load_data()</code>這行跟下行程式碼是比較困難的地方，我想辦法講的簡單一點。<br>想來說說這些x跟y是甚麼東西好了：<br>x_train = 等等要拿去讓機器訓練的數字圖片集<br>y_train = 等等要拿去讓機器訓練的數字標籤集<br>x_test = 機器訓練好後拿來做驗證的數字圖片集<br>y_test = 機器訓練好後拿來做驗證的數字標籤集<br>再將這個代稱拆解<br>x代表圖片集<br>y代表標籤集<br>train代表訓練用<br>test代表測試用<br>合起來就是<code>(x_train, y_train), (x_test, y_test)</code>然後進行讀取資料<code>mnist.load_data()</code>，目的就是讓這些資料轉變成等等要建立的模型能讀取的型態，就是這樣。<br>讀取型態大概就是長這樣<br>訓練用的(‘圖片’,’標籤’)<br>測試用的(‘圖片’,’標籤’)<br>另外圖片是一大串數字，這些數字就是圖片數字化的樣子，你可以print一下x裡的東西看一下長怎樣！</p>
<p><code>x_train, x_test = x_train / 255.0, x_test / 255.0</code>這行是資料處理，目的是讓等等建立的模型做訓練時可以比較好訓練找出規則。<br>主要的意思是對訓練和測試的圖片(已數字化)都除255.0當作資料再存取。<br>這個行為是所謂的<strong>歸一化</strong>，因為圖片為彩色RGB，值是0-255的數字，我們將這些色彩圖進行/255.0後會將這些數值縮小到0-1之間，好處是模型做計算時會比較好算，百位數跟個位數哪個比較好算，當然是個位數！另外就是防止overfitting，不會因為這張圖色彩在某個區間而認為這就是規則而當作辨識條件。</p>
<p>關於第二部分程式碼的注意事項:</p>
<ol>
<li>為什麼要除255.0而不是255？因為我們要它的小數點，因為歸一化是在0-1數字之間，就是小數點阿！</li>
<li>你可以發現我們做歸一化都是在圖片集上，標籤集不用做喔！</li>
<li>不用做歸一化其實也可以，這是一種資料處理的手法，不是絕對必要的動作。</li>
</ol>
<h3 id="程式講解-第三部分"><a href="#程式講解-第三部分" class="headerlink" title="程式講解-第三部分"></a>程式講解-第三部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>這部分就是在做建立模型(model)。<br>建立模型是深度學習最精華的地方，我們前面都是在做資料處理，目的就是讓現在我們建立的模型能夠讀取，也就是說，這裡是主菜。<br><code>model = tf.keras.models.Sequential([ ])</code>這裡是tensorflow建立模型的寫法。<br>這裡我覺得要用比喻的方式來說明，假如我們現在正在創造一個機器人，<code>model = tf.keras.models.Sequential([ ])</code>就是在做機器人的外殼，讓機器人有個形狀，告訴各位我要做一個機器人，model這個變數則是告訴大家機器人叫model。<br>機器人有了外殼後，接下來就是將空殼加入零件讓他能夠動起來。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br></pre></td></tr></table></figure>
<p>這些就是我們的零件，這段程式就是在建構我們的神經層。<br>其中你們有看到Flatten、Dense、Dropout這幾個英文單字，這些是利用keras在做建構網路層時會使用到的東西。</p>
<p><strong>Flatten層</strong><br>功能是將我們讀入的資料攤平攤開，把多維的輸入一维化，通常我們是把Flatten層當卷積層到全連結層的過渡層。而<code>input_shape=(28, 28)</code>則是設定Flatten層資料讀取進來的大小28*28。</p>
<p><strong>Dense層</strong><br>就是我們大家常說的全連接層，建立神經層。Dense層會用到很多參數，但是不一定每次建Dense層時，會對每個參數做設定。像這次我們只動用到2個參數，分別是unit與activation。以<code>tf.keras.layers.Dense(128, activation=&#39;relu&#39;)</code>來做解釋好了，裡面的參數寫的詳細點就是(unit = 128, activation = ‘relu’)。</p>
<ul>
<li>unit：就是我們神經元，要在神經層裡設定多少個神經元，就是在這裡設定，一般我們在做設定神經元時，只會寫數字，不會寫”unit = “。</li>
<li>activation：中文名叫激活函數，激活函數的設定有很多，這段程式中我用了兩次Dense層，而這兩層都有用到激活函數，分別是relu與softmax。這些設定我無法用人話說，因為真的是數學抽象東西….若真的想了解，請參考<a href="https://keras.io/zh/activations/" target="_blank" rel="noopener">Keras-激活函数 Activations</a>，他會告訴你在幹嘛……</li>
</ul>
<p><strong>Dropout層</strong><br>其功用在將訓練過程中每次更新參數時按一定比率斷開輸入神經元，人話的意思是在丟到一些參數結果進下一神經元，其目的防止overfitting。</p>
<p>程式內一些注意事項</p>
<ol>
<li>最後一行的Dense層為什麼是10，原因是我們輸出結果是0-9共10個數字，因此我們會需要10個神經元。</li>
<li>Dense層是建構模型裡不可或缺的零件，請一定要加Dense層。</li>
<li>Dropout層可加可不加，其實你玩久了就會發現有些建立模型的小規則和習慣，各位在建神經層時可以試試有加跟沒加的訓練結果長怎樣。</li>
<li>input_shape為什麼是28 X 28，原因是這些手寫數字圖片是28 X 28，讓模型讀取訓練資料前，還請讓這些訓練資料修正至統一大小，不然會無法讀取！今天的範例為什麼沒做修正，原因是這些圖片都已經變成28 X 28，不用再做修正，範例比較簡單些，之後如果要自己找資料練習，就會遇到圖片處理這個環節。</li>
</ol>
<h3 id="程式講解-第四部份"><a href="#程式講解-第四部份" class="headerlink" title="程式講解-第四部份"></a>程式講解-第四部份</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p><code>model.compile()</code>是用來選擇這個模型的目標以及求解方法。<br>如果要用上面機器人的例子來說的話，就是對這些在機器人裡的零件建立好規則、教導怎麼運作來防止不會出錯。今天機器人目標是要走路，那就要制訂好規則是用四肢爬還是二肢走，手腳要怎麼運作才能正常走路等類似的概念。<br>在模型中，我們尋求解決方法會用compile(編譯)函數定義損失函數(loss)、優化函數(optimizer)及成效衡量指標(mertrics)。</p>
<p><strong>優化函數(optimizer)</strong><br>我們建立起來的模型在學習訓練的時候會一個名叫學習率的東西，它是負責控制梯度的收斂程度，如果單次更新學習率的值過高，收斂方向的速度就會變快，但這裡又說一句話，越快並不一定是最好的方法，梯度下降的收斂過程就像走小山丘，太大會暴衝會不穩，太小收斂會太慢，或是卡在局部解(local minimum)而跨不出來了。為了讓學習率更能找到我們要的最底點，就會採取像Adam的優化函數來控制α。</p>
<p><strong>損失函數(loss)</strong><br>損失函數是神經網路定義要收斂的對象函數。因為我們有龐大的參數節點(神經元)，可以擬合任意函數，我們可以不用知道權重跟bias的值明確要設多少，但可以靠反向傳播做梯度下降，讓函數逐步收斂，直到逼近最低點(global minimum)。<br>好像不是太人話，但這裡我有點想不到能用什麼例子來比喻，大概就是我們會需要定義一個損失函數來尋找最底點這樣子。</p>
<p><strong>效衡量指標(mertrics)</strong><br>用來評估訓練和測試之間的模型標準，通常我們會用’accuracy’。<br>目前我看了很多模型，幾乎都是用’accuracy’。</p>
<h3 id="程式講解-第五部份"><a href="#程式講解-第五部份" class="headerlink" title="程式講解-第五部份"></a>程式講解-第五部份</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<p>這裡就是最後一步了，恭喜你堅持到這裡！<br>機器人零件裝好了，怎麼動的規則也建立好了，最後就是要進行測試是不是我們要的結果。<br>沒錯！最後的程式碼就是在進行測試以及評估的動作，確認是我們要的答案。<br><code>model.fit()</code>用來進行模型的訓練。其中你會看到(  )內使用了測試圖片集與標籤集x_train &amp;  y_train，意思就是我要拿這兩份資料來讓模型進行訓練，從這些訓練資料找出規則，進而讓電腦自行找到辨識最佳解。<br>而<code>epochs</code>是訓練次數，我們訓練一次模型時，會更改神經元上的變數權重以利形成良好的辨識規則，但通常模型訓練時不會一次訓練就是最佳解，學腳踏車不太可能一騎上去就會吧？要多騎幾次去累積經驗才能正常騎腳踏車。模型也是如此，我們會讓模型訓練完一次後，讓訓練完後的模型再進行訓練，直到規定的訓練次數都完成為止。當然要訓練幾次就是一個經驗，答案不是你所希望的，就是再訓練或是重新再來一次。<br>另外，因為這裡只是一個很簡單的範例程式，用到的設定其實還蠻少的，實際找例子做會有很多設定會去設，之後我會找機會說，如果你等不下去想早點知道，就參考<a href="https://keras.io/zh/models/model/" target="_blank" rel="noopener">這份文章</a>吧：！</p>
<p><code>model.evaluate(x_test, y_test)</code>則是評估你的模型正確率。當你得到了一個你滿意的模型就可以拿測試資料進行評估正確率，確認拿新的資料來辨識時，是不是也能如期的辨識出正確的答案。</p>
<p><strong>output</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 112us&#x2F;sample - loss: 0.2889 - acc: 0.9142</span><br><span class="line">Epoch 2&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 97us&#x2F;sample - loss: 0.1397 - acc: 0.9582</span><br><span class="line">Epoch 3&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 95us&#x2F;sample - loss: 0.1049 - acc: 0.9682</span><br><span class="line">Epoch 4&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 97us&#x2F;sample - loss: 0.0847 - acc: 0.9739</span><br><span class="line">Epoch 5&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 99us&#x2F;sample - loss: 0.0728 - acc: 0.9769</span><br><span class="line">10000&#x2F;10000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 69us&#x2F;sample - loss: 0.0758 - acc: 0.9779</span><br><span class="line"></span><br><span class="line">[0.07581472408375703, 0.9779]</span><br></pre></td></tr></table></figure>

<p>從output裡，我們有很多東西需要知道，這些在模型訓練時給予了我們很多重要的資訊來評估是不是更改我們的模型或是這就是我們要的模型。<br>我們從<code>60000/60000 [==============================] - 7s 112us/sample - loss: 0.2889 - acc: 0.9142</code>這裡來做講解好了，這段代表模型訓練完成一次了！</p>
<p><code>60000/60000 [==============================] - 7s 112us/sample</code>是電腦在模型訓練時所花費的時間，現在這個狀態是100%，所以旁邊的秒數是寫整個過程花費的時間。當訓練還在進行時，7s這個位置就會變成距離訓練完成所剩餘的時間。</p>
<p><code>loss: 0.2889 - acc: 0.9142</code>是我們主要看的地方，loss就是損失函數，而acc則是整體正確率，正確率為0.9142(91.42%)。每一次訓練完成都會顯示loss與acc，這些資訊就是訓練時主要看的。你可以發現output中每次訓練完成後，acc會提升，這也說明了模型越來越能找到規則，能夠辨識的正確率可以提升起來。</p>
<p><code>[0.07581472408375703, 0.9779]</code>是<code>model.evaluate()</code>的output。拿一份新的資料去進行辨識，loss和acc會是多少，就是output顯示的樣子。做這個目的在於確認模型沒有overfitting，也許在訓練時，模型把訓練資料裡全部的特徵都記住了，也就是連無關緊要的特徵也納入辨識規則中，導致正確率才會那麼高！因為訓練都是拿同一份資料。假如拿一份不是訓練資料裡的圖片去辨識，可能會因為這些無關緊要的特徵而判斷錯誤，我們要避免的就是這個！評估一下拿新的資料去辨識是不是與訓練時的正確率一樣，正是評估的主要意義。</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/">深度學習？！為什麼最近大學和資訊界都能聽到這個詞？</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-08T07:05:57.000Z" itemprop="datePublished">
    2020-09-08
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h3 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h3><p>因為碩士選擇了人工智慧，於是便開始接觸tensorflow。學習過程中發現深度學習，比我在大學四年所學到的東西還要來的難！到目前為止，我每天被深度學習困擾到開始有壓力，因此，我想說先把我手上學到的東西整理成文章，一來方便自己重新閱讀，二來寫文章時可以再重新複習一遍我學到的東西，甚至在寫文章時可以把一些模糊的觀念釐清一下，在這些想法的驅使下，決定來寫看看。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明什麼是深度學習，也算是我接下來寫文章的序言，一切的開頭。</p>
<h3 id="為什麼要學深度學習"><a href="#為什麼要學深度學習" class="headerlink" title="為什麼要學深度學習?"></a>為什麼要學深度學習?</h3><p>阿我就想學阿！沒人逼你學！阿不是…..目前在資訊界裡最常聽到的名詞之一應該就是AI(人工智慧)了！我們生活環境也開始慢慢出現跟AI應用有關的產品，好比說特斯拉的自動駕駛系統，駕駛只要輸入目的地，就可以睡覺了，因為特斯拉會自動幫你駕駛到目的地，完全不需要人為介入，這就是一個AI應用的例子。聽起來非常厲害，對！真的非常厲害，如果你心中產生了非常厲害的想法，那就是為什麼有人要去學深度學習的原因了。因為這種自駕車的技術，就是從深度學習延伸出來的應用，想必未來的各種產品也會朝著這種技術去發展，AI應用的例子真的很多，不止是自駕車技術，但因為礙於篇幅長度，所以只提一個例子來佐證，現階段深度學習還是一種新興的技術，各企業搶著要這類的人才，故薪水也不會差到哪裡去，這也是為什麼我想學的原因，當然也有被這種厲害的感覺所吸引。<br>回到標題為什麼要學深度學習，為何要下這種標題？其實算是再三提醒我學深度學習的初衷，盡管最近真的超想放棄，學到快吐血，但我也必須堅持住，因為這個厲害的感覺也許就換我給別人了。</p>
<h3 id="何謂深度學習"><a href="#何謂深度學習" class="headerlink" title="何謂深度學習?"></a>何謂深度學習?</h3><p>深度學習是人工智慧的其中一種技術，人工智慧算是眾多技術合在一起的統稱。若今天別人說AI，也並不代表是在說深度學習，可能再說其他相關技術。但目前為止，深度學習是AI的主流，最近開始流行AI也是要歸功於深度學習的興起，也有不少人把AI的這詞投影在深度學習裡。恩….有對有錯拉！聽得懂就好了，不過我還是要再強調一下，深度學習只是人工智慧的其中技術，就像下圖表示的，儘管深度學習是AI大主流，但依舊只是人工智慧裡的一環而已，在未來跟別人討論AI時，也請將這個知識視為常識，不然懂的人聽到其實滿尷尬的。</p>
<img src="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/pc01.JPG" class="" title="This is an image">
<p>(圖源<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fblogs.nvidia.com.tw%2F2016%2F07%2Fwhats-difference-artificial-intelligence-machine-learning-deep-learning-ai%2F&psig=AOvVaw3XqYIgghvTbnNs_sjlEl5N&ust=1591169227107000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCODggbjN4ukCFQAAAAAdAAAAABAD" target="_blank" rel="noopener">Nvidia官方部落格</a>)<br>雖然深度學習是目前AI的主流，但深度學習這一詞並不是一個新興詞，早在90年代就存在了，當時用神經網路的概念來發表，但礙於當時的設備性能，導致無法提倡這樣的概念，想法終究只能是想法。直到最近的硬體設備性能大幅提升後，才開始把這個概念又拉回來，也因此產生了風潮。</p>
<p>我重新審視一遍自己寫的，發現還是在說人話，接下來因為太多專有名詞和抽象概念了，可能會讓你產生混亂，所以特地提醒你一下！要準備集中精神看了。</p>
<p>「深度學習」表面上看起來很難，其實真的很難！你以為我會說簡單嗎？並沒有。很多文章說明深度學習會說簡單，其實也沒騙你拉！但是當你深入進去時，就會發現這個概念就像樹枝一樣，在樹上會隨著時間越長越多，樹枝開始不停出現分叉，要學的東西也就不停地出現，感覺永遠也沒有學完的一天。舊的東西還沒學完，新的東西又出現了，根本來不及去搞懂，這就是我目前體驗到的。</p>
<p>盡管我這樣說深度學習，他還是有一個很基礎很根本的概念和步驟在，所有的東西都是從這個概念延伸出去的。台大電機系教授李宏毅有說過：「深度學習也只要三個步驟：<strong>建構網路</strong>、<strong>設定目標</strong>、<strong>開始學習</strong>。」</p>
<p>我們用李宏毅教授所說的這三個步驟來解釋好了。</p>
<p><strong>深度學習 = 建構網路 + 設定目標 + 開始學習</strong></p>
<p>因此我們就必須去理解這三個步驟在說什麼。</p>
<p><strong>建構網路</strong><br>建構所謂的神經網路。<br>各位有聽過IPO嗎?也就是Input+Program+Output的簡稱。我們輸入資料，經過程式計算，最後輸出結果，這個就是IPO架構。有學過程式的人一定不陌生。而建構網路就是負責Program這塊。在深度學習的IPO裡，我們會建構一個模型，當輸入一份資料後，資料就會進入這個模型(model)去運算，最後得出結果。模型(model)就像人的神經，裡面有神經元，神經元跟神經元彼此會連線，當神經元有很多個並且連起來後，就會形成神經網路，呼應第一句說的，建構神經網路。</p>
<p><strong>設定目標</strong><br>簡單來說就是你希望這個模型是來做什麼的？<br>這邊我要說一個蠻重要的觀念，深度學習不是萬能的，模型建構出來沒辦法應用於所有的東西上，它只能解決特定的需求。這就來到了我說的第一句，你希望你的模型用來解決什麼問題的？可能是手寫數字的辨識，也有可能是讓機器學會畫畫，不同的問題需求，就會有不同的模型誕生，目前為止是沒有任何一個模型能套用到所有的問題上的。因此設定目標是一個極為關鍵的要素，有了一個目標，才會有想法去「建構網路」，最後才能讓電腦「開始學習」。</p>
<p><strong>開始學習</strong><br>讓機器開始學習。<br>如果什麼參數和細節都要透過人類去設定的話，那就不是「機器學習」。我們設定好目標，建構好網路，接下來就是要讓機器自己去學習。神經網路裡面有數千數百萬個數值細節，這些要靠機器自己去學習如何改變裡面的變數。人們要做的只有給機器大量的訓練資料和規則去學習，並且當機器給出結果時，要告訴它這個答案對不對，最終機器會得到一個最佳函數，也就是問題的最佳解。</p>
<p>這樣講有比較明白一點嗎?我蠻怕我解釋錯誤，自己再三檢查我寫的，覺得這應該就是深度學習最主要的問題與處理步驟，自己學過後了解深度學習的一些相關認知後再回來看這三個要素，蠻感同身受的！</p>
<h3 id="關於神經網路"><a href="#關於神經網路" class="headerlink" title="關於神經網路"></a>關於神經網路</h3><p>剛剛在上文我們有講到深度學習很早之前就被提過了，是以神經網路的概念提出，因此我們就應該好好的去了解一下神經網路到底是什麼了。</p>
<p>上文我有稍微帶到一點神經網路的東西，不知道各位有沒有看到？如果要用生活上的事物來比喻神經網路的話，大概就是人的神經了！正確來說就是模仿生物神經來創造神經網路的。</p>
<p>人的神經有兩個神經元，神經元之間會利用神經纖維來連成一條線進行信號傳輸，機器的神經網路亦是如此。我們在建構神經網路時，會先建立一層神經層，神經層裡有若干的神經元，數量多少就是靠我們自己去決定。接著還會再建立新的神經層，然後新神經層裡的神經元就會與上一層的神經元做連接，形成網路開始進行信號傳遞，什麼情況信號要傳遞到A或B神經元，正是深度學習在學習的。</p>
<p>當我們成功建立好一套神經網路後，就會是我們平常講的模型(Model)。<br>新建立模型一開始正確率一定很低，我們正是要透過大量的訓練資料來訓練這個模型，而模型會因這些訓練資料來學習判斷正確結果，訓練到一定程度後，就會是我們理想中的模型，就可以拿去解決我們需要的問題了，概念如下圖。</p>
<img src="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/pc02.jpg" class="" title="This is an image">

<p>另外可能會有人問說:模型訓練是在訓練什麼東西？為什麼訓練後正確率會開始提高？<br>神經網路可以說是一個數學公式，因為我一直希望是抱持著說人話的方式來寫文章，因此就不太說數學那邊的東西。不過這裡我必須要帶點數學觀念了！剛剛我們在上上段有說到神經元這個詞，其實這些神經元就代表著一個變數，一開始是隨機亂給的，所以辨識正確率才會那麼低。為了要讓模型提高正確率，我們會加入訓練資料來做訓練，目的就是為了改變這些神經元的參數，讓這些參數達到我們要的數值，進而提升模型預測的正確率。</p>
<p>如何提高模型正確率？改變神經網路裡神經元的參數權重。</p>
<p>怎麼改神經元的參數權重？替模型加入訓練資料來進行學習。</p>
<p>學習訓練資料裡的什麼？找出訓練資料裡的規則。</p>
<h3 id="神經網路的建置-amp-問題"><a href="#神經網路的建置-amp-問題" class="headerlink" title="神經網路的建置&amp;問題"></a>神經網路的建置&amp;問題</h3><p>這部分如果讀者是0基礎的話，我覺得看過就好，因為之後的程式範例文章看過理解後，才會開始對這一個標題有想法。不過這部分也是屬於深度學習的介紹，因此還是需要歸類在這一篇文章中。</p>
<p><strong>深度學習的精隨，在於怎麼建置神經網路。</strong><br>這句話是我說的，應該沒有任何毛病！當然深度學習也有資料處理這一塊，不過最精華最精華的，還是神經網路這一塊，調整神經網路的架構、參數、模型類別等…..，我們學習深度學習主要的地方。</p>
<p><strong>深度學習為什麼厲害，在於它可以疊很多神經層。</strong><br>神經網路你愛加幾層就幾層，沒人阻止你，建置怎樣的神經網路，正是我們在學習的。<br>不過這裡就來到一個問題: 神經網路越多層越好嗎？<br>答案:不一定！</p>
<p>雖然近幾年來，一些機器學習競賽結果來看，層數越深，錯誤率也跟著降低。VGG模型層數總共19層，錯誤率到7.3%，而googleNet比VGG層數多了3層，一共22層，錯誤率可以再降到6.7%。甚至157層的Residual Network，錯誤率更可降至3.5%！但是層數越多的網路，越是會有<strong>梯度消失問題（Vanishing gradient problem）</strong>，因為每一層運算讓數值不斷收斂，導致最後的 output 越來越小，跟正確答案相減之後也就看不到顯著的最小值，看起來到處都是最小值。而防止梯度爆炸和梯度消失也是我們在建構神經網路時也必須注意的東西。</p>
<p>那可能有人又會問:驗證時不是都有標準答案嗎?把所有的答案和標準答案做比對，怎麼會找不到最小值呢？<br>答案：其實我們要面對的可能不止單單這些標準答案，也許幾百萬幾千萬！驗證時我們沒辦法把一切的答案都納入進去，而是用隨機抽選的方式，在線上找一點，比對這點四周的數值，看看是否又更低的，再慢慢去貼近最低點，這個我們稱此為<strong>梯度下降(Gradient descent)</strong>。</p>
<p>當今天你被丟在一個環境的山上，你的目的是要走到這個環境的最低點，你會開始慢慢的往低點下去。過程可能繞一大圈才下山，也有可能直直的就往低點下去。但不管怎麼樣，最終目的便是前往環境的最低點。</p>
<p>但問題來了！當你下降到一個附近都平坦的地方，你可能就認為這裡就是環境的最低點，殊不知山的對面可能還存在更深的地方或是平原遠一點的地方還存在著谷底。</p>
<p>神經網路疊加的越多層，這個問題就會越明顯，因此需要設計不同的架構，跟特殊的運算過程，才能避免找不到最低點。有時候反而 layer 少一點，正確率還更高。</p>
<h3 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h3><p>我發現我後半段好像開始說東說西偏離主題了，因此總結一下我目前說的：<br>1.深度學習離不開三個要素： 建構網路 、 設定目標 、 開始學習<br>2.怎麼進行深度學習？建構神經網路模型→輸入大量訓練資料來進行模型訓練→再利用訓練好的模型進行實際預測<br>3.深度學習的精隨，在於怎麼建置神經網路。<br>4.神經層數越高，模型的正確率也會隨之增加，但也存在著梯度消失以及梯度爆炸的風險，因此如何避免這些風險並提高模型正確率，正是我們在深度學習所要探討的。</p>
<h3 id="個人心得"><a href="#個人心得" class="headerlink" title="個人心得"></a>個人心得</h3><p>抱歉！最近因為學業和家庭關係，變得不太常更新文章，導致github上的文章都是很久之前的，讓人覺得我是不是放棄這坑了。其實這篇文章我在6月初就寫好了，但是被教授抓去幫中國信託做點他們AI上的事情，然後每周又要有論文進度，因此不太能更新文章。<br>另外我也發現，幾個月前的文章，當初要表達什麼我也不知道了XD比如圖片該放哪張？這篇文章只有兩張圖，我卻想了很久…咦？我這裡有事先截圖留著嗎？我到底是要截哪張圖上來等等…已經有這不是我寫出來的錯覺了XD總而言之，希望這篇文對你在深度學習的認知上有一點基礎，雖然有人可能會覺得打那麼多誰看得完？十分抱歉，因為我不是超級專家，我也是學習中的學生，所以無法靠很厲害的圖解來讓讀者輕鬆閱讀，這點還請多多包涵！日後我會盡量改進的。</p>

      
    </div>
</article>

    </li>
  
</ul>



            <footer>
    <div>© 2020 - daniel chen </div>
    <div>
        <span>
            Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a>
        </span>
        ,
        <span>
            Theme - <a href="https://github.com/nameoverflow/hexo-theme-icalm" target="_blank" rel="noopener">Icalm</a>
        </span>
    </div>
</footer>

        </div>
    </div>
</div>

<script src="/js/pager/dist/singlepager.js"></script>

<script>
var sp = new Pager('data-pager-shell')

</script>
</body>
</html>