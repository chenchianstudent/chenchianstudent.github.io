<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Anyapoi WebSite</title>
  
  
  
  <!--link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css"-->
  
<link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css">

  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
<div class="Shell">
    <aside class='SideBar'>
    <section class='avatar' style="background-image: url()">
        <div class='av-pic' style="background-image: url()">
        </div>
    </section>
    <section class='menu'>
        <div>Anyapoi WebSite</div>
        
            <div>poi</div>
        
        <ul>
          
            <a href="/" class="Btn">
              <li>Home</li>
            </a>  
          
            <a href="/archives/" class="Btn">
              <li>Archive</li>
            </a>  
          
            <a href="/tags/" class="Btn">
              <li>Tags</li>
            </a>  
          
            <a href="/categories/" class="Btn">
              <li>Categories</li>
            </a>  
          
            <a href="/about/" class="Btn">
              <li>About</li>
            </a>  
          
            <a href="https://i.imgur.com/cjGoQtg.jpg" target="_blank" rel="noopener" class="Btn">
              <li>avatar</li>
            </a>  
          
        </ul>
    </section>
    <section class="media">
        
            
                <a href="https://github.com/chenchianstudent" target="_blank" rel="noopener">
                    <img src="/assets/github.svg" />
                </a>
            
        
            
                <a href="https://www.facebook.com/profile.php?id=100004713881642" target="_blank" rel="noopener">
                    <img src="/assets/facebook.svg" />
                </a>
            
        
    </section>
</aside>

    <div class="container">
        <div data-pager-shell>
            <ul class="Index">
  
    <header class='PageTitle'>
        <h1>{ Tensorflow }</h1>
    </header>
  
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/">資料增強imageGenerator使用心得</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-21T06:11:58.000Z" itemprop="datePublished">
    2020-09-21
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">實作心得</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/jupyter-notebook/">jupyter notebook</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h2 id="資料增強-Image-Generator-使用心得"><a href="#資料增強-Image-Generator-使用心得" class="headerlink" title="資料增強(Image Generator)使用心得"></a>資料增強(Image Generator)使用心得</h2><h2 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h2><p>記錄我在研究所學習深度學習的知識與心得。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明如何利用Keras的Image Generator來進行資料擴增。<br>文中會說明資料增強是什麼？<br>flow、flow_from_directory、fit以及flow_from_dataframe的使用。</p>
<h2 id="前置步驟-amp-注意事項"><a href="#前置步驟-amp-注意事項" class="headerlink" title="前置步驟&amp;注意事項"></a>前置步驟&amp;注意事項</h2><ol>
<li>本次心得比較特殊一點，重心在keras而已，tensorflow比較偏延伸應用向，但因為教學心得寫文章關係，因此我會帶點tensorflow。</li>
<li>我必須強調一下，本人在寫這篇文章時還是學習中的學生，算是初心者。內容若是有錯，誤導大家還請多多包涵！之後發現自己有說錯話，也會去重新修文章，你發現我有說錯的話，也請告訴我哪裡錯了，email和FB應該都在我首頁裡，不好意思麻煩老手了。</li>
<li>資料增強其實算是學習中期才需要看的文章，初學者可以先跳過這篇文章，會提早寫主要是因為我剛好又深入一次資料增強，趁記憶猶新馬上來寫一下，以免日後想到要寫這篇文章時，已經忘得一乾二淨。</li>
<li>什麼是深度學習？請參考這篇<a href="https://chenchianstudent.github.io/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/" target="_blank" rel="noopener">文章</a></li>
</ol>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>要訓練一個高正確率且泛用的模型，除了需要琢磨模型本身的架構之外，龐大的資料來讓我們去訓練也是一個重大關鍵。<br>今天我們不來討論模型結構這種比較偏數學且核心的問題，我們來討論「資料」這一塊。<br>在進行深度學習處理資料這一塊，我們最終極的目標就是將訓練資料轉變成模型可以讀取的形式。但是在模型讀取資料前，其實有很多小細節可以做，做了會怎樣？不外乎就是讓模型正確率再提高一點，或是將模型的訓練時間縮短。今天要講的「資料增強」就是這個小細節的一環，現在深度學習的比賽或是實例上，不少人都會用上資料增強，這是一個提高正確率不可或缺的手段。</p>
<h2 id="什麼是資料增強-Data-Augmentation-？"><a href="#什麼是資料增強-Data-Augmentation-？" class="headerlink" title="什麼是資料增強(Data Augmentation)？"></a>什麼是資料增強(Data Augmentation)？</h2><h3 id="一言以蔽之：製造假資料來騙機器說這是份新數據，請拿去訓練。"><a href="#一言以蔽之：製造假資料來騙機器說這是份新數據，請拿去訓練。" class="headerlink" title="一言以蔽之：製造假資料來騙機器說這是份新數據，請拿去訓練。"></a><strong>一言以蔽之：製造假資料來騙機器說這是份新數據，請拿去訓練。</strong></h3><p>前言我們有提到，除了對模型架構下功夫來提高正確率外，龐大的資料也是提高正確率最不可或缺的關鍵。我們訓練的資料越多、越完整，模型就能表現得越好！但一般來說，資料的收集往往是最大的痛點，收集資料比起改變模型結構，要來的困難許多。假如今天在資料有限的狀況下，又該如何創造新的資料呢？沒錯！最直接的方式就是進行資料增強！資料增強最主要的目的，就是透過一些”手法”來將一張圖擴增至2張以上，今天我手上有1000張圖片，那我就可以將數量增加到2000張甚至更多，比起1000張來進行訓練，2000張訓練出來的結果一定比較好！</p>
<img src="/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/pc03.png" class="" title="This is an image">
<p>(<a href="https://chtseng.wordpress.com/2017/11/11/data-augmentation-%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7/" target="_blank" rel="noopener">圖源</a>—&gt;因為我覺得這張圖呈現的很貼切，因此就引用了該網站的圖片來當圖片參考，這個人寫的也很不錯，歡迎參考他的文章內容)<br>這裡可能會有個疑問，同一張圖無論分裂幾百次，不都是同一張圖片嗎？這樣有意義？<br>答案是有意義的。在人類眼裡，這種行為是無意義的沒錯，因為不管怎麼看都是一樣的東西，是能變化出什麼花樣？但在機器眼裡，他就是一份新數據，機器去判斷不是靠肉眼，是靠一連串的計算和數字。因此這種「假」資料可以算一份訓練資料。</p>
<p>假歸假，這種假數據還是要靠特別的”手法”來騙過機器，而不是隨便從原圖複製幾張就行。<br>增強手法有很多種，常見的增強手法主要是靠旋轉、裁切、增加噪點、白化、拉長、放大縮小等…..，另外也有人特意去研究增強手法來當論文主題，因此每一天都有可能出現新的手法來騙機器。</p>
<h2 id="如何做資料增強？"><a href="#如何做資料增強？" class="headerlink" title="如何做資料增強？"></a>如何做資料增強？</h2><h3 id="一、了解增強手法"><a href="#一、了解增強手法" class="headerlink" title="一、了解增強手法"></a>一、了解增強手法</h3><p>首先回到一個根本的問題，為什麼要做資料增強？主要原因是資料取得不易，收集下來可能只有幾十張幾百張，無法訓練出好的模型，所以才會誕生出資料資強這種手段！<br>因此資料的收集還請做明確且不要馬虎，不要只拍個幾張圖片，然後用資料增強增加到1000張，這樣做的結果不會讓你正確率拉高，還可能會overfitting。資料增強不是資料處理的萬能解藥，這點還請多多注意！</p>
<p>本篇文章是用python語言裡的Keras Image Generator來進行。<br>現在網上查的文章，如果沒指定特定程式語言，大多都是用python來進行深度學習，我在學習也是用python，因此文章幾乎是用python語言寫的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">img_gen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>這段程式碼主要做的事情是來設定資料增強的手法。<br><code>from keras.preprocessing.image import ImageDataGenerator</code>是用來import我們需要的函式庫<br><code>img_gen = ImageDataGenerator(  )</code>的img_gen是變數，可以隨意取名字。<code>ImageDataGenerator(  )</code>則是我們設定資料增強的地方，(  )內填寫你需要的手法。</p>
<p>增強的手法怎麼設定?Keras官方文檔給出了不少手法供你設定，我一一列舉出來(親手整理的，沒有複製貼上喔~)：</p>
<ol>
<li>featurewise_center:<br>將輸入的資料均值設為0，並依特徵進行。使用布林值(True or False)</li>
<li>samplewise_center:<br>將每個樣本的均值設置為0。使用布林值(True or False)</li>
<li>featurewise_std_normalization:<br>將輸入的數據除以標準差，並依特徵進行。使用布林值(True or False)</li>
<li>samplewise_std_normalization:<br>將每個輸入的數據除以標準差。使用布林值(True or False)</li>
<li>zca_epsilon:<br>圖片白化。值默認為：1e-6。</li>
<li>zca_whitening:<br>是否要應用 ZCA 白化。使用布林值(True or False)</li>
<li>rotation_range:<br>隨機旋轉圖片的度數範圍。只接受整數數值</li>
<li>width_shift_range:<br>圖片寬度的某個比例，數據提升時圖片水平偏移的幅度。使用浮點數、一維數列或整数。<ul>
<li>float: 如果 &lt;1，則是除以總寬度的值，或者 &gt;=1，則為像素值。</li>
<li>1-D 數列: 數列中的隨機元素。</li>
<li>int: 來自間隔 (-width_shift_range, +width_shift_range) 之間的整數各像素。width_shift_range=2 時，可能值是整數 [-1, 0, +1]，與 width_shift_range= [-1, 0, +1] 相同；而 width_shift_range=1.0 時，可能值是 [-1.0, +1.0) 之間的浮點數。</li>
</ul>
</li>
<li>height_shift_range:<br>圖片長度的某個比例，數據提升時圖片水平偏移的幅度。使用浮點數、一維數列或整数。<ul>
<li>float: 如果 &lt;1，則是除以總寬度的值，或者 &gt;=1，則為像素質。</li>
<li>1-D 數列: 數列中的隨機元素。</li>
<li>int: 來自間隔 (-width_shift_range, +width_shift_range) 之間的整數各像素。width_shift_range=2 時，可能值是整數 [-1, 0, +1]，與 width_shift_range= [-1, 0, +1] 相同；而 width_shift_range=1.0 時，可能值是 [-1.0, +1.0) 之間的浮點數。</li>
</ul>
</li>
<li>shear_range:<br>剪切強度（逆時針方向的剪切變換角度）。使用浮點數。</li>
<li>zoom_range:<br>浮點數 或 [lower, upper]。隨機縮放範圍。<br>如果是浮點數，[lower, upper] = [1-zoom_range, 1+zoom_range]。</li>
<li>channel_shift_range:<br>隨機通道轉換的範圍。使用浮點數。</li>
<li>fill_mode:<br>當進行變換時超出邊界的點將根據本參數給定的方法進行處理：<br>{“constant”, “nearest”, “reflect” or “wrap”} 之一。默認為nearest。<ul>
<li>constant: kkkkkkkk|abcd|kkkkkkkk (cval=k)</li>
<li>nearest: aaaaaaaa|abcd|dddddddd</li>
<li>reflect: abcddcba|abcd|dcbaabcd</li>
<li>wrap: abcdabcd|abcd|abcdabcd</li>
</ul>
</li>
<li>cval:<br>用於邊界之外點的值。使用浮點數或整數。</li>
<li>horizontal_flip:<br>隨機水平翻轉。使用布林值(True or False)。</li>
<li>vertical_flip:<br>随機垂直翻轉。使用布林值(True or False)</li>
<li>rescale:<br>重新縮放因子。默認為 None。<br>如果是 None 或 0，則不進行縮放，否則將數據乘上所提供的值（在任何應用其他轉化之前）。</li>
<li>preprocessing_function:<br>應用於每個輸入的函數。這個函數會在任何其他改變之前運行。<br>這個函數需要一個參數：一張圖片（亦為 3 的 Numpy 張量），並且應該輸出一個同尺存的Numpy張量。</li>
<li>data_format:<br>圖像數據格式，{“channels_first”, “channels_last”} 之一。<br>“channels_last” 模式表示圖像輸入尺寸應該為 (samples, height, width, channels)，”channels_first” 模式表示輸入尺寸應該為 (samples, channels, height, width)。<br>默認為在 Keras 配置文件 ~/.keras/keras.json 中的 image_data_format 值。如果你未設置，那它就是 “channels_last”。</li>
<li>validation_split:<br>保留用於驗證的圖像比例（基本上是0-1之間）。使用浮點數</li>
<li>dtype:<br>生成數組用的數據類型。</li>
</ol>
<p>我知道一定有人沒看完，打那麼多字誰要看阿！對！是我也會放棄觀看。<br>能設定的東西是真的很多，而且有些設定十分的抽象，沒有實際的範例我想也很難懂，但相信我，在實作上用到的就那幾個，不用馬上去搞懂所有的設定，至於常用是哪幾個，應該就旋轉、裁切、增加噪點、白化、拉長、放大縮小等…..就這幾個手法在做，第一次接觸增強也可以只先做這幾種就好，等真的熟了再去嘗試其他的也不遲。<br><strong>題外話</strong><br>“資料增強時要用什麼手段”比較偏習慣和今天要學習的主題去做變化居多，如果第一次接觸沒有方向的話，建議去kaggle找別人的notebook看看，看多了就會發現大家常用的是哪幾個。我自己常用的就是上面那段程式碼裡面的設定，就給你們參考看看。</p>
<h3 id="二、flow、flow-from-directory、fit以及flow-from-dataframe的使用"><a href="#二、flow、flow-from-directory、fit以及flow-from-dataframe的使用" class="headerlink" title="二、flow、flow_from_directory、fit以及flow_from_dataframe的使用"></a>二、flow、flow_from_directory、fit以及flow_from_dataframe的使用</h3><p>做完上面的設定後，接著就是把這些手法套用至圖片上。<br>在套用前，我們必須要判斷一件事：你的訓練資料在處理前，是以什麼樣的形式呈現的？<br>我們在網路上找到的資料集大多有兩種形式：</p>
<ol>
<li>用各自類名命名的單獨資料夾中的所有圖像，A標籤的圖片全部集中在同一個資料夾中，以此類推。</li>
<li>所有圖像都存在於一個目錄中，並將圖片名稱與對應標籤寫入一個CSV或JSON文件中。</li>
</ol>
<p>這兩大類對資料處裡的方法會有所不同，這就是需要判斷的原因。<br>另外也關係到你接下來要用什麼樣的函數去進行資料增強，也就是文章的第二主題《flow、flow_from_directory、fit以及flow_from_dataframe的使用》，每個函數都有不太相同的使用時機，我自己也不是100%全熟，但我會把我目前用到的，介紹給各位。</p>
<p>※ 以下我會用數據生成器來代替”將資料增強手法套用至圖片”這個行為<br><strong>fit</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fit(x, </span><br><span class="line">    augment=<span class="literal">False</span>, </span><br><span class="line">    rounds=<span class="number">1</span>, </span><br><span class="line">    seed=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>將數據生成器套用至特定的數據上。<br>通常會用fit主要是圖片資料已經轉換成模型可以讀取的形式了(Numpy)，接著對這些數據套用fit就會幫你將這些資料進行增強。</p>
<ul>
<li>x：樣本數據，也就是這裡填寫你要增強的數據。</li>
<li>augment：是否隨機對數據進行增強。使用布林值(True or False)</li>
<li>rounds: 當 augment 為True，對該圖片要增強幾次。</li>
<li>seed: 使用種子碼隨機。</li>
</ul>
<p>下面是我寫程式時有用到fit的片段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>])</span><br><span class="line">datagen.fit(x_train)   &lt;---------這個地方</span><br><span class="line">x_train = x_train/<span class="number">255</span></span><br><span class="line">x_test = x_test/<span class="number">255</span></span><br><span class="line">x_val = x_val/<span class="number">255</span></span><br><span class="line">print(<span class="string">'rescale！done!'</span>)</span><br></pre></td></tr></table></figure>
<p>x_train是我的圖片訓練資料集，而下面的/255是在做歸一化，之前的文章有講到，這次就不多說了。</p>
<h3 id="flow"><a href="#flow" class="headerlink" title="flow"></a>flow</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">flow(x, </span><br><span class="line">     y=<span class="literal">None</span>, </span><br><span class="line">     batch_size=<span class="number">32</span>, </span><br><span class="line">     shuffle=<span class="literal">True</span>, </span><br><span class="line">     sample_weight=<span class="literal">None</span>, </span><br><span class="line">     seed=<span class="literal">None</span>, </span><br><span class="line">     save_to_dir=<span class="literal">None</span>, </span><br><span class="line">     save_prefix=<span class="string">''</span>, </span><br><span class="line">     save_format=<span class="string">'png'</span>, </span><br><span class="line">     subset=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>透過數據生成器可以將numpy的數組和標籤，進行批量的資料增強。<br>用法比較像fit的加強版。fit是對特定的數組進行增強，而flow除了做到fit的工作外，還能批量進行，並且還加上儲存的功能。</p>
<ul>
<li>x：樣本數據，也就是這裡填寫你要增強的數據。</li>
<li>y：標籤</li>
<li>batch_size: 批量數據的尺寸，默認為32。</li>
<li>shuffle: 是否混洗數據，講白點就是亂數打亂，默認為True。</li>
<li>save_to_dir: 是否要保存增強後的圖片，是的話填入要保存的路徑，默認為None。</li>
<li>save_prefix: 保存圖片的名稱前綴。</li>
<li>save_format: 二選一 “png” &amp; “jpeg” ，默認為”png”。</li>
<li>yields: 形如(x,y)的tuple，x是代表圖像數據的numpy數組，y是代表標籤的numpy數組。</li>
<li>seed: 是否用種子碼打亂數據。</li>
</ul>
<p>flow的使用是我這4個要介紹的數據生成器中，唯一沒使用過的生成器。<br>不過我在網上有找到不少範例，我用範例有稍微改了一下，應該可以Run起來的，自己測試還可以。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">img_gen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 將圖片轉成array並儲存至l陣列，再將l陣列轉成numpy</span></span><br><span class="line">l=[]</span><br><span class="line">img01 = load_img(<span class="string">r"圖片路徑/00001.jpg"</span>)  </span><br><span class="line">img02 = load_img(<span class="string">r"圖片路徑/00002.jpg"</span>)  </span><br><span class="line">x = img_to_array(img01)</span><br><span class="line">y = img_to_array(img02) </span><br><span class="line">l.append(x)</span><br><span class="line">l.append(y)</span><br><span class="line">l=np.array(l)</span><br></pre></td></tr></table></figure>



<p><strong>flow_from_dataframe</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">flow_from_dataframe(dataframe, </span><br><span class="line">                    directory, </span><br><span class="line">                    x_col=<span class="string">'filename'</span>, </span><br><span class="line">                    y_col=<span class="string">'class'</span>, </span><br><span class="line">                    has_ext=<span class="literal">True</span>, </span><br><span class="line">                    target_size=(<span class="number">256</span>, <span class="number">256</span>), </span><br><span class="line">                    color_mode=<span class="string">'rgb'</span>, </span><br><span class="line">                    classes=<span class="literal">None</span>, </span><br><span class="line">                    class_mode=<span class="string">'categorical'</span>, </span><br><span class="line">                    batch_size=<span class="number">32</span>, </span><br><span class="line">                    shuffle=<span class="literal">True</span>, </span><br><span class="line">                    seed=<span class="literal">None</span>, </span><br><span class="line">                    save_to_dir=<span class="literal">None</span>, </span><br><span class="line">                    save_prefix=<span class="string">''</span>, </span><br><span class="line">                    save_format=<span class="string">'png'</span>, </span><br><span class="line">                    subset=<span class="literal">None</span>, </span><br><span class="line">                    interpolation=<span class="string">'nearest'</span>)</span><br></pre></td></tr></table></figure>
<p>在此數據生成器輸入 dataframe 和圖片目錄的路徑，使其生成批量的增強數據。<br>這個函數常適用在資料形式為”所有圖像都存在於一個目錄中，並將圖片名稱與對應標籤寫入一個CSV或JSON文件中”的這一類。<br>flow_from_dataframe有超級多東西可以設定，可能對新手來說會花上不少時間。</p>
<ul>
<li>dataframe: Pandas dataframe，一列為圖像名稱，另一列為該圖像類別標籤，或是做為原始目標數據多個列。</li>
<li>directory: 字符串，目標目錄的路徑，也就是dataframe裡的所有圖像的路徑。</li>
<li>x_col: 字符串，dataframe 圖像名稱的列名稱，也就是圖像名稱該列的最上面名字，沒有的話就自行加個。</li>
<li>y_col: 字符串或字符串列表，圖像對應的標籤類別的列，與”x_col”雷同，一樣是沒有就自行加入。</li>
<li>has_ext: 如果 dataframe[x_col] 中的文件名具有擴展名則為 True，否則為 False。使用布林值(True or False)</li>
<li>target_size: 將圖片調整為(height, width)的尺寸，默認為 (256, 256)。只接受整數。</li>
<li>color_mode: 二選一 “grayscale” &amp; “rgb” 。默認為”rgb”。 圖像是否轉換為 1 個或 3 個顏色通道。</li>
<li>classes: 可選的類別列表 (例如， [‘dogs’, ‘cats’])。默認為None。 若沒有提供，則類比列表會自動從 y_col 中推理出來，y_col 將會被映射為類別索引）。包含從類名到類索引的映射的字典可以通過屬性 class_indices 獲得。</li>
<li>class_mode: 六選一 “categorical”, “binary”, “sparse”, “input”, “other” or None 之一。 默認為”categorical”。<br>決定返回標籤數組的類型：<br>categorical：  2D one-hot 編碼標籤。<br>binary： 1D 二進制標籤。<br>sparse： 1D 整數標籤。<br>input： 與輸入圖像相同的圖像（主要用於與自動編碼器一起使用）。<br>other： 將是 y_col 數據的 numpy 數組，<br>None： 不返回任何標籤（生成器只會產生批量的圖像數據，這對使用model.predict_generator(), model.evaluate_generator() 等很有用）。</li>
<li>batch_size: 批量數據的尺寸，默認為32。</li>
<li>shuffle: 是否混洗數據，講白點就是亂數打亂，默認為True。</li>
<li>seed: 是否用種子碼打亂數據。</li>
<li>save_to_dir: 是否要保存增強後的圖片，是的話填入要保存的路徑，默認為None。</li>
<li>save_prefix: 保存圖片的名稱前綴。</li>
<li>save_format: 二選一 “png” &amp; “jpeg” ，默認為”png”。</li>
<li>follow_links: 是否跟隨類子目錄的符號連結，默認為False。</li>
<li>subset: 決定資料的數據子集 (“training” 或 “validation”)，前提是 ImageDataGenerator 中有設定 validation_split。</li>
<li>interpolation: 在目標大小與加載圖像的大小不同時，用於重新採樣圖像的插值方法。 支持的方法有 “nearest”, “bilinear”, and “bicubic”。 如果安裝了 1.1.3 以上版本的 PIL 的話，同樣支持 “lanczos”。 如果安裝了 3.4.0 以上版本的 PIL 的話，同樣支持 “box” 和 “hamming”。 默認情況下，使用 “nearest”。</li>
</ul>
<p>下面是我寫程式時有用到flow_from_dataframe的片段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">df_train = pd.read_csv(<span class="string">"C:/**********/C1-P2_Train Dev/train2.csv"</span>,encoding=<span class="string">"utf8"</span>)</span><br><span class="line">img_gen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>],</span><br><span class="line">    validation_split=<span class="number">0.25</span>   <span class="comment">#設定驗證集</span></span><br><span class="line">)</span><br><span class="line">train_generator = img_gen.flow_from_dataframe(</span><br><span class="line">                                              dataframe=df_train,</span><br><span class="line">                                              directory=<span class="string">"C:/Users/**************/Crop_Train"</span>,</span><br><span class="line">                                              x_col=<span class="string">"image_id"</span>,</span><br><span class="line">                                              y_col=<span class="string">"grade"</span>,</span><br><span class="line">                                              batch_size=<span class="number">10</span>,</span><br><span class="line">                                              <span class="comment">#has_ext=False, </span></span><br><span class="line">                                              subset=<span class="string">"training"</span>, </span><br><span class="line">                                              class_mode=<span class="string">"categorical"</span>,</span><br><span class="line">                                              color_mode=<span class="string">"rgb"</span>,</span><br><span class="line">                                              target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line"></span><br><span class="line">val_generator = img_gen.flow_from_dataframe( </span><br><span class="line">                                          dataframe=df_train, </span><br><span class="line">                                          directory=<span class="string">"C:/**************/Crop_Train"</span>,</span><br><span class="line">                                          x_col=<span class="string">"image_id"</span>,</span><br><span class="line">                                          y_col=<span class="string">"grade"</span>, </span><br><span class="line">                                          batch_size=<span class="number">10</span>,</span><br><span class="line">                                          <span class="comment">#has_ext=False, </span></span><br><span class="line">                                          subset=<span class="string">"validation"</span>, </span><br><span class="line">                                          class_mode=<span class="string">"categorical"</span>, </span><br><span class="line">                                          color_mode=<span class="string">"rgb"</span>,</span><br><span class="line">                                          target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br></pre></td></tr></table></figure>
<p><code>flow_from_dataframe</code>函數裡有個<code>dataframe=df_train</code>，這個<code>df_train</code>是CSV檔，變數的宣告我寫在最上方。</p>
<p>另外這個範例有一個很重要的東西要講，各位應該有看到一個<code>validation_split=0.25</code>這個設定吧？<br>這個設定是用來設置驗證資料集，0.25代表拿訓練資料裡的25%來當驗證。</p>
<p>當<code>validation_split</code>有被設定後，接下來進行<code>flow_from_dataframe</code>這個函數就需要在設定裡加上<code>subset=&quot;validation&quot;或 &quot;training&quot;</code>。training代表訓練集，validation代表驗證集。<br>這也就是為什麼我宣告了兩次變數去進行<code>flow_from_dataframe</code>這個函數，因為我需要訓練集跟驗證集，兩個是要個別做宣告的。</p>
<p>那要進行訓練時要怎麼去應用上面的東西呢？<br>假設你已經建構好一個模型了，接下來要進行訓練。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model 代表你建置的模型名稱</span></span><br><span class="line">model.fit_generator(</span><br><span class="line">                    <span class="comment">#使用訓練集</span></span><br><span class="line">                    generator = train_generator,                                                 steps_per_epoch = step_size_train,</span><br><span class="line">                    <span class="comment">#使用驗證集</span></span><br><span class="line">                    validation_data = val_generator,    </span><br><span class="line">                    validation_steps = step_size_valid, </span><br><span class="line">                    epochs = <span class="number">10</span>,</span><br><span class="line">                    verbose = <span class="number">1</span>,</span><br><span class="line">                    callbacks = [RLR, ckptforall],</span><br><span class="line">                    use_multiprocessing = <span class="literal">False</span>,</span><br><span class="line">                    shuffle = <span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>訓練時就不是用<code>fit</code>了，而是用<code>fit_generator</code>。<br>裡面的設定也有小變化喔！各位應該有看到<code>batch_size</code>這個設定不見了吧？<br>在<code>fit_generator</code>這個函數裡，不會用到<code>batch_size</code>，就算用了也只會噴錯給你看。<br><code>batch_size</code>的不見，換來的是<code>steps_per_epoch = step_size_train</code>變成必填設定，怎麼設定？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">step_size_train = train_generator.n//train_generator.batch_size</span><br></pre></td></tr></table></figure>
<p>再加個<code>epochs</code>決定你要訓練幾次，這樣就是基本的訓練形式，可以直接進行訓練了。<br>如果還還要再加個驗證資料，那就是以下兩個設定要填：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">validation_data = val_generator,</span><br><span class="line">validation_steps = step_size_valid,</span><br></pre></td></tr></table></figure>
<p><code>validation_steps</code>中的<code>step_size_valid</code>設定怎麼用？就跟<code>steps_per_epoch</code>一樣：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">step_size_valid = val_generator.n//val_generator.batch_size</span><br></pre></td></tr></table></figure>
<p>範例中<code>fit_generator</code>剩下的設定就不是太必要的東西，算額外的設定，因此我就不多加說明。</p>
<p>總結上述的程式範例，整個流程為下圖：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#讀取csv檔</span></span><br><span class="line">df_train = pd.read_csv(<span class="string">"C:/********/C1-P2_Train Dev/train2.csv"</span>,encoding=<span class="string">"utf8"</span>)  </span><br><span class="line"><span class="comment"># 設定增強手法</span></span><br><span class="line">img_gen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>],</span><br><span class="line">    validation_split=<span class="number">0.25</span>   <span class="comment">#設定驗證集</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 進行資料增強於訓練資料中</span></span><br><span class="line">train_generator = img_gen.flow_from_dataframe(</span><br><span class="line">                                              dataframe=df_train,</span><br><span class="line">                                              directory=<span class="string">"C:/********/Crop_Train"</span>,</span><br><span class="line">                                              x_col=<span class="string">"image_id"</span>,</span><br><span class="line">                                              y_col=<span class="string">"grade"</span>,</span><br><span class="line">                                              batch_size=<span class="number">10</span>,</span><br><span class="line">                                              <span class="comment">#has_ext=False, </span></span><br><span class="line">                                              subset=<span class="string">"training"</span>, </span><br><span class="line">                                              class_mode=<span class="string">"categorical"</span>,</span><br><span class="line">                                              color_mode=<span class="string">"rgb"</span>,</span><br><span class="line">                                              target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line"><span class="comment"># 進行資料增強於驗證資料中</span></span><br><span class="line">val_generator = img_gen.flow_from_dataframe( </span><br><span class="line">                                          dataframe=df_train, </span><br><span class="line">                                          directory=<span class="string">"C:/**********/test/Crop_Train"</span>,</span><br><span class="line">                                          x_col=<span class="string">"image_id"</span>,</span><br><span class="line">                                          y_col=<span class="string">"grade"</span>, </span><br><span class="line">                                          batch_size=<span class="number">10</span>,</span><br><span class="line">                                          <span class="comment">#has_ext=False, </span></span><br><span class="line">                                          subset=<span class="string">"validation"</span>, </span><br><span class="line">                                          class_mode=<span class="string">"categorical"</span>, </span><br><span class="line">                                          color_mode=<span class="string">"rgb"</span>,</span><br><span class="line">                                          target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">                                          </span><br><span class="line">*********************過程中你建置了一個模型*********************                                           </span><br><span class="line"><span class="comment"># model 代表你建置的模型名稱</span></span><br><span class="line"><span class="comment"># 進行訓練</span></span><br><span class="line">model.fit_generator(</span><br><span class="line">    generator = train_generator,        <span class="comment"># 訓練資料集                          </span></span><br><span class="line">    steps_per_epoch = step_size_train,</span><br><span class="line">    validation_data = val_generator,    <span class="comment"># 驗證資料集</span></span><br><span class="line">    validation_steps = step_size_valid, </span><br><span class="line">    epochs = <span class="number">10</span>,</span><br><span class="line">    verbose = <span class="number">1</span>,</span><br><span class="line">    callbacks = [RLR, ckptforall],</span><br><span class="line">    use_multiprocessing = <span class="literal">False</span>,</span><br><span class="line">    shuffle = <span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>不要直接複製起來用喔！應該會噴錯，因為這只是一個概念流程圖。</p>
<p><strong>flow_from_directory</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">flow_from_directory(directory, </span><br><span class="line">                    target_size=(<span class="number">256</span>, <span class="number">256</span>), </span><br><span class="line">                    color_mode=<span class="string">'rgb'</span>, </span><br><span class="line">                    classes=<span class="literal">None</span>, </span><br><span class="line">                    class_mode=<span class="string">'categorical'</span>, </span><br><span class="line">                    batch_size=<span class="number">32</span>, </span><br><span class="line">                    shuffle=<span class="literal">True</span>, </span><br><span class="line">                    seed=<span class="literal">None</span>, </span><br><span class="line">                    save_to_dir=<span class="literal">None</span>, </span><br><span class="line">                    save_prefix=<span class="string">''</span>, </span><br><span class="line">                    save_format=<span class="string">'png'</span>, </span><br><span class="line">                    follow_links=<span class="literal">False</span>, </span><br><span class="line">                    subset=<span class="literal">None</span>, </span><br><span class="line">                    interpolation=<span class="string">'nearest'</span>)</span><br></pre></td></tr></table></figure>
<p>這個數據生成器最主要目的是從圖片資料夾裡抓出圖片，接著對該圖片進行增強後再儲存至指定路徑中，不會去管標籤類別。<br>因此<code>flow_from_directory</code>適用於”用各自類名命名的單獨資料夾中的所有圖像，A標籤的圖片全部集中在同一個資料夾中，以此類推”的形式。</p>
<ul>
<li>directory: 欲增強的圖片資料夾路徑，資料夾內接受 PNG, JPG, BMP, PPM 或 TIF 格式的圖像。。</li>
<li>target_size: 將圖片調整為(height, width)的尺寸，默認為 (256, 256)。只接受整數。</li>
<li>color_mode: 二選一 “grayscale” &amp; “rgb” 。默認為”rgb”。 圖像是否轉換為 1 個或 3 個顏色通道。</li>
<li>classes: 可選的類別列表 (例如， [‘dogs’, ‘cats’])。默認為None。 若沒有提供，則類比列表會自動從 y_col 中推理出來，y_col 將會被映射為類別索引）。包含從類名到類索引的映射的字典可以通過屬性 class_indices 獲得。</li>
<li>class_mode: 六選一 “categorical”, “binary”, “sparse”, “input”, “other” or None 之一。 默認為”categorical”。<br>決定返回標籤數組的類型：<br>categorical：  2D one-hot 編碼標籤。<br>binary： 1D 二進制標籤。<br>sparse： 1D 整數標籤。<br>input： 與輸入圖像相同的圖像（主要用於與自動編碼器一起使用）。<br>other： 將是 y_col 數據的 numpy 數組，<br>None： 不返回任何標籤（生成器只會產生批量的圖像數據，這對使用model.predict_generator(), model.evaluate_generator() 等很有用）。這裡要特別留意，如果 class_mode 為 None，數據仍然需要留在 directory 的子目錄才能正常運作。</li>
<li>batch_size: 批量數據的尺寸，默認為32。</li>
<li>shuffle: 是否混洗數據，講白點就是亂數打亂，默認為True。</li>
<li>seed: 是否用種子碼打亂數據。</li>
<li>save_to_dir: 是否要保存增強後的圖片，是的話填入要保存的路徑，默認為None。</li>
<li>save_prefix: 保存圖片的名稱前綴。</li>
<li>save_format: 二選一 “png” &amp; “jpeg” ，默認為”png”。</li>
<li>follow_links: 是否跟隨類子目錄的符號連結，默認為False。</li>
<li>subset: 決定資料的數據子集 (“training” 或 “validation”)，前提是 ImageDataGenerator 中有設定 validation_split。</li>
<li>interpolation: 在目標大小與加載圖像的大小不同時，用於重新採樣圖像的插值方法。 支持的方法有 “nearest”, “bilinear”, and “bicubic”。 如果安裝了 1.1.3 以上版本的 PIL 的話，同樣支持 “lanczos”。 如果安裝了 3.4.0 以上版本的 PIL 的話，同樣支持 “box” 和 “hamming”。 默認情況下，使用 “nearest”。</li>
</ul>
<p>這是我使用<code>flow_from_directory</code>時的程式片段，下面我會稍微做個解釋：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    vertical_flip=<span class="literal">True</span>,</span><br><span class="line">    rotation_range=<span class="number">10</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    zoom_range=<span class="number">.1</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>,</span><br><span class="line">    shear_range=<span class="number">0.1</span>,</span><br><span class="line">    rescale=<span class="number">1</span>/<span class="number">255</span>,</span><br><span class="line">    brightness_range=[<span class="number">0.5</span>, <span class="number">1.5</span>])</span><br><span class="line">train_dir = <span class="string">r'C:/********************/test/'</span></span><br><span class="line">train_generator = datagen.flow_from_directory(</span><br><span class="line">          train_dir,</span><br><span class="line">          target_size=(<span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line">          batch_size=<span class="number">1</span>,</span><br><span class="line">          shuffle=<span class="literal">False</span>,</span><br><span class="line">          save_to_dir=<span class="string">'C:/Users/*********/C1-P2_Train Dev/Train_dataFrame/'</span>,</span><br><span class="line">          save_prefix=<span class="string">'train'</span>,</span><br><span class="line">          save_format=<span class="string">'jpg'</span>,</span><br><span class="line">          class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">45000</span>):</span><br><span class="line">    train_generator.next()</span><br><span class="line">    <span class="keyword">if</span> (i%<span class="number">100</span> == <span class="number">0</span>):</span><br><span class="line">        print(<span class="string">"."</span>, end=<span class="string">''</span>)</span><br><span class="line">print(<span class="string">"down"</span>)</span><br></pre></td></tr></table></figure>
<p>前面的應該大家都熟了，就是增強手法的設定，主要是下面的程式碼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">train_dir = <span class="string">r'C:/********************/test/'</span></span><br><span class="line">train_generator = datagen.flow_from_directory(</span><br><span class="line">          train_dir,</span><br><span class="line">          target_size=(<span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line">          batch_size=<span class="number">1</span>,</span><br><span class="line">          shuffle=<span class="literal">False</span>,</span><br><span class="line">          save_to_dir=<span class="string">'C:/***************/C1-P2_Train Dev/Train_dataFrame/'</span>,</span><br><span class="line">          save_prefix=<span class="string">'train'</span>,</span><br><span class="line">          save_format=<span class="string">'jpg'</span>,</span><br><span class="line">          class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">45000</span>):</span><br><span class="line">    train_generator.next()</span><br><span class="line">    <span class="keyword">if</span> (i%<span class="number">100</span> == <span class="number">0</span>):</span><br><span class="line">        print(<span class="string">"."</span>, end=<span class="string">''</span>)</span><br><span class="line">print(<span class="string">"down"</span>)</span><br></pre></td></tr></table></figure>
<p><code>train_dir</code>是變數，記錄訓練資料的資料夾路徑。<br>這裡有兩個很重要的地方：</p>
<ol>
<li>資料夾路徑不是寫到目標資料夾的所在位置，而是所在位置的上一層，假如目標資料夾的路徑為”A/B/C/目標資料夾”，那寫法就是”A/B/C”，這樣子就可以停了。</li>
<li>目標資料夾所在的位置，最好是只放單獨的資料夾，也就是只放目標資料夾，不然很容易噴路徑錯誤。我至今也沒搞懂為何會這樣，就當有個限制在，怕衍伸出不必要的麻煩。<br>我用圖片來說明會比較好：<img src="/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/pc01.jpg" class="" title="This is an image">
Crop_Train資料夾是我的訓練資料集，而它路徑上一層test就是Crop_Train的所在位置。這個位置只能放一個資料夾。</li>
</ol>
<p><code>train_generator = datagen.flow_from_directory( )</code>就是本次數據生成器主要的核心，裡面的設定我不細講，上面我有做說明了。</p>
<p>在這邊你可以先嘗試Run一下，有個小細節要讓各位知道。<br>我們不是做完資料增強了嗎？現在Run下去，<code>save_to_dir</code>這個路徑裡是不是就會有增強後的圖片了？<br>答案是：沒半張。<br>我當時也是傻眼，沒道理阿！之前的<code>flow_from_directory</code>或是<code>fit</code>使用下去就有結果了，為什麼<code>flow_from_directory</code>照著<code>flow_from_directory</code>的邏輯走，結果會沒反應呢？</p>
<p>我也另外爬文查這個問題了，好笑的是，天下一大抄，全部抄官方文檔或是別人的example，半字不提這個情況…..，所以等我查到這個問題的核心前，就當是一個未解之謎。</p>
<p>不過不是不能用，就只是要多加個for迴圈</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">45000</span>):</span><br><span class="line">    train_generator.next()</span><br></pre></td></tr></table></figure>

<p>45000是因為我的訓練集有45000張圖片，我要所有的圖片都進行增強。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (i%<span class="number">100</span> == <span class="number">0</span>):</span><br><span class="line">        print(<span class="string">"."</span>, end=<span class="string">''</span>)</span><br></pre></td></tr></table></figure>
<p>後面我有多加這個，主要是想知道圖偏增強進行到哪了。<br>output的結果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Found 45000 images belonging to 1 classes.</span><br><span class="line">..................................................................................................................................................................................................................................................................................................................................................................................................................................................................down</span><br></pre></td></tr></table></figure>
<p>實際的結果：</p>
<img src="/2020/09/21/%E8%B3%87%E6%96%99%E5%A2%9E%E5%BC%B7ImageGenerator-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/pc02.jpg" class="" title="This is an image">
<p>左邊第一張對應右邊第一張，以此類推。<br>跟原圖片不太相同，但仔細去看的話，其實跟原圖片有很多相似處，這個就是資料增強。<br>要先說明一下，我只對原圖片增強一次，<code>batch_size</code>我設定1而已喔！如果一張要變成好幾張，還請把<code>batch_size</code>調高。</p>
<h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p>[<a href="https://keras.io/zh/preprocessing/image/]" target="_blank" rel="noopener">https://keras.io/zh/preprocessing/image/]</a><br>[<a href="https://kknews.cc/zh-tw/code/yeg6oba.html]" target="_blank" rel="noopener">https://kknews.cc/zh-tw/code/yeg6oba.html]</a><br>[<a href="https://www.itread01.com/content/1546542668.html]" target="_blank" rel="noopener">https://www.itread01.com/content/1546542668.html]</a></p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E7%9A%84Hello_World-%E6%89%8B%E5%AF%AB%E6%95%B8%E5%AD%97%E8%BE%A8%E8%AD%98/">World-手寫數字辨識</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-08T07:17:20.000Z" itemprop="datePublished">
    2020-09-08
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">實作心得</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/jupyter-notebook/">jupyter notebook</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h3 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h3><p>記錄我在研究所學習深度學習的知識與心得。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明如何利用tensorflow來寫一個最基礎的深度學習範例，相當於學習程式語言的hello world。我會盡量將每個程式碼進行解釋，也保持著盡量說人話的方式來說明，太多專有名詞換作是我去看這類的文章，也一定很想關掉頁面。所以請抱持放鬆的心情來看文章！</p>
<h3 id="前置步驟-amp-注意事項"><a href="#前置步驟-amp-注意事項" class="headerlink" title="前置步驟&amp;注意事項"></a>前置步驟&amp;注意事項</h3><ol>
<li>本心得教學是使用tensorflow來進行撰寫。怎麼裝tensorflow？我有另外寫了<a href="https://chenchianstudent.github.io/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/" target="_blank" rel="noopener">文章</a>。</li>
<li>我必須強調一下，本人在寫這篇文章時還是學習中的學生，算是初心者。內容若是有錯，誤導大家還請多多包涵！之後發現自己有說錯話，也會去重新修文章，你發現我有說錯話，也請告訴我哪裡錯了。</li>
<li>深度學習的一些專有名詞和要表達的概念實在太多了，如果漏掉了還請多多包涵。</li>
<li>模型訓練的過程中，有些參數若是照我的內容抄，結果執行時噴錯，原因很有可能是設備性能造成的。我的指導老師說了一句我覺得蠻中肯的話:深度學習也是一種軍備競賽，裝備差的人能表現的實在有限。</li>
<li>若是範例跑不動，可以採用colab。colab是google發明類似jupyter notebook的程式編譯器，是線上的，有網路就可以在瀏覽器上使用，有興趣可以試試，目前是免費的，但不保證未來也是免費喔！colab的教學我再考慮看看要不要另外寫一篇來說。</li>
<li>什麼是深度學習？請參考這篇<a href="https://chenchianstudent.github.io/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/" target="_blank" rel="noopener">文章</a></li>
</ol>
<h2 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h2><p>本文章對應的github專案，內容全是我自己寫的，歡迎大家參考，也請查看專案的 readme.md ，它會教你怎麼使用。<br>網址：<a href="https://github.com/chenchianstudent/DeepLearing-test" target="_blank" rel="noopener">https://github.com/chenchianstudent/DeepLearing-test</a></p>
<h3 id="了解資料內容-什麼是手寫數字辨識資料集"><a href="#了解資料內容-什麼是手寫數字辨識資料集" class="headerlink" title="了解資料內容-什麼是手寫數字辨識資料集?"></a>了解資料內容-什麼是手寫數字辨識資料集?</h3><p>簡單來說，它是一個很多張圖片的資料夾。<br>內容是一般人從數字0寫到9的圖片，不同人寫下並拍照，最後匯集在一起變成手寫數字資料集。手寫數字資料集從很久以前就有人在使用了，它不是最近才出現的，當時創造這份資料的主要目標，是想辦法透過手寫資料集讓電腦能正確判斷人寫的數字，也就是這篇文章要做的事情。<br>在以前這是一份很艱難的任務，但自從深度學習興起後，電腦辨識手寫數字這份任務就變得很簡單！而且辨識率可以達到99%以上，比人類辨識還要精準！</p>
<h3 id="程式內容"><a href="#程式內容" class="headerlink" title="程式內容"></a>程式內容</h3><p>以下為等等要講解的程式內容，也就是一個手寫數字辨識的實際範例<br>完整程式在我的Github <a href="https://github.com/chenchianstudent/DeepLearing-Test" target="_blank" rel="noopener">Deep Learing-test</a>專案中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<p>一共15行，解決以前的大難題，很厲害吧！<br>接下來要做的就是講解這15行在幹嘛，但因為一次說明會很複雜，因此我會將程式分成5個部分，就像jupyter notebook一樣。<br>第一部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>第二部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br></pre></td></tr></table></figure>
<p>第三部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>第四部份</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p>第五部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>

<h3 id="程式講解-第一部分"><a href="#程式講解-第一部分" class="headerlink" title="程式講解-第一部分"></a>程式講解-第一部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>這是我們最一開始必須import的函式庫，也就是我們的主角tensorflow，接下來會用tensorflow來進行深度學習。<br>而<code>import tensorflow as tf</code>的<code>as tf</code>則是將tensorflow做簡稱，等等在寫程式時如果要用到tensorflow時，只需要打tf電腦就會呼叫tensorflow了。<br>基本上你查文章時很多人都是將tensorflow簡稱tf的，希望各位初學者也養成這個習慣。<br>一來大家看你程式碼時比較不會多想，因為大家都知道tf是什麼，二來是你養成習慣後，查文章看到tf也可以知道作者是在表達什麼，對大家都好，tf這習慣不強制性，但養成會更好。<br>再來我們說說下行的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>如果有寫過程式的人，應該會很明白的這是要做print出一個值的動作。<br>問題是這個值是什麼？<br>很簡單，version的中文是”版本”，整句的意思：print出tensorflow的版本。</p>
<p>關於第一部分程式碼的注意事項:</p>
<ol>
<li>version旁邊的__是特殊寫法，為什麼這樣寫——–&gt;沒為什麼，就是tensorflow的規定。</li>
<li><code>__version__</code> 的<em>_ 一邊是兩個_，左右兩邊共4個</em> &lt;——-反正寫錯會跳error，你就會記得了。</li>
<li>tf就是我們上面講的，tensorflow的代稱。</li>
</ol>
<h3 id="程式講解-第二部分"><a href="#程式講解-第二部分" class="headerlink" title="程式講解-第二部分"></a>程式講解-第二部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br></pre></td></tr></table></figure>
<p><code>mnist = tf.keras.datasets.mnist</code>的整句意思為以mnist這個變數來存取數字辨識資料集。<br>mnist的意思是手寫數字辨識，你在google打上mnist就會跑出很多手寫數字辨識的文章或資料集。<br>奇怪？我都沒有下載手寫數字資料集，為什麼就能存取數字辨識了？<br>原因就是這個<code>tf.keras.datasets</code>，tensorflow裡面就有內建手寫數字辨識了，我們去呼叫tensorflow資料庫裡的mnist手寫數字辨識就好了，tensorflow將很多大家常用的資料集都放到自己的資料庫了，有興趣的可以上網查一下這個資料庫裡有什麼，今次只講解mnist，因此就不花時間說明。<br>這是我們剛抓進來的<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">mnist資料集詳細資料</a>，可以看一下！<br>資料集內容大概是長這樣</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train-images-idx3-ubyte.gz:  training set images (9912422 bytes)</span><br><span class="line">train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)</span><br><span class="line">t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)</span><br><span class="line">t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)</span><br></pre></td></tr></table></figure>
<p>四個檔案—&gt;training的圖片和標籤(2個)+test的圖片和標籤(2個)<br>為什麼我要突然講資料內容，因為接下來的程式講解會用到這些來說明，老師當初上課不講害我查很久才知道這是在幹嘛的==<br><code>(x_train, y_train), (x_test, y_test) = mnist.load_data()</code>這行跟下行程式碼是比較困難的地方，我想辦法講的簡單一點。<br>想來說說這些x跟y是甚麼東西好了：<br>x_train = 等等要拿去讓機器訓練的數字圖片集<br>y_train = 等等要拿去讓機器訓練的數字標籤集<br>x_test = 機器訓練好後拿來做驗證的數字圖片集<br>y_test = 機器訓練好後拿來做驗證的數字標籤集<br>再將這個代稱拆解<br>x代表圖片集<br>y代表標籤集<br>train代表訓練用<br>test代表測試用<br>合起來就是<code>(x_train, y_train), (x_test, y_test)</code>然後進行讀取資料<code>mnist.load_data()</code>，目的就是讓這些資料轉變成等等要建立的模型能讀取的型態，就是這樣。<br>讀取型態大概就是長這樣<br>訓練用的(‘圖片’,’標籤’)<br>測試用的(‘圖片’,’標籤’)<br>另外圖片是一大串數字，這些數字就是圖片數字化的樣子，你可以print一下x裡的東西看一下長怎樣！</p>
<p><code>x_train, x_test = x_train / 255.0, x_test / 255.0</code>這行是資料處理，目的是讓等等建立的模型做訓練時可以比較好訓練找出規則。<br>主要的意思是對訓練和測試的圖片(已數字化)都除255.0當作資料再存取。<br>這個行為是所謂的<strong>歸一化</strong>，因為圖片為彩色RGB，值是0-255的數字，我們將這些色彩圖進行/255.0後會將這些數值縮小到0-1之間，好處是模型做計算時會比較好算，百位數跟個位數哪個比較好算，當然是個位數！另外就是防止overfitting，不會因為這張圖色彩在某個區間而認為這就是規則而當作辨識條件。</p>
<p>關於第二部分程式碼的注意事項:</p>
<ol>
<li>為什麼要除255.0而不是255？因為我們要它的小數點，因為歸一化是在0-1數字之間，就是小數點阿！</li>
<li>你可以發現我們做歸一化都是在圖片集上，標籤集不用做喔！</li>
<li>不用做歸一化其實也可以，這是一種資料處理的手法，不是絕對必要的動作。</li>
</ol>
<h3 id="程式講解-第三部分"><a href="#程式講解-第三部分" class="headerlink" title="程式講解-第三部分"></a>程式講解-第三部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>這部分就是在做建立模型(model)。<br>建立模型是深度學習最精華的地方，我們前面都是在做資料處理，目的就是讓現在我們建立的模型能夠讀取，也就是說，這裡是主菜。<br><code>model = tf.keras.models.Sequential([ ])</code>這裡是tensorflow建立模型的寫法。<br>這裡我覺得要用比喻的方式來說明，假如我們現在正在創造一個機器人，<code>model = tf.keras.models.Sequential([ ])</code>就是在做機器人的外殼，讓機器人有個形狀，告訴各位我要做一個機器人，model這個變數則是告訴大家機器人叫model。<br>機器人有了外殼後，接下來就是將空殼加入零件讓他能夠動起來。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br></pre></td></tr></table></figure>
<p>這些就是我們的零件，這段程式就是在建構我們的神經層。<br>其中你們有看到Flatten、Dense、Dropout這幾個英文單字，這些是利用keras在做建構網路層時會使用到的東西。</p>
<p><strong>Flatten層</strong><br>功能是將我們讀入的資料攤平攤開，把多維的輸入一维化，通常我們是把Flatten層當卷積層到全連結層的過渡層。而<code>input_shape=(28, 28)</code>則是設定Flatten層資料讀取進來的大小28*28。</p>
<p><strong>Dense層</strong><br>就是我們大家常說的全連接層，建立神經層。Dense層會用到很多參數，但是不一定每次建Dense層時，會對每個參數做設定。像這次我們只動用到2個參數，分別是unit與activation。以<code>tf.keras.layers.Dense(128, activation=&#39;relu&#39;)</code>來做解釋好了，裡面的參數寫的詳細點就是(unit = 128, activation = ‘relu’)。</p>
<ul>
<li>unit：就是我們神經元，要在神經層裡設定多少個神經元，就是在這裡設定，一般我們在做設定神經元時，只會寫數字，不會寫”unit = “。</li>
<li>activation：中文名叫激活函數，激活函數的設定有很多，這段程式中我用了兩次Dense層，而這兩層都有用到激活函數，分別是relu與softmax。這些設定我無法用人話說，因為真的是數學抽象東西….若真的想了解，請參考<a href="https://keras.io/zh/activations/" target="_blank" rel="noopener">Keras-激活函数 Activations</a>，他會告訴你在幹嘛……</li>
</ul>
<p><strong>Dropout層</strong><br>其功用在將訓練過程中每次更新參數時按一定比率斷開輸入神經元，人話的意思是在丟到一些參數結果進下一神經元，其目的防止overfitting。</p>
<p>程式內一些注意事項</p>
<ol>
<li>最後一行的Dense層為什麼是10，原因是我們輸出結果是0-9共10個數字，因此我們會需要10個神經元。</li>
<li>Dense層是建構模型裡不可或缺的零件，請一定要加Dense層。</li>
<li>Dropout層可加可不加，其實你玩久了就會發現有些建立模型的小規則和習慣，各位在建神經層時可以試試有加跟沒加的訓練結果長怎樣。</li>
<li>input_shape為什麼是28 X 28，原因是這些手寫數字圖片是28 X 28，讓模型讀取訓練資料前，還請讓這些訓練資料修正至統一大小，不然會無法讀取！今天的範例為什麼沒做修正，原因是這些圖片都已經變成28 X 28，不用再做修正，範例比較簡單些，之後如果要自己找資料練習，就會遇到圖片處理這個環節。</li>
</ol>
<h3 id="程式講解-第四部份"><a href="#程式講解-第四部份" class="headerlink" title="程式講解-第四部份"></a>程式講解-第四部份</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>
<p><code>model.compile()</code>是用來選擇這個模型的目標以及求解方法。<br>如果要用上面機器人的例子來說的話，就是對這些在機器人裡的零件建立好規則、教導怎麼運作來防止不會出錯。今天機器人目標是要走路，那就要制訂好規則是用四肢爬還是二肢走，手腳要怎麼運作才能正常走路等類似的概念。<br>在模型中，我們尋求解決方法會用compile(編譯)函數定義損失函數(loss)、優化函數(optimizer)及成效衡量指標(mertrics)。</p>
<p><strong>優化函數(optimizer)</strong><br>我們建立起來的模型在學習訓練的時候會一個名叫學習率的東西，它是負責控制梯度的收斂程度，如果單次更新學習率的值過高，收斂方向的速度就會變快，但這裡又說一句話，越快並不一定是最好的方法，梯度下降的收斂過程就像走小山丘，太大會暴衝會不穩，太小收斂會太慢，或是卡在局部解(local minimum)而跨不出來了。為了讓學習率更能找到我們要的最底點，就會採取像Adam的優化函數來控制α。</p>
<p><strong>損失函數(loss)</strong><br>損失函數是神經網路定義要收斂的對象函數。因為我們有龐大的參數節點(神經元)，可以擬合任意函數，我們可以不用知道權重跟bias的值明確要設多少，但可以靠反向傳播做梯度下降，讓函數逐步收斂，直到逼近最低點(global minimum)。<br>好像不是太人話，但這裡我有點想不到能用什麼例子來比喻，大概就是我們會需要定義一個損失函數來尋找最底點這樣子。</p>
<p><strong>效衡量指標(mertrics)</strong><br>用來評估訓練和測試之間的模型標準，通常我們會用’accuracy’。<br>目前我看了很多模型，幾乎都是用’accuracy’。</p>
<h3 id="程式講解-第五部份"><a href="#程式講解-第五部份" class="headerlink" title="程式講解-第五部份"></a>程式講解-第五部份</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<p>這裡就是最後一步了，恭喜你堅持到這裡！<br>機器人零件裝好了，怎麼動的規則也建立好了，最後就是要進行測試是不是我們要的結果。<br>沒錯！最後的程式碼就是在進行測試以及評估的動作，確認是我們要的答案。<br><code>model.fit()</code>用來進行模型的訓練。其中你會看到(  )內使用了測試圖片集與標籤集x_train &amp;  y_train，意思就是我要拿這兩份資料來讓模型進行訓練，從這些訓練資料找出規則，進而讓電腦自行找到辨識最佳解。<br>而<code>epochs</code>是訓練次數，我們訓練一次模型時，會更改神經元上的變數權重以利形成良好的辨識規則，但通常模型訓練時不會一次訓練就是最佳解，學腳踏車不太可能一騎上去就會吧？要多騎幾次去累積經驗才能正常騎腳踏車。模型也是如此，我們會讓模型訓練完一次後，讓訓練完後的模型再進行訓練，直到規定的訓練次數都完成為止。當然要訓練幾次就是一個經驗，答案不是你所希望的，就是再訓練或是重新再來一次。<br>另外，因為這裡只是一個很簡單的範例程式，用到的設定其實還蠻少的，實際找例子做會有很多設定會去設，之後我會找機會說，如果你等不下去想早點知道，就參考<a href="https://keras.io/zh/models/model/" target="_blank" rel="noopener">這份文章</a>吧：！</p>
<p><code>model.evaluate(x_test, y_test)</code>則是評估你的模型正確率。當你得到了一個你滿意的模型就可以拿測試資料進行評估正確率，確認拿新的資料來辨識時，是不是也能如期的辨識出正確的答案。</p>
<p><strong>output</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 112us&#x2F;sample - loss: 0.2889 - acc: 0.9142</span><br><span class="line">Epoch 2&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 97us&#x2F;sample - loss: 0.1397 - acc: 0.9582</span><br><span class="line">Epoch 3&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 95us&#x2F;sample - loss: 0.1049 - acc: 0.9682</span><br><span class="line">Epoch 4&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 97us&#x2F;sample - loss: 0.0847 - acc: 0.9739</span><br><span class="line">Epoch 5&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 99us&#x2F;sample - loss: 0.0728 - acc: 0.9769</span><br><span class="line">10000&#x2F;10000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 69us&#x2F;sample - loss: 0.0758 - acc: 0.9779</span><br><span class="line"></span><br><span class="line">[0.07581472408375703, 0.9779]</span><br></pre></td></tr></table></figure>

<p>從output裡，我們有很多東西需要知道，這些在模型訓練時給予了我們很多重要的資訊來評估是不是更改我們的模型或是這就是我們要的模型。<br>我們從<code>60000/60000 [==============================] - 7s 112us/sample - loss: 0.2889 - acc: 0.9142</code>這裡來做講解好了，這段代表模型訓練完成一次了！</p>
<p><code>60000/60000 [==============================] - 7s 112us/sample</code>是電腦在模型訓練時所花費的時間，現在這個狀態是100%，所以旁邊的秒數是寫整個過程花費的時間。當訓練還在進行時，7s這個位置就會變成距離訓練完成所剩餘的時間。</p>
<p><code>loss: 0.2889 - acc: 0.9142</code>是我們主要看的地方，loss就是損失函數，而acc則是整體正確率，正確率為0.9142(91.42%)。每一次訓練完成都會顯示loss與acc，這些資訊就是訓練時主要看的。你可以發現output中每次訓練完成後，acc會提升，這也說明了模型越來越能找到規則，能夠辨識的正確率可以提升起來。</p>
<p><code>[0.07581472408375703, 0.9779]</code>是<code>model.evaluate()</code>的output。拿一份新的資料去進行辨識，loss和acc會是多少，就是output顯示的樣子。做這個目的在於確認模型沒有overfitting，也許在訓練時，模型把訓練資料裡全部的特徵都記住了，也就是連無關緊要的特徵也納入辨識規則中，導致正確率才會那麼高！因為訓練都是拿同一份資料。假如拿一份不是訓練資料裡的圖片去辨識，可能會因為這些無關緊要的特徵而判斷錯誤，我們要避免的就是這個！評估一下拿新的資料去辨識是不是與訓練時的正確率一樣，正是評估的主要意義。</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/">深度學習？！為什麼最近大學和資訊界都能聽到這個詞？</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-09-08T07:05:57.000Z" itemprop="datePublished">
    2020-09-08
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Deep-Learning/">Deep Learning</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-Deep-Learning/">深度學習 Deep Learning</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h3 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h3><p>因為碩士選擇了人工智慧，於是便開始接觸tensorflow。學習過程中發現深度學習，比我在大學四年所學到的東西還要來的難！到目前為止，我每天被深度學習困擾到開始有壓力，因此，我想說先把我手上學到的東西整理成文章，一來方便自己重新閱讀，二來寫文章時可以再重新複習一遍我學到的東西，甚至在寫文章時可以把一些模糊的觀念釐清一下，在這些想法的驅使下，決定來寫看看。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明什麼是深度學習，也算是我接下來寫文章的序言，一切的開頭。</p>
<h3 id="為什麼要學深度學習"><a href="#為什麼要學深度學習" class="headerlink" title="為什麼要學深度學習?"></a>為什麼要學深度學習?</h3><p>阿我就想學阿！沒人逼你學！阿不是…..目前在資訊界裡最常聽到的名詞之一應該就是AI(人工智慧)了！我們生活環境也開始慢慢出現跟AI應用有關的產品，好比說特斯拉的自動駕駛系統，駕駛只要輸入目的地，就可以睡覺了，因為特斯拉會自動幫你駕駛到目的地，完全不需要人為介入，這就是一個AI應用的例子。聽起來非常厲害，對！真的非常厲害，如果你心中產生了非常厲害的想法，那就是為什麼有人要去學深度學習的原因了。因為這種自駕車的技術，就是從深度學習延伸出來的應用，想必未來的各種產品也會朝著這種技術去發展，AI應用的例子真的很多，不止是自駕車技術，但因為礙於篇幅長度，所以只提一個例子來佐證，現階段深度學習還是一種新興的技術，各企業搶著要這類的人才，故薪水也不會差到哪裡去，這也是為什麼我想學的原因，當然也有被這種厲害的感覺所吸引。<br>回到標題為什麼要學深度學習，為何要下這種標題？其實算是再三提醒我學深度學習的初衷，盡管最近真的超想放棄，學到快吐血，但我也必須堅持住，因為這個厲害的感覺也許就換我給別人了。</p>
<h3 id="何謂深度學習"><a href="#何謂深度學習" class="headerlink" title="何謂深度學習?"></a>何謂深度學習?</h3><p>深度學習是人工智慧的其中一種技術，人工智慧算是眾多技術合在一起的統稱。若今天別人說AI，也並不代表是在說深度學習，可能再說其他相關技術。但目前為止，深度學習是AI的主流，最近開始流行AI也是要歸功於深度學習的興起，也有不少人把AI的這詞投影在深度學習裡。恩….有對有錯拉！聽得懂就好了，不過我還是要再強調一下，深度學習只是人工智慧的其中技術，就像下圖表示的，儘管深度學習是AI大主流，但依舊只是人工智慧裡的一環而已，在未來跟別人討論AI時，也請將這個知識視為常識，不然懂的人聽到其實滿尷尬的。</p>
<img src="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/pc01.JPG" class="" title="This is an image">
<p>(圖源<a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fblogs.nvidia.com.tw%2F2016%2F07%2Fwhats-difference-artificial-intelligence-machine-learning-deep-learning-ai%2F&psig=AOvVaw3XqYIgghvTbnNs_sjlEl5N&ust=1591169227107000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCODggbjN4ukCFQAAAAAdAAAAABAD" target="_blank" rel="noopener">Nvidia官方部落格</a>)<br>雖然深度學習是目前AI的主流，但深度學習這一詞並不是一個新興詞，早在90年代就存在了，當時用神經網路的概念來發表，但礙於當時的設備性能，導致無法提倡這樣的概念，想法終究只能是想法。直到最近的硬體設備性能大幅提升後，才開始把這個概念又拉回來，也因此產生了風潮。</p>
<p>我重新審視一遍自己寫的，發現還是在說人話，接下來因為太多專有名詞和抽象概念了，可能會讓你產生混亂，所以特地提醒你一下！要準備集中精神看了。</p>
<p>「深度學習」表面上看起來很難，其實真的很難！你以為我會說簡單嗎？並沒有。很多文章說明深度學習會說簡單，其實也沒騙你拉！但是當你深入進去時，就會發現這個概念就像樹枝一樣，在樹上會隨著時間越長越多，樹枝開始不停出現分叉，要學的東西也就不停地出現，感覺永遠也沒有學完的一天。舊的東西還沒學完，新的東西又出現了，根本來不及去搞懂，這就是我目前體驗到的。</p>
<p>盡管我這樣說深度學習，他還是有一個很基礎很根本的概念和步驟在，所有的東西都是從這個概念延伸出去的。台大電機系教授李宏毅有說過：「深度學習也只要三個步驟：<strong>建構網路</strong>、<strong>設定目標</strong>、<strong>開始學習</strong>。」</p>
<p>我們用李宏毅教授所說的這三個步驟來解釋好了。</p>
<p><strong>深度學習 = 建構網路 + 設定目標 + 開始學習</strong></p>
<p>因此我們就必須去理解這三個步驟在說什麼。</p>
<p><strong>建構網路</strong><br>建構所謂的神經網路。<br>各位有聽過IPO嗎?也就是Input+Program+Output的簡稱。我們輸入資料，經過程式計算，最後輸出結果，這個就是IPO架構。有學過程式的人一定不陌生。而建構網路就是負責Program這塊。在深度學習的IPO裡，我們會建構一個模型，當輸入一份資料後，資料就會進入這個模型(model)去運算，最後得出結果。模型(model)就像人的神經，裡面有神經元，神經元跟神經元彼此會連線，當神經元有很多個並且連起來後，就會形成神經網路，呼應第一句說的，建構神經網路。</p>
<p><strong>設定目標</strong><br>簡單來說就是你希望這個模型是來做什麼的？<br>這邊我要說一個蠻重要的觀念，深度學習不是萬能的，模型建構出來沒辦法應用於所有的東西上，它只能解決特定的需求。這就來到了我說的第一句，你希望你的模型用來解決什麼問題的？可能是手寫數字的辨識，也有可能是讓機器學會畫畫，不同的問題需求，就會有不同的模型誕生，目前為止是沒有任何一個模型能套用到所有的問題上的。因此設定目標是一個極為關鍵的要素，有了一個目標，才會有想法去「建構網路」，最後才能讓電腦「開始學習」。</p>
<p><strong>開始學習</strong><br>讓機器開始學習。<br>如果什麼參數和細節都要透過人類去設定的話，那就不是「機器學習」。我們設定好目標，建構好網路，接下來就是要讓機器自己去學習。神經網路裡面有數千數百萬個數值細節，這些要靠機器自己去學習如何改變裡面的變數。人們要做的只有給機器大量的訓練資料和規則去學習，並且當機器給出結果時，要告訴它這個答案對不對，最終機器會得到一個最佳函數，也就是問題的最佳解。</p>
<p>這樣講有比較明白一點嗎?我蠻怕我解釋錯誤，自己再三檢查我寫的，覺得這應該就是深度學習最主要的問題與處理步驟，自己學過後了解深度學習的一些相關認知後再回來看這三個要素，蠻感同身受的！</p>
<h3 id="關於神經網路"><a href="#關於神經網路" class="headerlink" title="關於神經網路"></a>關於神經網路</h3><p>剛剛在上文我們有講到深度學習很早之前就被提過了，是以神經網路的概念提出，因此我們就應該好好的去了解一下神經網路到底是什麼了。</p>
<p>上文我有稍微帶到一點神經網路的東西，不知道各位有沒有看到？如果要用生活上的事物來比喻神經網路的話，大概就是人的神經了！正確來說就是模仿生物神經來創造神經網路的。</p>
<p>人的神經有兩個神經元，神經元之間會利用神經纖維來連成一條線進行信號傳輸，機器的神經網路亦是如此。我們在建構神經網路時，會先建立一層神經層，神經層裡有若干的神經元，數量多少就是靠我們自己去決定。接著還會再建立新的神經層，然後新神經層裡的神經元就會與上一層的神經元做連接，形成網路開始進行信號傳遞，什麼情況信號要傳遞到A或B神經元，正是深度學習在學習的。</p>
<p>當我們成功建立好一套神經網路後，就會是我們平常講的模型(Model)。<br>新建立模型一開始正確率一定很低，我們正是要透過大量的訓練資料來訓練這個模型，而模型會因這些訓練資料來學習判斷正確結果，訓練到一定程度後，就會是我們理想中的模型，就可以拿去解決我們需要的問題了，概念如下圖。</p>
<img src="/2020/09/08/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%EF%BC%9F%EF%BC%81%E7%82%BA%E4%BB%80%E9%BA%BC%E6%9C%80%E8%BF%91%E5%A4%A7%E5%AD%B8%E5%92%8C%E8%B3%87%E8%A8%8A%E7%95%8C%E9%83%BD%E8%83%BD%E8%81%BD%E5%88%B0%E9%80%99%E5%80%8B%E8%A9%9E%EF%BC%9F/pc02.jpg" class="" title="This is an image">

<p>另外可能會有人問說:模型訓練是在訓練什麼東西？為什麼訓練後正確率會開始提高？<br>神經網路可以說是一個數學公式，因為我一直希望是抱持著說人話的方式來寫文章，因此就不太說數學那邊的東西。不過這裡我必須要帶點數學觀念了！剛剛我們在上上段有說到神經元這個詞，其實這些神經元就代表著一個變數，一開始是隨機亂給的，所以辨識正確率才會那麼低。為了要讓模型提高正確率，我們會加入訓練資料來做訓練，目的就是為了改變這些神經元的參數，讓這些參數達到我們要的數值，進而提升模型預測的正確率。</p>
<p>如何提高模型正確率？改變神經網路裡神經元的參數權重。</p>
<p>怎麼改神經元的參數權重？替模型加入訓練資料來進行學習。</p>
<p>學習訓練資料裡的什麼？找出訓練資料裡的規則。</p>
<h3 id="神經網路的建置-amp-問題"><a href="#神經網路的建置-amp-問題" class="headerlink" title="神經網路的建置&amp;問題"></a>神經網路的建置&amp;問題</h3><p>這部分如果讀者是0基礎的話，我覺得看過就好，因為之後的程式範例文章看過理解後，才會開始對這一個標題有想法。不過這部分也是屬於深度學習的介紹，因此還是需要歸類在這一篇文章中。</p>
<p><strong>深度學習的精隨，在於怎麼建置神經網路。</strong><br>這句話是我說的，應該沒有任何毛病！當然深度學習也有資料處理這一塊，不過最精華最精華的，還是神經網路這一塊，調整神經網路的架構、參數、模型類別等…..，我們學習深度學習主要的地方。</p>
<p><strong>深度學習為什麼厲害，在於它可以疊很多神經層。</strong><br>神經網路你愛加幾層就幾層，沒人阻止你，建置怎樣的神經網路，正是我們在學習的。<br>不過這裡就來到一個問題: 神經網路越多層越好嗎？<br>答案:不一定！</p>
<p>雖然近幾年來，一些機器學習競賽結果來看，層數越深，錯誤率也跟著降低。VGG模型層數總共19層，錯誤率到7.3%，而googleNet比VGG層數多了3層，一共22層，錯誤率可以再降到6.7%。甚至157層的Residual Network，錯誤率更可降至3.5%！但是層數越多的網路，越是會有<strong>梯度消失問題（Vanishing gradient problem）</strong>，因為每一層運算讓數值不斷收斂，導致最後的 output 越來越小，跟正確答案相減之後也就看不到顯著的最小值，看起來到處都是最小值。而防止梯度爆炸和梯度消失也是我們在建構神經網路時也必須注意的東西。</p>
<p>那可能有人又會問:驗證時不是都有標準答案嗎?把所有的答案和標準答案做比對，怎麼會找不到最小值呢？<br>答案：其實我們要面對的可能不止單單這些標準答案，也許幾百萬幾千萬！驗證時我們沒辦法把一切的答案都納入進去，而是用隨機抽選的方式，在線上找一點，比對這點四周的數值，看看是否又更低的，再慢慢去貼近最低點，這個我們稱此為<strong>梯度下降(Gradient descent)</strong>。</p>
<p>當今天你被丟在一個環境的山上，你的目的是要走到這個環境的最低點，你會開始慢慢的往低點下去。過程可能繞一大圈才下山，也有可能直直的就往低點下去。但不管怎麼樣，最終目的便是前往環境的最低點。</p>
<p>但問題來了！當你下降到一個附近都平坦的地方，你可能就認為這裡就是環境的最低點，殊不知山的對面可能還存在更深的地方或是平原遠一點的地方還存在著谷底。</p>
<p>神經網路疊加的越多層，這個問題就會越明顯，因此需要設計不同的架構，跟特殊的運算過程，才能避免找不到最低點。有時候反而 layer 少一點，正確率還更高。</p>
<h3 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h3><p>我發現我後半段好像開始說東說西偏離主題了，因此總結一下我目前說的：<br>1.深度學習離不開三個要素： 建構網路 、 設定目標 、 開始學習<br>2.怎麼進行深度學習？建構神經網路模型→輸入大量訓練資料來進行模型訓練→再利用訓練好的模型進行實際預測<br>3.深度學習的精隨，在於怎麼建置神經網路。<br>4.神經層數越高，模型的正確率也會隨之增加，但也存在著梯度消失以及梯度爆炸的風險，因此如何避免這些風險並提高模型正確率，正是我們在深度學習所要探討的。</p>
<h3 id="個人心得"><a href="#個人心得" class="headerlink" title="個人心得"></a>個人心得</h3><p>抱歉！最近因為學業和家庭關係，變得不太常更新文章，導致github上的文章都是很久之前的，讓人覺得我是不是放棄這坑了。其實這篇文章我在6月初就寫好了，但是被教授抓去幫中國信託做點他們AI上的事情，然後每周又要有論文進度，因此不太能更新文章。<br>另外我也發現，幾個月前的文章，當初要表達什麼我也不知道了XD比如圖片該放哪張？這篇文章只有兩張圖，我卻想了很久…咦？我這裡有事先截圖留著嗎？我到底是要截哪張圖上來等等…已經有這不是我寫出來的錯覺了XD總而言之，希望這篇文對你在深度學習的認知上有一點基礎，雖然有人可能會覺得打那麼多誰看得完？十分抱歉，因為我不是超級專家，我也是學習中的學生，所以無法靠很厲害的圖解來讓讀者輕鬆閱讀，這點還請多多包涵！日後我會盡量改進的。</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/">在Anaconda安裝Tensorflow2.0版本(GPU版本篇)</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-06-01T06:14:51.000Z" itemprop="datePublished">
    2020-06-01
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">實作心得</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Jupyter-notebook/">Jupyter notebook</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Anaconda/">Anaconda</a> }
  </li>


  </ul>
  
  
</div>

    </header>
    <div>
      
        <h3 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h3><p>因為碩士選擇了人工智慧，於是便開始接觸tensorflow。網路上雖然有很多的教學文章可以參考，但是按照他們的教學做都失敗了，不是執行時dead kernel，不然就是沒抓到tensorflow的函式庫，還有最重要的一點就是爬出來的文章過舊，已經沒辦法照著做了，當時為了安裝tensorflow折騰了我好久，因此便寫下我安裝的心路歷程，也方便我日後觀看，不用再爬文。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明如何在anaconda安裝tensorflow 2，包括tensorflow CPU版本以及GPU版本，也會順便提醒安裝時要注意什麼以免安裝失敗。<br>本來想CPU跟GPU一次講解完畢，但發現文章過長，故分成兩篇撰寫，此篇為GPU版本。</p>
<h3 id="前置步驟-amp-注意事項"><a href="#前置步驟-amp-注意事項" class="headerlink" title="前置步驟&amp;注意事項"></a>前置步驟&amp;注意事項</h3><ol>
<li>閱覽此篇文章前，請先閱讀<a href="https://chenchianstudent.github.io/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/" target="_blank" rel="noopener">此篇文章</a>，有些小技巧我在CPU版本有說，我不知道這篇我會不會特地寫出來，撰寫過程可能會因為文章過長要想的地方太多而忘記去解釋，因此我會希望先看完CPU版本的文章再來讀這篇會比較好！</li>
<li>很重要!!!!如果有安裝anaconda的，請卸載anaconda，記得是卸載乾淨！我安裝失敗有很大的原因是沒卸載anaconda，導致anaconda沒有去抓重要的東西進來。</li>
<li>懂一點伺服器安裝指令。</li>
<li>這裡我還是要給各位說明一下，每個人遇到的問題可能會不同，也許我遇到的問題你根本沒遇到，我沒遇到的問題你遇到了，因此請具備爬文找問題和方法的處理態度去做接下來的事，這裡我只能把我的遇到的問題跟解決方式說出來，我無法神通廣大預測你會遇到什麼問題。</li>
<li>tensorflow-GPU安裝的版本為2.0。</li>
<li>在安裝tensorflow-GPU前，請先確認你的顯示卡支不支援tensorflow，較低階的顯示卡有存在跑不動的問題。<br>(怎麼檢查?這裡有文章教你<a href="https://www.itread01.com/content/1547549489.html" target="_blank" rel="noopener">TensorFlow：檢查顯示卡支援哪個版本的CUDA - IT閱讀</a>)</li>
<li>我不知道這算不算必要，但請安裝最新的顯卡驅動程式，就當保險起見，以免衍生出新的問題。</li>
<li>安裝於Windows系統，實際在寫tensorflow時是用jupyter notebook，spyder似乎不能寫的樣子?</li>
</ol>
<h3 id="我該安裝GPU還是CPU版本-這到底有什麼差別"><a href="#我該安裝GPU還是CPU版本-這到底有什麼差別" class="headerlink" title="我該安裝GPU還是CPU版本?這到底有什麼差別?"></a>我該安裝GPU還是CPU版本?這到底有什麼差別?</h3><p>能安裝GPU版本當然是安裝GPU版本囉！GPU跟CPU這兩個版本計算能力差很多的，我親自體驗過，因為最一開始是裝CPU版本，當時一直裝失敗GPU版本就退而求其次裝CPU版本。CPU訓練模型的時間，GPU可以跑好幾次，甚至有些參數可以調大來計算求更好的模型正確率。個人認為CPU版本純粹是給入門者熟悉用的，不管怎麼樣，要繼續學tensorflow和人工智慧就是要切換成GPU版本，這點還是認清一下吧！兩邊真的差很多。<br>這邊給你一個GPU版本的執行速度，4400筆訓練完只需要花一分鐘左右的時間，CPU會用到5分鐘甚至更久。</p>
<img src="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/pc07.JPG" class="" title="This is an image">

<h3 id="安裝GPU版本的流程"><a href="#安裝GPU版本的流程" class="headerlink" title="安裝GPU版本的流程"></a>安裝GPU版本的流程</h3><p>這個流程其實就是我下面要說的安裝步驟，突然獨立出這個部分是因為我怕安裝步驟內容過長，各位光是被我的文字海淹沒就不行了，因此便獨立出來說一下大致的安裝流程。<br>前置  更新顯卡驅動程式(我不知道是不是必要，但我安裝tensorflow的電腦都會更新驅動)<br>第一步 卸載anaconda<br>第二步 安裝cuda和cudnn<br>第三步 安裝anaconda<br>第四步 安裝tensorflow-GPU&amp;指定版本<br>第五步 測試</p>
<h3 id="GPU版本安裝第一步驟-卸載anaconda"><a href="#GPU版本安裝第一步驟-卸載anaconda" class="headerlink" title="GPU版本安裝第一步驟-卸載anaconda"></a>GPU版本安裝第一步驟-卸載anaconda</h3><p>GPU版本的安裝我爬了不少文章，但是幾乎是失敗的，原因其實有兩種，第一種是蠻多文章過舊，有些安裝方式或是測試方式tensorflow2.0已經不支援了，不然就是天下一大抄，抄完後實際的內容也沒特別去解釋或補充，東漏一個西漏一個，有些乾脆不寫核心問題，導致照他的步驟做，就失敗了。第二個失敗原因就是這個，安裝tensorflow的時候沒將anaconda卸載，有沒有卸載就是成功失敗的關鍵了！這邊可能要先講下面會說的CUDA和cuDNN，我們重裝的原因主要是把CUDA和cuDNN的一些設定參數放進anaoncda裡，使tensorflow能正常運作而不會dead kernel。這裡若是在已安裝anaconda的情況下再安裝CUDA和cuDNN，那這兩個的設定參數可能就吃不到了。好像是可以手動加進去拉！但是我直接說我不會，因此乾脆一點直接重裝讓anaconda自己去抓設定參數就好了，也不用去想手動加入的事情。</p>
<p>因此，第一步驟最關鍵的部分就是將anaconda卸載。如果沒有安裝過anaconda的話可以直接跳過此步驟<br>卸載完成後先去官網將安裝檔載下來等等拿來用<br>Anaconda官方下載網頁:<a href="https://www.anaconda.com/products/individual" target="_blank" rel="noopener">https://www.anaconda.com/products/individual</a></p>
<h3 id="CPU版本安裝第二步驟-安裝CUDA"><a href="#CPU版本安裝第二步驟-安裝CUDA" class="headerlink" title="CPU版本安裝第二步驟-安裝CUDA"></a>CPU版本安裝第二步驟-安裝CUDA</h3><p>CUDA是什麼?<br>網路上隨便搜索就不少文章，這邊我套用一下wiki的說明<br>CUDA（Compute Unified Device Architecture，統一計算架構）是由NVIDIA所推出的一種整合技術，是該公司對於GPGPU的正式名稱。透過這個技術，使用者可利用NVIDIA的GeForce 8以後的GPU和較新的Quadro GPU進行計算。亦是首次可以利用GPU作為C-編譯器的開發環境。NVIDIA行銷的時候，往往將編譯器與架構混合推廣，造成混亂。實際上，CUDA可以相容OpenCL或者自家的C-編譯器。無論是CUDA C-語言或是OpenCL，指令最終都會被驅動程式轉換成PTX代碼，交由顯示核心計算。<br>另外這是我的解釋<br>其實就是優化GPU運算的一種工具。</p>
<p>CUDA下載網址:<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a><br>在下載前請先確認你的顯卡支援哪種版本號，方法我在前置步驟&amp;注意事項那邊有講。<br>我安裝的電腦顯卡分別是GTX1050 Ti跟GTX 1650，兩個選擇的版本號皆是最新的10.2。<br>接下來我會用我的顯卡支援的版本號做接下來的步驟，其他版本號的安裝步驟也大同小異拉，就是版本那邊選擇支援的版本號就是了。</p>
<p>CUDA<br>版本號:10.2<br>進入上面寫的下載網址後選擇你要求的CUDA<br>Operating System→Windows<br>Architecture→x86_64<br>Version→10 (看你支援的版本號喔)<br>Installer Type→都可以，隨便你選擇<br>圖片紅框的地方就是我選擇的選項</p>
<img src="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/pc01.jpg" class="" title="This is an image">
<p>選完Installer Type後，便會開始進行下載安裝檔的動作。<br>下載下來開始進行安裝，跟安裝更新顯卡驅動一樣，這裡我就不多做解釋。<br>安裝過程中路徑如果照預設路徑安裝，會在這個地方出現C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA，也可以在這邊確認你安裝的CUDA版本號。</p>
<img src="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/pc02.JPG" class="" title="This is an image">

<h3 id="GPU版本安裝第三步驟-安裝cuDNN"><a href="#GPU版本安裝第三步驟-安裝cuDNN" class="headerlink" title="GPU版本安裝第三步驟-安裝cuDNN"></a>GPU版本安裝第三步驟-安裝cuDNN</h3><p>cuDNN是什麼?<br>是一種用於深度神經網絡的GPU加速庫，也就是加速我們tensorflow-GPU運算性能的一種工具。</p>
<p>CUDA和cuDNN都要裝喔！缺一不可，安裝順序是先CUDA後cuDNN。<br>cuDNN下載網址:<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener">https://developer.nvidia.com/cudnn</a><br>點進去後找到下圖紅框download的位置。</p>
<img src="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/pc03.jpg" class="" title="This is an image">
<p>接下來nivida會叫你登入帳號，這裡請登入。<br>登入後就會有個同意選項要你按，下圖是按完同意後的樣子。</p>
<img src="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/pc04.jpg" class="" title="This is an image">
<p>機靈的你可能發現了圖片裡有個紅框，沒錯！這裡需要注意一下！<br>要特別注意cuDNN的安裝檔是支援哪個版本的CUDA，CUDA10.2就是配cuDNN10.2，不能配個cuDNN10.1喔！<br>下載下來是個壓縮檔，不是安裝檔，這裡稍微看一下，然後把壓縮檔內的檔案全部複製起來。</p>
<img src="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/pc05.jpg" class="" title="This is an image">
<p>丟到CUDA裡，安裝時的預設路徑為<br>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.2</p>
<h3 id="GPU版本安裝第四步驟-安裝anaconda"><a href="#GPU版本安裝第四步驟-安裝anaconda" class="headerlink" title="GPU版本安裝第四步驟-安裝anaconda"></a>GPU版本安裝第四步驟-安裝anaconda</h3><p>確認好CUDA和cuDNN都安裝完成後，就可以將anaconda載回來了。<br>Anaconda官方下載網頁:<a href="https://www.anaconda.com/products/individual" target="_blank" rel="noopener">https://www.anaconda.com/products/individual</a><br>你當初怎麼裝的，這裡就照著做，我是一路next下去，照著預設做。</p>
<h3 id="GPU版本安裝第五步驟-安裝tensorflow-GPU"><a href="#GPU版本安裝第五步驟-安裝tensorflow-GPU" class="headerlink" title="GPU版本安裝第五步驟-安裝tensorflow-GPU"></a>GPU版本安裝第五步驟-安裝tensorflow-GPU</h3><p>這是conda安裝tensorflow的說明:<a href="https://anaconda.org/anaconda/tensorflow-gpu" target="_blank" rel="noopener">https://anaconda.org/anaconda/tensorflow-gpu</a></p>
<img src="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/pc08.JPG" class="" title="This is an image">
<p>裡面寫了照這個指令輸入便可安裝該作業系統提供的版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c anaconda tensorflow-gpu</span><br></pre></td></tr></table></figure>
<p>因此我們便開啟anaconda的CMD來下這個指令。<br>過程中我遇到一個問題，不知道在安裝的你有沒有遇到，好像windows tensorflow-gpu v2.1的載點掛了。<br>anaconda幫我找了備用載點去下載tensorflow-GPU，版本為v1.10。<br>這樣子只能自己去下載更新tensorflow-GPU了。<br>在anaconda的CMD下達指令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow-gpu&#x3D;&#x3D;2.0</span><br></pre></td></tr></table></figure>
<p>提醒一下<br>千萬別用這個指令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --ignore-installed --upgrade tensorflow-gpu</span><br></pre></td></tr></table></figure>
<p>我不知道各位有沒有遇到，他下載的tensorflow-GPU的版本為v2.4。<br>我實際去tensorflow官網查，也沒有2.4版本的消息，到底是哪個環節出錯誤了?<br>實際去測也是各種噴錯，目前我推估這個版本是沒有辦法使用的。</p>
<p>這裡有人可能會說<br>我一開始使用conda安裝的tensorflow-GPU v1.10版本經測試也可以用啊?為什麼要特地去裝2.0版本?而且還只指定2.0版本，不能用2.1或2.2版本嗎?</p>
<p>恩…..對！v1.10可以用，但是當你使用了tensorflow 2的模型架構時，會直接噴錯，並告訴你這是TF2才支援的寫法，而且tensorflow 2已經開始算主流，寫法也會開始慢慢轉變成TF2的寫法，沒有必要執著在TF1。<br>而至於為什麼指定為v2.0而不是其他版本原因是我自己安裝時，只有2.0版本成功執行起來，2.1跟2.2直接噴錯不讓我動，應該是我能力不足而不是那個版本有問題，最一開始我也說了，我碰壁很久了，這是我目前能安裝起來並能順利執行程式的心得步驟，也許之後會再修改或是另開文章更新其他版本，但目前這是我的安裝步驟的最佳解。</p>
<h3 id="GPU版本安裝第五步驟-測試tensorflow-GPU"><a href="#GPU版本安裝第五步驟-測試tensorflow-GPU" class="headerlink" title="GPU版本安裝第五步驟-測試tensorflow-GPU"></a>GPU版本安裝第五步驟-測試tensorflow-GPU</h3><p>第四步驟做完後，就可以打開Anaconda的jupyter notebook</p>
<img src="/2020/06/01/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-0%E7%89%88%E6%9C%AC-GPU%E7%89%88%E6%9C%AC%E7%AF%87/pc06.jpg" class="" title="This is an image">
<p>以下為測試tensorflow-gpu的程式碼</p>
<ul>
<li>最基本的查看tensorflow版本號<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
output:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v2.0</span><br></pre></td></tr></table></figure></li>
<li>查看電腦是否有GPU<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">gpu_device_name &#x3D; tf.test.gpu_device_name()</span><br><span class="line">print(gpu_device_name)</span><br></pre></td></tr></table></figure>
output:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;device:GPU:0</span><br></pre></td></tr></table></figure></li>
<li>檢查GPU是否可用<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"> tf.test.is_gpu_available()</span><br></pre></td></tr></table></figure>
output:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">True或是False</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/">在Anaconda安裝Tensorflow2.0版本(CPU版本篇)</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2020-05-25T07:58:46.000Z" itemprop="datePublished">
    2020-05-25
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">實作心得</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Jupyter-notebook/">Jupyter notebook</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Anaconda/">Anaconda</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/Tensorflow-%E5%AF%A6%E4%BD%9C%E5%BF%83%E5%BE%97/">Tensorflow 實作心得</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <h1 id="在Anaconda安裝Tensorflow2-0版本-CPU版本篇"><a href="#在Anaconda安裝Tensorflow2-0版本-CPU版本篇" class="headerlink" title="在Anaconda安裝Tensorflow2.0版本(CPU版本篇)"></a>在Anaconda安裝Tensorflow2.0版本(CPU版本篇)</h1><h3 id="為什麼會有這篇文章"><a href="#為什麼會有這篇文章" class="headerlink" title="為什麼會有這篇文章?"></a>為什麼會有這篇文章?</h3><p>因為碩士選擇了人工智慧，於是便開始接觸tensorflow。網路上雖然有很多的教學文章可以參考，但是按照他們的教學做都失敗了，不是執行時dead kernel，不然就是沒抓到tensorflow的函式庫，還有最重要的一點就是爬出來的文章過舊，已經沒辦法照著做了，當時為了安裝tensorflow折騰了我好久，因此便寫下我安裝的心路歷程，也方便我日後觀看，不用再爬文。</p>
<h3 id="這篇文章做什麼用的"><a href="#這篇文章做什麼用的" class="headerlink" title="這篇文章做什麼用的?"></a>這篇文章做什麼用的?</h3><p>這篇文章是來說明如何在anaconda安裝tensorflow 2，包括tensorflow CPU版本以及GPU版本，也會順便提醒安裝時要注意什麼以免安裝失敗。<br>本來想CPU跟GPU一次講解完畢，但發現文章過長，故分成兩篇撰寫，此篇為CPU版本。</p>
<h3 id="前置步驟-amp-注意事項"><a href="#前置步驟-amp-注意事項" class="headerlink" title="前置步驟&amp;注意事項"></a>前置步驟&amp;注意事項</h3><ol>
<li>很重要!!!!如果有安裝anaconda的，請卸載anaconda，記得是卸載乾淨！我安裝失敗有很大的原因是沒卸載anaconda，導致anaconda沒有去抓重要的東西進來。</li>
<li>懂一點伺服器安裝指令。</li>
<li>這裡我還是要給各位說明一下，每個人遇到的問題可能會不同，也許我遇到的問題你根本沒遇到，我沒遇到的問題你遇到了，因此請具備爬文找問題和方法的處理態度去做接下來的事，這裡我只能把我的遇到的問題跟解決方式說出來，我無法神通廣大預測你會遇到什麼問題。</li>
<li>tensorflow-CPU安裝的版本為1.10。</li>
<li>在安裝tensorflow-GPU前，請先確認你的顯示卡支不支援tensorflow，較低階的顯示卡有存在跑不動的問題。<br>(怎麼檢查?這裡有文章教你<a href="https://www.itread01.com/content/1547549489.html" target="_blank" rel="noopener">TensorFlow：檢查顯示卡支援哪個版本的CUDA - IT閱讀</a>)</li>
<li>我不知道這算不算必要，但請安裝最新的顯卡驅動程式，就當保險起見，以免衍生出新的問題。</li>
<li>安裝於Windows系統，實際在寫tensorflow時是用jupyter notebook，spyder似乎不能寫的樣子?</li>
</ol>
<h3 id="我該安裝GPU還是CPU版本-這到底有什麼差別"><a href="#我該安裝GPU還是CPU版本-這到底有什麼差別" class="headerlink" title="我該安裝GPU還是CPU版本?這到底有什麼差別?"></a>我該安裝GPU還是CPU版本?這到底有什麼差別?</h3><p>能安裝當然是安裝GPU版本囉！GPU跟CPU這兩個版本計算能力差很多的，我親自體驗過，因為我最一開始是裝CPU版本，當時一直裝失敗GPU版本就退而求其次裝CPU版本。CPU訓練模型的時間，GPU可以跑好幾次，甚至有些參數可以調大來計算求更好的模型正確率。個人認為CPU版本純粹是給入門者熟悉用的，不管怎麼樣，要繼續學tensorflow和人工智慧就是要切換成GPU版本，這點還是認清一下吧！兩邊真的差很多。<br>這邊給你一個GPU版本的執行速度，4400筆訓練完只需要花一分鐘左右的時間，CPU會用到5分鐘甚至更久。</p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc11.JPG" class="" title="This is an image">

<h3 id="CPU版本安裝第一步驟-安裝anaconda並開啟anaconda的CMD"><a href="#CPU版本安裝第一步驟-安裝anaconda並開啟anaconda的CMD" class="headerlink" title="CPU版本安裝第一步驟-安裝anaconda並開啟anaconda的CMD"></a>CPU版本安裝第一步驟-安裝anaconda並開啟anaconda的CMD</h3><p>CPU版本的安裝我主要是參考<a href="https://medium.com/@virginiakm1988/%E5%9C%A8-anaconda-%E8%99%9B%E6%93%AC%E7%92%B0%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%9D-tensorflow%E8%88%87-keras-c2c5aed98fef" target="_blank" rel="noopener">這篇文章</a>來做的，實際有安裝成功，不想看我教學的可以直接點進去看。<br>如果純粹只是嘗鮮的，安裝CPU版本就好了，跟GPU相比之下簡單又省時(指安裝過程)。<br>另外，安裝CPU版本的，可以不用卸載anaconda，但如果已經卸載了或是還沒安裝過的，請到官網去下載並安裝anaconda。<br>Anaconda官方下載網頁:<a href="https://www.anaconda.com/products/individual" target="_blank" rel="noopener">https://www.anaconda.com/products/individual</a></p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc01.JPG" class="" title="This is an image">
<p>安裝完成後，點擊左下的windows查找anaonda的CMD並開啟他</p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc02.jpg" class="" title="This is an image">
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc03.JPG" class="" title="This is an image">
<h3 id="CPU版本安裝第二步驟-建置新的anaconda環境"><a href="#CPU版本安裝第二步驟-建置新的anaconda環境" class="headerlink" title="CPU版本安裝第二步驟-建置新的anaconda環境"></a>CPU版本安裝第二步驟-建置新的anaconda環境</h3><p>我們延續第一步驟開啟CMD後，下達該指令來建置一個新的anaconda環境。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name tensorflow python&#x3D;3.5</span><br></pre></td></tr></table></figure>
<p>name空格後面的是環境名稱，也就是tensorflow這裡，你可以自行更改成你熟悉的名稱。而python=3.5則是指定python為3.5版本。<br>安裝過程請直接Y帶過，除非你想弄懂他要安裝什麼進來。<br>成功後開啟anaconda，這裡就會有一個新的環境可以讓你做切換。</p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc04.jpg" class="" title="This is an image">
<p>(因為我重裝GPU版本，導致以前CPU版本的資料都沒了，沒辦法截圖，我只能以文字形容，十分抱歉！)<br>說到這裡可能有人會覺得為什麼要建置新的虛擬環境?用原先預設的root不是也可以?<br>沒錯！確實可以，目前直接在預設環境安裝CPU版本是沒問題的。<br>為什麼要安裝新的虛擬環境，原因是”指定python版本”。<br>建置正確的版本號，來避免程式執行時衍伸的新錯誤或是不該出現的問題，也就是版本出錯無法運行的問題，又或是沒出錯但出現執行卡死，爬的文章好多都不寫原因直接給指令，害我要多爬這類的問題。</p>
<p>另外，在anaconda的CMD裡也可以直接切換環境，只要打以下指令就可以切換了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate tensorflow</span><br></pre></td></tr></table></figure>
<p>這裡的tensorflow是你的環境名稱，環境名稱不同就要更改喔！不要傻傻地也打tensorflow。</p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc05.JPG" class="" title="This is an image">
<p>右邊的(base)轉變成(tensorflow)就表示成功了。</p>
<h3 id="CPU版本安裝第三步驟-安裝tensorflow-CPU版本"><a href="#CPU版本安裝第三步驟-安裝tensorflow-CPU版本" class="headerlink" title="CPU版本安裝第三步驟-安裝tensorflow CPU版本"></a>CPU版本安裝第三步驟-安裝tensorflow CPU版本</h3><p>繼續第二步驟CMD切換環境的部分，將預設環境切換成新的環境後，就可以下達安裝指令了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install tensorflow</span><br></pre></td></tr></table></figure>
<p>然後就會開始安裝tensorflow了，中途記得按Y繼續，很簡單的。</p>
<p>我知道接下來有人會急著測試是不是有安裝成功，但先停下來，我有個anaconda的技巧要告訴大家，當然用不用隨你。<br>我們安裝函式庫時，幾乎都是對CMD下達install指令，然後在CMD裡面看是否有安裝完成。<br>我今天要教的技巧就是，不用在CMD裡下指令就可以將函式庫加進anaconda環境裡。<br>剛剛我們有介紹環境列表在哪裡吧?其實那裏的最大功用就是控管函式庫。</p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc06.jpg" class="" title="This is an image">
<p>圖片紅框裡installed部分，是顯示這個環境已經安裝的函式庫，可以切換成ALL等之類的特定篩選<br>切換成ALL之後，我們先去搜尋jupyter notebook，新環境是沒有幫你安裝jupyter notebook的，等等要測時會用到，因此先安裝notebook</p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc07.jpg" class="" title="This is an image">
<p>勾選你要的，然後點擊右下角apply就會幫你安裝了。<br>(注意！是notebook這個才是jupyter notebook喔！我因為安裝過了才點其他的)</p>
<h3 id="CPU版本安裝第四步驟-測試tensorflow-CPU版本"><a href="#CPU版本安裝第四步驟-測試tensorflow-CPU版本" class="headerlink" title="CPU版本安裝第四步驟-測試tensorflow CPU版本"></a>CPU版本安裝第四步驟-測試tensorflow CPU版本</h3><p>安裝完成jupyter notebook後，我們接著要做的是開啟新環境的jupyter notebook。<br>怎麼做呢?有兩種方法：<br>第一種是下圖的方式，每個環境旁邊都有執行圖式，點下去就可以選擇執行方式，選擇notebook就可以開啟了。</p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc08.jpg" class="" title="This is an image">
<p>第二種方法就是開啟windows搜尋jupyter notebook，找到環境的jupyter notebook就ok了。</p>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc09.jpg" class="" title="This is an image">
<p>好了！接下來就是我們最期待的測試階段！<br>以下為測試程式碼，是察看你tensorflow版本號的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<img src="/2020/05/25/%E5%9C%A8Anaconda%E5%AE%89%E8%A3%9DTensorflow2-CPU%E7%89%88%E6%9C%AC%E7%AF%87/pc10.JPG" class="" title="This is an image">
<p>output會顯示你的版本號，如果連版本號都沒出來就表示沒安裝成功。<br>網路上什麼session()之類的，全是舊版的，是tensorflow 2是不支援的，你打再多都是噴錯。</p>

      
    </div>
</article>

    </li>
  
</ul>



            <footer>
    <div>© 2020 - daniel chen </div>
    <div>
        <span>
            Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a>
        </span>
        ,
        <span>
            Theme - <a href="https://github.com/nameoverflow/hexo-theme-icalm" target="_blank" rel="noopener">Icalm</a>
        </span>
    </div>
</footer>

        </div>
    </div>
</div>

<script src="/js/pager/dist/singlepager.js"></script>

<script>
var sp = new Pager('data-pager-shell')

</script>
</body>
</html>